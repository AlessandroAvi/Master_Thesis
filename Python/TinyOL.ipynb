{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from PIL import Image\n",
    "\n",
    "import myTestingPlot as myPlotT\n",
    "import myDatasetPlot as myPlotD\n",
    "import myDatasetParse as myParse\n",
    "import myWriteFile as myWrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Dataset for letter ['A' 'E' 'I' 'O' 'U']\n",
      "\n",
      "Raw shape        -> (180000, 5)\n",
      "Columns          -> ['acquisition', 'letter', 'ax', 'ay', 'az']\n",
      "\n",
      "Tot samples      -> 900\n",
      "1 Sample is long -> 200\n",
      "\n",
      "\n",
      "**** OL data\n",
      "\n",
      "*** Separate train-valid\n",
      "\n",
      "Train data shape  -> (101, 600)\n",
      "Train label shape -> (101,)\n",
      "\n",
      "Test data shape   -> (42, 600)\n",
      "Test label shape  -> (42,)\n",
      "\n",
      "**** TF data\n",
      "\n",
      "*** Separate train-valid\n",
      "\n",
      "Train data shape  -> (529, 600)\n",
      "Train label shape -> (529,)\n",
      "\n",
      "Test data shape   -> (226, 600)\n",
      "Test label shape  -> (226,)\n"
     ]
    }
   ],
   "source": [
    "tmp1, tmp2 = myParse.loadDataFromTxt('augmented_vowels')\n",
    "\n",
    "# Shuffle the matrix of all letters\n",
    "vowels_data = np.zeros(tmp1.shape)\n",
    "vowels_label = np.empty(tmp2.shape, dtype=str) \n",
    "\n",
    "index_ary = list(range(0, tmp1.shape[0]))\n",
    "index_ary = random.sample(index_ary, len(index_ary)) \n",
    "\n",
    "for i in range(0, tmp1.shape[0]):\n",
    "    vowels_data[i,:] = tmp1[index_ary[i],:]\n",
    "    vowels_label[i]  = tmp2[index_ary[i]]\n",
    "    \n",
    "# Separate in 60% and 40% for training the TF model and the OL model\n",
    "sep = int((vowels_data.shape[0])*0.16)\n",
    "\n",
    "print('\\n**** OL data')\n",
    "OL_data  = vowels_data[:sep, :]\n",
    "OL_label = vowels_label[:sep]\n",
    "OL_data_train_vow, OL_label_train_vow, OL_data_test_vow, OL_label_test_vow = myParse.parseTrainValid(OL_data, OL_label)\n",
    "\n",
    "\n",
    "print('\\n**** TF data')\n",
    "TF_data  = vowels_data[sep:, :]\n",
    "TF_label = vowels_label[sep:]\n",
    "TF_data_train, TF_label_train, TF_data_test, TF_label_test = myParse.parseTrainValid(TF_data, TF_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Dataset for letter ['B']\n",
      "\n",
      "Raw shape        -> (29400, 5)\n",
      "Columns          -> ['acquisition', 'letter', 'ax', 'ay', 'az']\n",
      "\n",
      "Tot samples      -> 147\n",
      "1 Sample is long -> 200\n",
      "\n",
      "\n",
      "*** Separate train-valid\n",
      "\n",
      "Train data shape  -> (102, 600)\n",
      "Train label shape -> (102,)\n",
      "\n",
      "Test data shape   -> (43, 600)\n",
      "Test label shape  -> (43,)\n"
     ]
    }
   ],
   "source": [
    "B_data, B_label = myParse.loadDataFromTxt('B_dataset')\n",
    "B_train_data, B_train_label, B_test_data, B_test_label = myParse.parseTrainValid(B_data, B_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Dataset for letter ['M']\n",
      "\n",
      "Raw shape        -> (29000, 5)\n",
      "Columns          -> ['acquisition', 'letter', 'ax', 'ay', 'az']\n",
      "\n",
      "Tot samples      -> 145\n",
      "1 Sample is long -> 200\n",
      "\n",
      "\n",
      "*** Separate train-valid\n",
      "\n",
      "Train data shape  -> (101, 600)\n",
      "Train label shape -> (101,)\n",
      "\n",
      "Test data shape   -> (42, 600)\n",
      "Test label shape  -> (42,)\n"
     ]
    }
   ],
   "source": [
    "M_data, M_label = myParse.loadDataFromTxt('M_dataset')\n",
    "M_train_data, M_train_label, M_test_data, M_test_label = myParse.parseTrainValid(M_data, M_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Dataset for letter ['R']\n",
      "\n",
      "Raw shape        -> (29000, 5)\n",
      "Columns          -> ['acquisition', 'letter', 'ax', 'ay', 'az']\n",
      "\n",
      "Tot samples      -> 145\n",
      "1 Sample is long -> 200\n",
      "\n",
      "\n",
      "*** Separate train-valid\n",
      "\n",
      "Train data shape  -> (101, 600)\n",
      "Train label shape -> (101,)\n",
      "\n",
      "Test data shape   -> (42, 600)\n",
      "Test label shape  -> (42,)\n"
     ]
    }
   ],
   "source": [
    "R_data, R_label = myParse.loadDataFromTxt('R_dataset')\n",
    "R_train_data, R_train_label, R_test_data, R_test_label = myParse.parseTrainValid(R_data, R_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset of all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New dataset of ordered data has shape (405, 600)\n",
      "New dataset of ordered label has shape(405,)\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix that contains all the train data\n",
    "\n",
    "order_data_all = OL_data_train_vow\n",
    "order_data_all = np.vstack(( order_data_all, B_train_data))\n",
    "order_data_all = np.vstack(( order_data_all, R_train_data))\n",
    "order_data_all = np.vstack(( order_data_all, M_train_data))\n",
    "\n",
    "order_label_all = OL_label_train_vow\n",
    "order_label_all = np.hstack(( order_label_all, B_train_label))\n",
    "order_label_all = np.hstack(( order_label_all, R_train_label))\n",
    "order_label_all = np.hstack(( order_label_all, M_train_label))\n",
    "\n",
    "print('\\nNew dataset of ordered data has shape ' + str(order_data_all.shape))\n",
    "print('New dataset of ordered label has shape' + str(order_label_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the matrix of all letters\n",
    "mixed_data_all = np.zeros(order_data_all.shape)\n",
    "mixed_label_all = np.empty(order_label_all.shape, dtype=str) \n",
    "\n",
    "index_ary = list(range(0, order_data_all.shape[0]))\n",
    "index_ary = random.sample(index_ary, len(index_ary)) \n",
    "\n",
    "for i in range(0, order_data_all.shape[0]):\n",
    "    mixed_data_all[i,:] = order_data_all[index_ary[i],:]\n",
    "    mixed_label_all[i]  = order_label_all[index_ary[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset of only new letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New dataset of mixed data has shape (304, 600)\n",
      "New dataset of mixed label has shape(304,)\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix that contains all the train data\n",
    "\n",
    "order_data_new = B_train_data\n",
    "order_data_new = np.vstack(( order_data_new, R_train_data))\n",
    "order_data_new = np.vstack(( order_data_new, M_train_data))\n",
    "\n",
    "order_label_new = B_train_label\n",
    "order_label_new = np.hstack(( order_label_new, R_train_label))\n",
    "order_label_new = np.hstack(( order_label_new, M_train_label))\n",
    "\n",
    "print('\\nNew dataset of mixed data has shape ' + str(order_data_new.shape))\n",
    "print('New dataset of mixed label has shape' + str(order_label_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the matrix of all letters\n",
    "mixed_data_new = np.zeros(order_data_new.shape)\n",
    "mixed_label_new = np.empty(order_label_new.shape, dtype=str) \n",
    "\n",
    "index_ary = list(range(0, order_data_new.shape[0]))\n",
    "index_ary = random.sample(index_ary, len(index_ary)) \n",
    "\n",
    "for i in range(0, order_data_new.shape[0]):\n",
    "    mixed_data_new[i,:] = order_data_new[index_ary[i],:]\n",
    "    mixed_label_new[i]  = order_label_new[index_ary[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Container(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.R_test_data       = R_test_data\n",
    "        self.R_test_label      = R_test_label\n",
    "        self.B_test_data       = B_test_data\n",
    "        self.B_test_label      = B_test_label\n",
    "        self.M_test_data       = M_test_data\n",
    "        self.M_test_label      = M_test_label\n",
    "        self.R_test_data       = R_test_data\n",
    "        self.OL_data_test_vow  = OL_data_test_vow\n",
    "        self.OL_label_test_vow = OL_label_test_vow\n",
    "        \n",
    "OL_testing_data = Data_Container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lettToSoft(ary, labels):\n",
    "    ret_ary = np.zeros([len(ary), len(labels)])\n",
    "    \n",
    "    for i in range(0, len(ary)):\n",
    "        for j in range(0, len(labels)):\n",
    "            if(ary[i]==labels[j]):\n",
    "                ret_ary[i,j] = 1\n",
    "\n",
    "            \n",
    "    return ret_ary   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameters\n",
    "optimizer = 'Adam'\n",
    "loss    = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "vowels = ['A', 'E', 'I', 'O', 'U']\n",
    "\n",
    "epochs = 2         # 20\n",
    "batch_size = 64    # 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model structure\n",
    "\n",
    "# Buoni risultati con 3 layer da 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_shape =(TF_data_train.shape[1],),name='input_layer'))\n",
    "#model.add(Dense(128, activation = 'relu', name='hidden1'))\n",
    "model.add(Dense(300, activation = 'relu', name='hidden2'))\n",
    "model.add(Dense(5, activation='softmax' , name = 'output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 128)               76928     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 300)               38700     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 5)                 1505      \n",
      "=================================================================\n",
      "Total params: 117,133\n",
      "Trainable params: 117,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer= optimizer, loss=loss, metrics=metrics) #use sparse is each letter is an integer (es a->1 b->2 c->3 ..)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7/7 - 0s - loss: 363.7159 - accuracy: 0.4019 - val_loss: 105.5826 - val_accuracy: 0.5660\n",
      "Epoch 2/2\n",
      "7/7 - 0s - loss: 66.9968 - accuracy: 0.6809 - val_loss: 40.9305 - val_accuracy: 0.7075\n",
      "\n",
      "Evaluation:\n",
      "8/8 - 0s - loss: 32.0816 - accuracy: 0.7788\n"
     ]
    }
   ],
   "source": [
    "# Perform training\n",
    "train_hist = model.fit(TF_data_train, lettToSoft(TF_label_train, vowels), epochs=epochs, batch_size=batch_size, validation_split=0.2 , verbose=2)\n",
    "print('\\nEvaluation:')\n",
    "results = model.evaluate(TF_data_test, lettToSoft(TF_label_test, vowels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_loss = train_hist.history['loss']\n",
    "hist_val_loss = train_hist.history['val_loss']\n",
    "epoch_list = list(range(epochs))\n",
    "plt.figure(1)\n",
    "plt.plot(epoch_list, hist_loss, 'bo', label='Training loss')\n",
    "plt.plot(epoch_list, hist_val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on random vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       -> E\n",
      "Prediction -> E\n"
     ]
    }
   ],
   "source": [
    "rand_n = int(random.uniform(0, TF_data_test.shape[0]))\n",
    "sample_data = TF_data_test[rand_n,:].reshape(1,TF_data_test.shape[1])\n",
    "sample_label = TF_label_test[rand_n]\n",
    "\n",
    "pred = model.predict(sample_data)\n",
    "print(f'True       -> {sample_label}')\n",
    "print(f'Prediction -> {vowels[np.argmax(pred)]}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#myPlotT.plotTest(TF_data_test, TF_label_test, model, vowels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveParams(SAVE_MODEL_PATH, model):\n",
    "    \n",
    "    new_file = open(SAVE_MODEL_PATH + '/params.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    new_file.write(\"\\n Batch size: \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs: \" + str(epochs))\n",
    "    new_file.write(\"\\n Validation split: \" + str(0.2))\n",
    "    new_file.write(\"\\n Metrics: \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer: \" + optimizer)\n",
    "    new_file.write(\"\\n Loss: \" + loss + \"\\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = \"C:/Users/massi/UNI/Magistrale/Anno 5/Semestre 2/Tesi/Code/Python/Saved_models/model/\"\n",
    "model.save(SAVE_MODEL_PATH + \"model.h5\")\n",
    "saveParams(SAVE_MODEL_PATH, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Layer(object):\n",
    "    def __init__(self, model):\n",
    "\n",
    "        self.ML_frozen = keras.models.Sequential(model.layers[:-1])\n",
    "        self.ML_frozen.compile()\n",
    "        self.W = np.array(model.layers[-1].get_weights()[0])\n",
    "        self.b = np.array(model.layers[-1].get_weights()[1])\n",
    "        self.label = ['A', 'E', 'I', 'O', 'U']\n",
    "        \n",
    "        self.width = self.W.shape[0]\n",
    "\n",
    "    def predict(self, x):\n",
    "        mat_prod = np.matmul(x, self.W) + self.b\n",
    "        return tf.nn.softmax(mat_prod)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNewClass(model, y_true, y_true_soft, i, gauss):\n",
    "    \n",
    "    # Check if letter is new\n",
    "    found = 0\n",
    "    for k in range(0, len(model.label)):\n",
    "        if (y_true[i] == model.label[k]):\n",
    "            found = 1\n",
    "\n",
    "    # If first time seeing this letter\n",
    "    if (found == 0):\n",
    "\n",
    "        model.label.append(y_true[i])   # Add new letter to label\n",
    "        print(f'\\n\\n    New letter detected -> letter \\033[1m{y_true[i]}\\033[0m \\n')\n",
    "    \n",
    "        if(gauss==0):\n",
    "            model.W = np.hstack((model.W, np.zeros([model.width,1])))\n",
    "            model.b = np.hstack((model.b, np.zeros([1])))\n",
    "        elif(gauss==1):\n",
    "            gaussW = np.zeros([model.width,1])\n",
    "            for i in range(0,model.width):\n",
    "                gaussW[i,0] = random.gauss(0, 0.01)\n",
    "            gaussB = random.gauss(0, 0.01)\n",
    "            model.W = np.hstack((model.W, gaussW))\n",
    "            model.b = np.hstack((model.b, gaussB))\n",
    "        elif(gauss==2):  # sporcariaper far funzionare LWF\n",
    "            model.W = np.hstack((model.W, np.zeros([model.width,1])))\n",
    "            model.b = np.hstack((model.b, np.zeros([1])))\n",
    "            \n",
    "                   \n",
    "        print(f'    Now W is -> {model.W.shape}              and b is -> {model.b.shape}\\n\\n')\n",
    "\n",
    "        y_true_soft = lettToSoft(y_true, model.label)\n",
    "                \n",
    "    return y_true_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneEpoch_OL(model, x, y_true, learn_rate):\n",
    "    \n",
    "    print('**********************************\\nPerforming training with OL METHOD - STOCHASTICH\\n')\n",
    "   \n",
    "    cntr=1\n",
    "    tot_samples = x.shape[0]\n",
    "    \n",
    "    y_true_soft = lettToSoft(y_true, model.label)  # Transform the true label letters in softmax\n",
    "        \n",
    "    # Cycle over all samples\n",
    "    for i in range(0, tot_samples):\n",
    "        \n",
    "        y_true_soft = checkNewClass(model, y_true, y_true_soft, i, 0)   # Check if letter is new\n",
    "        \n",
    "        # PPREDICTION\n",
    "        y_ML = model.ML_frozen.predict(x[i,:].reshape(1,x.shape[1]))\n",
    "        y_pred = model.predict(y_ML[0,:])        \n",
    "          \n",
    "        # BACKPROPAGATION\n",
    "        cost = y_pred-y_true_soft[i,:]\n",
    "\n",
    "        for j in range(0,model.W.shape[0]):\n",
    "            # Update weights\n",
    "            deltaW = np.multiply(cost, y_ML[0,j])\n",
    "            dW = np.multiply(deltaW, learn_rate)\n",
    "            model.W[j,:] = model.W[j,:]-dW\n",
    "\n",
    "        # Update biases\n",
    "        db = np.multiply(cost, learn_rate)\n",
    "        model.b = model.b-db\n",
    "        \n",
    "        print(f\"\\r    Currently at {np.round(np.round(cntr/x.shape[0],4)*100,2)}% of dataset\", end=\"\")\n",
    "        cntr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneEpoch_OL_miniBatch(model, x, y_true, learn_rate, batch_size):\n",
    "    \n",
    "    print('**********************************\\nPerforming training with OL METHOD - MINI BATCH\\n')\n",
    "    \n",
    "    cntr=1\n",
    "    tot_samples = x.shape[0]\n",
    "    sum_gradW = np.zeros([model.W.shape[0], 8])\n",
    "    sum_gradB = np.zeros([1, 8])\n",
    "    \n",
    "    y_true_soft = lettToSoft(y_true, model.label)     # Transform the true label letters in softmax array\n",
    "        \n",
    "    # Cycle over all samples\n",
    "    for i in range(0, tot_samples):\n",
    "        \n",
    "        y_true_soft = checkNewClass(model, y_true, y_true_soft, i, 0)   # Check if letter is new\n",
    "        \n",
    "        h = model.W.shape[0]\n",
    "        w = model.W.shape[1]\n",
    "        \n",
    "        if(i%batch_size==0):\n",
    "                model.W = model.W - np.multiply(sum_gradW, 1/batch_size*learn_rate)[:h,:w]\n",
    "                model.b = model.b - np.multiply(sum_gradB, 1/batch_size*learn_rate)[0,:w]\n",
    "\n",
    "                sum_gradW = np.zeros([h, 8])  #reset each batch  \n",
    "                sum_gradB = np.zeros([1, 8])  #reset each batch   \n",
    "        \n",
    "        # PREDICTION\n",
    "        y_ML = model.ML_frozen.predict(x[i,:].reshape(1,x.shape[1]))\n",
    "        y_pred = model.predict(y_ML[0,:])\n",
    "\n",
    "        # BACKPROPAGATION\n",
    "        cost = y_pred-y_true_soft[i,:]\n",
    "\n",
    "        for j in range(0,h): \n",
    "            # Update weights\n",
    "            tmp = np.multiply(cost, y_ML[0,j]) \n",
    "            deltaW = np.zeros([1,8])\n",
    "            deltaW[0,:w] = tmp  \n",
    "            sum_gradW[j,:] += deltaW[0,:]\n",
    "\n",
    "        # Update biases\n",
    "        deltaB = np.zeros([1,8])\n",
    "        deltaB[0,:w] = cost\n",
    "        sum_gradB += deltaB\n",
    "\n",
    "        # If last iteration\n",
    "        if(i==tot_samples-1):\n",
    "            model.W = model.W - np.multiply(sum_gradW, 1/batch_size*learn_rate)[:h,:w]\n",
    "            model.b = model.b - np.multiply(sum_gradB, 1/batch_size*learn_rate)[0,:w]\n",
    "        \n",
    "        print(f\"\\r    Currently at {np.round(np.round(cntr/x.shape[0],4)*100,2)}% of dataset\", end=\"\")\n",
    "        cntr +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def trainOneEpoch_OL_v2(model, x, y_true, learn_rate):\n",
    "    \n",
    "    print('**********************************\\nPerforming training with CWR METHOD - STOCASTICH \\n')\n",
    "    \n",
    "    cntr=1\n",
    "    tot_samples = x.shape[0]\n",
    "    \n",
    "    y_true_soft = lettToSoft(y_true, model.label)    # Transform the true label letters in softmax\n",
    "            \n",
    "    # Cycle over every sample\n",
    "    for i in range(0, tot_samples):\n",
    "        y_true_soft = checkNewClass(model, y_true, y_true_soft, i, 1)    # Check if letter is new\n",
    "        \n",
    "        # PREDICTION\n",
    "        y_ML = model.ML_frozen.predict(x[i,:].reshape(1,x.shape[1]))\n",
    "        y_pred = model.predict(y_ML[0,:])\n",
    "\n",
    "        # BACKPROPAGATION\n",
    "        cost = y_pred-y_true_soft[i,:]  \n",
    "\n",
    "        for j in range(0,model.W.shape[0]):\n",
    "            # Update weights\n",
    "            deltaW = np.multiply(cost, y_ML[0,j])\n",
    "            dW = np.multiply(deltaW, learn_rate)\n",
    "            model.W[j,5:] = model.W[j,5:]-dW[5:]\n",
    "\n",
    "        # Update biases\n",
    "        db = np.multiply(cost, learn_rate)\n",
    "        model.b[5:] = model.b[5:]-db[5:]\n",
    "        \n",
    "        print(f\"\\r    Currently at {np.round(np.round(cntr/x.shape[0],4)*100,2)}% of dataset\", end=\"\")\n",
    "        cntr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneEpoch_OL_v2_miniBatch(model, x, y_true, learn_rate, batch_size):\n",
    "    \n",
    "    print('**********************************\\nPerforming training with CWR - MINI BATCH \\n ')  \n",
    "\n",
    "    cntr=1\n",
    "    tot_samples = x.shape[0]\n",
    "    sum_gradW = np.zeros([model.W.shape[0], 8])\n",
    "    sum_gradB = np.zeros([1, 8])\n",
    "    \n",
    "    # Transform the true label letters in softmax array\n",
    "    y_true_soft = lettToSoft(y_true, model.label)\n",
    "           \n",
    "    # Cycle over all input samples\n",
    "    for i in range(0, tot_samples):\n",
    "        \n",
    "        y_true_soft = checkNewClass(model, y_true, y_true_soft, i, 0) # Check if letter is new\n",
    "        \n",
    "        h = model.W.shape[0]\n",
    "        w = model.W.shape[1]\n",
    "        \n",
    "        # If beginning of batch\n",
    "        if(i%batch_size==0):\n",
    "                model.W[:,5:] = model.W[:,5:] - np.multiply(sum_gradW, 1/batch_size*learn_rate)[:h,5:w]\n",
    "                model.b[5:]   = model.b[5:]   - np.multiply(sum_gradB, 1/batch_size*learn_rate)[0,5:w]\n",
    "                sum_gradW = np.zeros([h, 8])  # reset\n",
    "                sum_gradB = np.zeros([1, 8])  # reset\n",
    "            \n",
    "        # PREDICTION\n",
    "        y_ML = model.ML_frozen.predict(x[i,:].reshape(1,x.shape[1]))\n",
    "        y_pred = model.predict(y_ML[0,:])\n",
    "\n",
    "        # BACKPROPAGATION\n",
    "        cost = y_pred-y_true_soft[i,:]\n",
    "\n",
    "        for j in range(0,h):  \n",
    "            # Update weights\n",
    "            tmp = np.multiply(cost, y_ML[0,j]) \n",
    "            deltaW = np.zeros([1,8])\n",
    "            deltaW[0,:tmp.shape[0]] = tmp  \n",
    "            sum_gradW[j,:] += deltaW[0,:]\n",
    "\n",
    "        # Update biases\n",
    "        deltaB = np.zeros([1,8])\n",
    "        deltaB[0,:cost.shape[0]] = cost\n",
    "        sum_gradB += deltaB\n",
    "\n",
    "        # If last iteration\n",
    "        if(i==tot_samples-1):\n",
    "            model.W[:,5:] = model.W[:,5:] - np.multiply(sum_gradW, 1/batch_size*learn_rate)[:h,5:w]\n",
    "            model.b[5:]   = model.b[5:]   - np.multiply(sum_gradB, 1/batch_size*learn_rate)[0,5:w]\n",
    "        \n",
    "        print(f\"\\r    Currently at {np.round(np.round(cntr/x.shape[0],4)*100,2)}% of dataset\", end=\"\")\n",
    "        cntr +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneEpochOL_LWF(model, x, y_true, learn_rate):\n",
    "    \n",
    "    print('**********************************')\n",
    "    print('Performing training with OL METHOD - LWF')\n",
    "    print()\n",
    "    \n",
    "    lam  = 0\n",
    "    cntr = 1\n",
    "    tot_samples = x.shape[0]\n",
    "    y_LWF = np.zeros([tot_samples, 8])    # Define container for LWF\n",
    "\n",
    "    # Perform nitial prediciton for LWF\n",
    "    print('   Performing prediction of all dataset')\n",
    "    for u in range(0, x.shape[0]):\n",
    "        y_ML = model.ML_frozen.predict(x[u,:].reshape(1,x.shape[1]))\n",
    "        y_LWF[u,:5] = model.predict(y_ML[0,:])\n",
    "    \n",
    "    \n",
    "    y_true_soft = lettToSoft(y_true, model.label)    # Transform the true label letters in softmax\n",
    "         \n",
    "    # Cycle over every sample\n",
    "    for i in range(0, tot_samples):\n",
    "        \n",
    "        y_true_soft = checkNewClass(model, y_true, y_true_soft, i, 2)   # Check if letter is new\n",
    "        \n",
    "        w = model.W.shape[1]\n",
    "        h = model.W.shape[0]\n",
    "        if(w==6):\n",
    "            lam = 2/3\n",
    "        elif(w==7):\n",
    "            lam = 3/4\n",
    "        elif(w==8):\n",
    "            lam = 4/5\n",
    "            \n",
    "             \n",
    "        # PREDICTION\n",
    "        y_ML = model.ML_frozen.predict(x[i,:].reshape(1,x.shape[1]))\n",
    "        y_pred = model.predict(y_ML[0,:])\n",
    "      \n",
    "        \n",
    "        # BACKPROPAGATION        \n",
    "        cost_norm = y_pred-y_true_soft[i,:]\n",
    "        cost_LWF  = y_pred-y_LWF[i,:w]\n",
    "\n",
    "        for j in range(0,h):\n",
    "            # Update weights\n",
    "            deltaW_norm = np.multiply(cost_norm,1-lam)\n",
    "            deltaW_LWF  = np.multiply(cost_LWF, lam)\n",
    "            deltaW      = np.multiply(deltaW_norm+deltaW_LWF, y_ML[0,j])\n",
    "            dW          = np.multiply(deltaW, learn_rate)\n",
    "\n",
    "            model.W[j,:] = model.W[j,:]-dW\n",
    "\n",
    "            # Update biases\n",
    "            db_norm = np.multiply(cost_norm, 1-lam)\n",
    "            db_LWF  = np.multiply(cost_LWF, lam)\n",
    "            db      = np.multiply(db_norm+db_LWF, learn_rate)\n",
    "            model.b = model.b-db\n",
    "        \n",
    "        print(f\"\\r    Currently at {np.round(np.round(cntr/x.shape[0],4)*100,2)}% of dataset\", end=\"\")\n",
    "        cntr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneEpochOL_LWF_v2(model, x, y_true, learn_rate, batch_size):\n",
    "    \n",
    "    print('**********************************\\nPerforming training with OL METHOD - LWF with MINI BATCH\\n')\n",
    "    \n",
    "    lam  = 0\n",
    "    cntr = 1\n",
    "    tot_samples = x.shape[0]\n",
    "    # Transform the true label letters in softmax array\n",
    "    y_true_soft = lettToSoft(y_true, model.label)\n",
    "        \n",
    "        \n",
    "    # Initialize now and then reset it once every batch_size\n",
    "    sum_gradW = np.zeros([model.W.shape[0], 8])\n",
    "    sum_gradB = np.zeros([1, 8])\n",
    "    \n",
    "    # Define a matrix that I can then fill with the initial inference\n",
    "    y_LWF = np.zeros([ x.shape[0], 8])\n",
    "    \n",
    "    # For every sample in the dataset given\n",
    "    for i in range(0, tot_samples):\n",
    "        \n",
    "        \n",
    "        # Check if letter is new\n",
    "        y_true_soft = checkNewClass(model, y_true, y_true_soft, i, 0)\n",
    "        \n",
    "        h = model.W.shape[0]\n",
    "        w = model.W.shape[1]\n",
    "        if(w==6):\n",
    "            lam = 2/3\n",
    "        elif(w==7):\n",
    "            lam = 3/4\n",
    "        elif(w==8):\n",
    "            lam = 4/5\n",
    "        \n",
    "        # Reset the matrices that keep track of the summation of gradient\n",
    "        if(i%batch_size==0):\n",
    "                model.W = model.W - np.multiply(sum_gradW, 1/batch_size*learn_rate)[:h, :w]\n",
    "                model.b = model.b - np.multiply(sum_gradB, 1/batch_size*learn_rate)[0,:w]\n",
    "            \n",
    "                sum_gradW = np.zeros([h, 8])\n",
    "                sum_gradB = np.zeros([1, 8])\n",
    "                \n",
    "                # Value that avoids the last prediction of LWF to be outside of dataset dimension\n",
    "                limit = 0\n",
    "                if(i+batch_size > tot_samples):\n",
    "                    limit = i+batch_size-tot_samples\n",
    "                    \n",
    "                \n",
    "                for k in range(0, batch_size-limit):\n",
    "                    # Prediction from ML frozen model\n",
    "                    y_ML = model.ML_frozen.predict(x[i+k,:].reshape(1,x.shape[1]))\n",
    "                    # Prediction from LWF \n",
    "                    y_LWF[k,:w] = model.predict(y_ML[0,:])\n",
    "      \n",
    "        # Prediction from ML frozen model\n",
    "        y_ML = model.ML_frozen.predict(x[i,:].reshape(1,x.shape[1]))\n",
    "        # Prediction from TinyOL layer\n",
    "        y_pred = model.predict(y_ML[0,:])\n",
    "         \n",
    "        # ---- BACKPROPAGATION | MINI BATCH + LWF\n",
    "        cost_norm = y_pred-y_true_soft[i,:]\n",
    "        cost_LWF  = y_pred-y_LWF[i,:w]\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range(0,h):  # da 0 a 300\n",
    "\n",
    "            # Update weights\n",
    "            tmp_norm     = np.multiply(cost_norm, 1-lam)\n",
    "            tmp_LWF      = np.multiply(cost_LWF,  lam)\n",
    "            if(len(tmp_LWF)>5):\n",
    "                tmp_LWF[5] = 0\n",
    "            elif(len(tmp_LWF)>6):\n",
    "                tmp_LWF[6] = 0\n",
    "            elif(len(tmp_LWF)>7):\n",
    "                tmp_LWF[7] = 0\n",
    "            tmp_tot      = np.multiply(tmp_norm+tmp_LWF, y_ML[0,j])\n",
    "            deltaW       = deltaW = np.zeros([1,8])\n",
    "            deltaW[0,:w] = tmp_tot \n",
    "            \n",
    "            sum_gradW[j,:] += deltaW[0,:]            \n",
    "            \n",
    "\n",
    "\n",
    "            # Update biases\n",
    "            db_norm = np.multiply(cost_norm, 1-lam)\n",
    "            db_LWF  = np.multiply(cost_LWF,  lam)    \n",
    "            deltaB = np.zeros([1,8])\n",
    "            deltaB[0,:w] = db_norm+db_LWF\n",
    "            \n",
    "            sum_gradB += deltaB\n",
    "            \n",
    "        # if is last iteration , update the matrix\n",
    "        if(i==tot_samples-1):\n",
    "            model.W = model.W - np.multiply(sum_gradW, 1/batch_size*learn_rate)[:h, :w]\n",
    "            model.b = model.b - np.multiply(sum_gradB, 1/batch_size*learn_rate)[0,:w]\n",
    "        \n",
    "        print(f\"\\r    Currently at {np.round(np.round(cntr/x.shape[0],4)*100,2)}% of dataset\", end=\"\")\n",
    "        cntr +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneEpoch_CWR(model, x, y_true, learn_rate, batch_size):\n",
    "        \n",
    "    print('**********************************\\nPerforming training CWR \\n ')  \n",
    "\n",
    "    cntr=1\n",
    "    tot_samples = x.shape[0]\n",
    "    TW = np.zeros([model.W.shape[0], 8])\n",
    "    TB = np.zeros([1, 8])\n",
    "    found_lett = np.zeros([1,8])\n",
    "    \n",
    "    y_true_soft = lettToSoft(y_true, model.label)    # Transform the true label letters in softmax array\n",
    "           \n",
    "    # Cycle over all input samples\n",
    "    for i in range(0, tot_samples):\n",
    "        \n",
    "        y_true_soft = checkNewClass(model, y_true, y_true_soft, i, 0) # Check if letter is new\n",
    "        \n",
    "        h = model.W.shape[0]\n",
    "        w = model.W.shape[1]\n",
    "        \n",
    "        dummy = 0\n",
    "        \n",
    "        # If beginning of batch\n",
    "        if(i%batch_size==0 and i!=0): \n",
    "            for k in range(0, w):\n",
    "                if(found_lett[0,k]==0):\n",
    "                    dummy = 0\n",
    "                    #model.W[:,k] = np.copy(TW[:,k])\n",
    "                    #model.b[k]   = np.copy(TB[0,k])\n",
    "                else:\n",
    "                    tempW = np.multiply(model.W[:,k], found_lett[0,k])\n",
    "                    tempB = np.multiply(model.b[k], found_lett[0,k])\n",
    "                    model.W[:,k] = np.multiply(tempW+TW[:,k], 1/(found_lett[0,k]+1))\n",
    "                    model.b[k]   = np.multiply(tempB+TB[0,k], 1/(found_lett[0,k]+1))\n",
    "                    \n",
    "            TW[:h,:w] = model.W\n",
    "            TB[0,:w] = model.b\n",
    "            found_lett = np.zeros([1,8])  # reset\n",
    "        elif(i==0):\n",
    "            TW = np.zeros([h, 8])   # reset  \n",
    "            TB = np.zeros([1, 8])   # reset     \n",
    "                \n",
    "        found_lett[0,np.argmax(y_true_soft[i,:])] += 1  # update the letter counter\n",
    "            \n",
    "        # PREDICTION ON THE MATRIX TW AND TB\n",
    "        y_ML = model.ML_frozen.predict(x[i,:].reshape(1,x.shape[1]))\n",
    "        y_pred = tf.nn.softmax(np.matmul(y_ML, TW) + TB)\n",
    "\n",
    "        # BACKPROPAGATION\n",
    "        cost = y_pred[0,:w]-y_true_soft[i,:]\n",
    "\n",
    "        for j in range(0,h):  # da 0 a 300\n",
    "            deltaW = np.multiply(cost, y_ML[0,j])\n",
    "            dW = np.multiply(deltaW, learn_rate)\n",
    "            TW[j,:w] = TW[j,:w] - dW\n",
    "\n",
    "        # Update biases\n",
    "        db = np.multiply(cost, learn_rate)\n",
    "        TB[0,:w] = TB[0,:w]-db\n",
    "\n",
    "        # If last iteration\n",
    "        if(i==tot_samples-1):\n",
    "            for k in range(5, w):\n",
    "                if(found_lett[0,k]==0):\n",
    "                    dummy = 0\n",
    "                    #model.W[:,k] = np.copy(TW[:,k])\n",
    "                    #model.b[k]   = np.copy(TB[0,k])\n",
    "                else:\n",
    "                    tempW = np.multiply(model.W[:,k], found_lett[0,k])\n",
    "                    tempB = np.multiply(model.b[k], found_lett[0,k])\n",
    "                    model.W[:,k] = np.multiply(tempW+TW[:,k], 1/(found_lett[0,k]+1))\n",
    "                    model.b[k]   = np.multiply(tempB+TB[0,k], 1/(found_lett[0,k]+1))\n",
    "        \n",
    "        print(f\"\\r    Currently at {np.round(np.round(cntr/x.shape[0],4)*100,2)}% of dataset\", end=\"\")\n",
    "        cntr +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ML model (cut model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 128)               76928     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 300)               38700     \n",
      "=================================================================\n",
      "Total params: 115,628\n",
      "Trainable params: 115,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ML_model = keras.models.Sequential(model.layers[:-1])\n",
    "ML_model.summary()\n",
    "ML_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_CUT_PATH = \"C:/Users/massi/UNI/Magistrale/Anno 5/Semestre 2/Tesi/Code/Python/Saved_models/Frozen_model/\"\n",
    "ML_model.save(SAVE_MODEL_CUT_PATH + \"model.h5\")\n",
    "saveParams(SAVE_MODEL_CUT_PATH, ML_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "learn_rate = 0.001\n",
    "lam = 0.4\n",
    "batch_size_new = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE WHICH TRAINING AND PLOTS TO SHOW\n",
    "\n",
    "KERAS      = 1\n",
    "OL_vowels  = 0\n",
    "OL         = 0\n",
    "OL_mini    = 0\n",
    "LWF        = 0\n",
    "LWF_mini   = 0\n",
    "OL_v2      = 0\n",
    "OL_v2_mini = 0\n",
    "CWR        = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with OL only on vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(OL_vowels==1):\n",
    "    Model_OL_vowels = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpoch_OL(Model_OL_vowels, OL_data_train_vow, OL_label_train_vow, learn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with OL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(OL==1):\n",
    "    Model_OL_all_mixed = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpoch_OL(Model_OL_all_mixed, mixed_data_all, mixed_label_all, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with OL + mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(OL_mini==1):\n",
    "    Model_OL_mini = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpoch_OL_miniBatch(Model_OL_mini, mixed_data_all, mixed_label_all, 0.001, batch_size_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(LWF==1):\n",
    "    Model_LWF_1 = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpochOL_LWF(Model_LWF_1, mixed_data_all, mixed_label_all, learn_rate)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LWF + mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(LWF_mini==1):\n",
    "    Model_LWF_2 = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpochOL_LWF_v2(Model_LWF_2, mixed_data_all, mixed_label_all, learn_rate, batch_size_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with OL v2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(OL_v2==1):\n",
    "    Model_OL_v2 = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpoch_OL_v2(Model_OL_v2, mixed_data_all, mixed_label_all, learn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with OL v2 + mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(OL_v2_mini==1):\n",
    "    Model_OL_v2_miniBatch = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpoch_OL_v2_miniBatch(Model_OL_v2_miniBatch, mixed_data_all, mixed_label_all, learn_rate, batch_size_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with CWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "Performing training CWR \n",
      " \n",
      "    Currently at 100.0% of dataset"
     ]
    }
   ],
   "source": [
    "if(CWR==1):\n",
    "    Model_CWR = Custom_Layer(model)\n",
    "    for i in range(0, num_epochs):\n",
    "        trainOneEpoch_CWR(Model_CWR, OL_data_train_vow, OL_label_train_vow, 0.00005, 10)\n",
    "        # GOOD l rate 0.00005  - batch size 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMULATION PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(KERAS==1):\n",
    "    res00, res01, res02 = myPlotT.testOL_v2(model, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res00, res01, res02, 'KERAS', 'origModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(OL_vowels==1):\n",
    "    res10, res11, res12 = myPlotT.testOL(Model_OL_vowels, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res10, res11, res12, 'VOWELS', 'trainVowels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(OL==1):\n",
    "    res20, res21, res22 = myPlotT.testOL(Model_OL_all_mixed, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res20, res21, res22, 'OL', 'trainOL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL + mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(OL_mini==1):\n",
    "    res30, res31, res32 = myPlotT.testOL(Model_OL_mini, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res30, res31, res32, 'OL + mini batch', 'trainOL_mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(LWF==1):\n",
    "    res40, res41, res42 = myPlotT.testOL(Model_LWF_1, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res40, res41, res42, 'LWF', 'trainLWF_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LWF + mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(LWF_mini==1):\n",
    "    res50, res51, res52 = myPlotT.testOL(Model_LWF_2, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res50, res51, res52, 'LWF + mini batch', 'trainLWF_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(OL_v2==1):\n",
    "    res60, res61, res62 = myPlotT.testOL(Model_OL_v2, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res60, res61, res62, 'OL v2', 'trainOL_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OL v2 + mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(OL_v2_mini==1):\n",
    "    res70, res71, res72 = myPlotT.testOL(Model_OL_v2_miniBatch, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res70, res71, res72, 'OL v2 + mini batch', 'trainOL_v2_mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(CWR==1):\n",
    "    res80, res81, res82 = myPlotT.testOL(Model_CWR, OL_testing_data)\n",
    "    myPlotT.plotTestOL(res80, res81, res82, 'CWR', 'trainCWR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myPlotT.plotAllTEst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this simulation the best trained model is:\n",
      "ORIG:         21.3\n",
      "CWR: 21.3\n"
     ]
    }
   ],
   "source": [
    "print('In this simulation the best trained model is:')\n",
    "print(f'ORIG:         {round(np.sum(res00)/np.sum(res02),4)*100}')\n",
    "if(OL_vowels==1):\n",
    "    print(f'VOWELS:       {round(np.sum(res10)/np.sum(res12),4)*100}')\n",
    "if(OL==1):\n",
    "    print(f'OL:           {round(np.sum(res20)/np.sum(res22),4)*100}')\n",
    "if(OL_mini==1):\n",
    "    print(f'OL + mini:    {round(np.sum(res30)/np.sum(res32),4)*100}')\n",
    "if(LWF==1):\n",
    "    print(f'LWF:          {round(np.sum(res40)/np.sum(res42),4)*100}')\n",
    "if(LWF_mini==1):\n",
    "    print(f'LWF + mini:   {round(np.sum(res50)/np.sum(res52),4)*100}')\n",
    "if(OL_v2==1):\n",
    "    print(f'OL v2:        {round(np.sum(res60)/np.sum(res62),4)*100}')\n",
    "if(OL_v2_mini==1):\n",
    "    print(f'OL v2 + mini: {round(np.sum(res70)/np.sum(res72),4)*100}')\n",
    "if(CWR==1):\n",
    "    print(f'CWR: {round(np.sum(res80)/np.sum(res82),4)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down in txt files all the results across 10 or so simulations          \n",
    "WRITE_SIMU_RES = 0\n",
    "                \n",
    "if(WRITE_SIMU_RES==1):\n",
    "    myWrite.writeSimuRes('orig',      res00, res01, res02)\n",
    "    myWrite.writeSimuRes('vowels',    res10, res11, res12)\n",
    "    myWrite.writeSimuRes('OL',        res20, res21, res22)\n",
    "    myWrite.writeSimuRes('OL_mini',   res30, res31, res32)\n",
    "    myWrite.writeSimuRes('LWF',       res40, res41, res42)\n",
    "    myWrite.writeSimuRes('LWF_mini',  res50, res51, res52)\n",
    "    myWrite.writeSimuRes('OL_v2',     res60, res61, res62)\n",
    "    myWrite.writeSimuRes('OL_v2_min', res70, res71, res72)\n",
    "    myWrite.writeSimuRes('CWR',       res80, res81, res82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for orig is: 22.51\n",
      "Average accuracy for vowels is: 17.39\n",
      "Average accuracy for OL is: 71.43\n",
      "Average accuracy for OL_mini is: 72.84\n",
      "Average accuracy for LWF is: 30.43\n",
      "Average accuracy for LWF_mini is: 37.11\n",
      "Average accuracy for OL_v2 is: 72.92\n",
      "Average accuracy for OL_v2_min is: 74.11\n",
      "Average accuracy for CWR is: 76.98\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ENABLE_PLOTS = 0\n",
    "myPlotD.plotSimuRes(1)\n",
    "if(ENABLE_PLOTS==1):\n",
    "\n",
    "\n",
    "\n",
    "    myPlotD.plotDatasetStructure(TF_data_train,TF_data_test,\n",
    "                                 OL_data_train_vow,OL_data_test_vow,\n",
    "                                 B_train_data,B_test_data,\n",
    "                                 R_train_data,R_test_data,\n",
    "                                 M_train_data,M_test_data)\n",
    "\n",
    "    myPlotD.plotDatasetOL(OL_data_train_vow,OL_data_test_vow,\n",
    "                          B_train_data,B_test_data,\n",
    "                          R_train_data,R_test_data,\n",
    "                          M_train_data,M_test_data)\n",
    "\n",
    "    myPlotD.plotDatasetTF(TF_data_train,TF_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts for generating libraries for the STM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_STM_FILES = 0\n",
    "\n",
    "if(WRITE_STM_FILES==1):\n",
    "    myWrite.writeSampleB()\n",
    "    myWrite.writeSampleMix()\n",
    "    myWrite.writeSampleVowels()\n",
    "    \n",
    "myWrite.writeLastLayer(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
