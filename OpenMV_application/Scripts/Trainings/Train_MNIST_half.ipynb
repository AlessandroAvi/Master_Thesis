{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8g3_OkUNOuD"
   },
   "source": [
    "## **Import the TensorFlow library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKk-D3IZkkbE"
   },
   "source": [
    "This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to eb applied on the OpenMV camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1674,
     "status": "ok",
     "timestamp": 1636125291944,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XCqcQuaBLNgF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8C9aeAMdSE"
   },
   "source": [
    "Load MNIST dataset and split in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1636125292418,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mNfeJ2bbNDET",
    "outputId": "606983b1-3cb4-47dc-cd7f-2594067c9536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset shapes are\n",
      "    Train dataset shape: (60000, 28, 28)\n",
      "    Test dataset shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "print('The original dataset shapes are')\n",
    "print(f'    Train dataset shape: {data_train.shape}')\n",
    "print(f'    Test dataset shape:  {data_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaAIs1HlrltM"
   },
   "source": [
    "Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1636125293501,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wjQCPI7FTr2H",
    "outputId": "ef9f907e-5961-4f6a-e438-b894251c263c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:\n",
      "     Train dataset lower than 6 has shape:  (36017, 28, 28)\n",
      "     Train dataset higher than 6 has shape: (23983, 28, 28)\n",
      "\n",
      "     Test dataset lower than 6 has shape:  (6031, 28, 28)\n",
      "     Test dataset higher than 6 has shape: (3969, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_samples = label_train.shape[0]\n",
    "test_samples  = label_test.shape[0]\n",
    "\n",
    "trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n",
    "testLow_samples = np.sum(np.where(label_test <  6, 1, 0))\n",
    "\n",
    "# separate in containers data that is lower nad higer than 6\n",
    "data_low_train   = np.zeros([trainLow_samples,28,28])\n",
    "label_low_train  = np.zeros(trainLow_samples)\n",
    "data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n",
    "label_high_train = np.zeros(train_samples-trainLow_samples)\n",
    "\n",
    "data_low_test   = np.zeros([testLow_samples,28,28])\n",
    "label_low_test  = np.zeros(testLow_samples)\n",
    "data_high_test  = np.zeros([test_samples-testLow_samples,28,28])\n",
    "label_high_test = np.zeros(test_samples-testLow_samples)\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,train_samples):  \n",
    "    if(label_train[i]<6):\n",
    "        data_low_train[j,:,:] = data_train[i,:,:]\n",
    "        label_low_train[j]    = label_train[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_train[k,:,:] = data_train[i,:,:]\n",
    "        label_high_train[k]    = label_train[i]\n",
    "        k+=1\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,test_samples):  \n",
    "    if(label_test[i]<6):\n",
    "        data_low_test[j,:,:] = data_test[i,:,:]\n",
    "        label_low_test[j]    = label_test[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_test[k,:,:] = data_test[i,:,:]\n",
    "        label_high_test[k]    = label_test[i]\n",
    "        k+=1\n",
    "\n",
    "print('After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:')\n",
    "print(f'     Train dataset lower than 6 has shape:  {data_low_train.shape}')\n",
    "print(f'     Train dataset higher than 6 has shape: {data_high_train.shape}')\n",
    "print()\n",
    "print(f'     Test dataset lower than 6 has shape:  {data_low_test.shape}')\n",
    "print(f'     Test dataset higher than 6 has shape: {data_high_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1636125293502,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "bgVHZlEqqBr7",
    "outputId": "28486df0-9dfe-4765-d6f3-99f928d59445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly check if dataset that I created are filled correctly\n",
    "num = int(random.uniform(0,trainLow_samples))\n",
    "plt.imshow(data_low_train[num], cmap=\"gray\") # Import the image\n",
    "print(label_low_train[num])\n",
    "plt.show() # Plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTx7YrtENh3F"
   },
   "source": [
    "## **Pre process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "lU_tKzkCse1H"
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "c2TsbEYpU-p2"
   },
   "outputs": [],
   "source": [
    "# Something I don't know\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293504,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "eE5Ju7QbRDBF"
   },
   "outputs": [],
   "source": [
    "data_low_train  = data_low_train.astype(np.float32) / 255.0\n",
    "data_high_train = data_high_train.astype(np.float32) / 255.0\n",
    "data_low_test   = data_low_test.astype(np.float32) / 255.0\n",
    "data_high_test  = data_high_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNaCD_O0RPDs"
   },
   "source": [
    "## **Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "epochs     = 30\n",
    "optimizer  = \"adam\"\n",
    "loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics    = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1636125294415,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "8pfF6SCiRUjB"
   },
   "outputs": [],
   "source": [
    "# METHOD 1\n",
    "# Define the model architecture\n",
    "#model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "#    tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(6, activation = \"softmax\")\n",
    "#])\n",
    "\n",
    "#model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 8118      \n",
      "=================================================================\n",
      "Total params: 8,198\n",
      "Trainable params: 8,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "executionInfo": {
     "elapsed": 1293,
     "status": "error",
     "timestamp": 1636125295704,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZRk1oPJmTCM2",
    "outputId": "ddc8832c-c895-4dc8-ffcf-7a119c04dfce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "541/541 [==============================] - 2s 5ms/step - loss: 1.1787 - accuracy: 0.9015 - val_loss: 1.0958 - val_accuracy: 0.9545\n",
      "Epoch 2/30\n",
      "541/541 [==============================] - 2s 4ms/step - loss: 1.1007 - accuracy: 0.9475 - val_loss: 1.0890 - val_accuracy: 0.9584\n",
      "Epoch 3/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0933 - accuracy: 0.9531 - val_loss: 1.0857 - val_accuracy: 0.9586\n",
      "Epoch 4/30\n",
      "541/541 [==============================] - 2s 4ms/step - loss: 1.0879 - accuracy: 0.9584 - val_loss: 1.0828 - val_accuracy: 0.9631\n",
      "Epoch 5/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0846 - accuracy: 0.9609 - val_loss: 1.0814 - val_accuracy: 0.9628\n",
      "Epoch 6/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0807 - accuracy: 0.9650 - val_loss: 1.0760 - val_accuracy: 0.9695\n",
      "Epoch 7/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0782 - accuracy: 0.9677 - val_loss: 1.0746 - val_accuracy: 0.9695\n",
      "Epoch 8/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0758 - accuracy: 0.9704 - val_loss: 1.0725 - val_accuracy: 0.9717\n",
      "Epoch 9/30\n",
      "541/541 [==============================] - 2s 5ms/step - loss: 1.0733 - accuracy: 0.9728 - val_loss: 1.0723 - val_accuracy: 0.9725\n",
      "Epoch 10/30\n",
      "541/541 [==============================] - 2s 5ms/step - loss: 1.0713 - accuracy: 0.9754 - val_loss: 1.0740 - val_accuracy: 0.9728\n",
      "Epoch 11/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0702 - accuracy: 0.9758 - val_loss: 1.0694 - val_accuracy: 0.9761\n",
      "Epoch 12/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0683 - accuracy: 0.9782 - val_loss: 1.0672 - val_accuracy: 0.9781\n",
      "Epoch 13/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0667 - accuracy: 0.9799 - val_loss: 1.0651 - val_accuracy: 0.9803\n",
      "Epoch 14/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0651 - accuracy: 0.9816 - val_loss: 1.0644 - val_accuracy: 0.9803\n",
      "Epoch 15/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0631 - accuracy: 0.9828 - val_loss: 1.0642 - val_accuracy: 0.9808\n",
      "Epoch 16/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0619 - accuracy: 0.9841 - val_loss: 1.0608 - val_accuracy: 0.9850\n",
      "Epoch 17/30\n",
      "541/541 [==============================] - 2s 5ms/step - loss: 1.0604 - accuracy: 0.9859 - val_loss: 1.0601 - val_accuracy: 0.9850\n",
      "Epoch 18/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0594 - accuracy: 0.9867 - val_loss: 1.0593 - val_accuracy: 0.9856\n",
      "Epoch 19/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0581 - accuracy: 0.9877 - val_loss: 1.0594 - val_accuracy: 0.9872\n",
      "Epoch 20/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0571 - accuracy: 0.9885 - val_loss: 1.0593 - val_accuracy: 0.9858\n",
      "Epoch 21/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0563 - accuracy: 0.9893 - val_loss: 1.0576 - val_accuracy: 0.9881\n",
      "Epoch 22/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0553 - accuracy: 0.9905 - val_loss: 1.0585 - val_accuracy: 0.9861\n",
      "Epoch 23/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0547 - accuracy: 0.9908 - val_loss: 1.0565 - val_accuracy: 0.9889\n",
      "Epoch 24/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0541 - accuracy: 0.9914 - val_loss: 1.0573 - val_accuracy: 0.9875\n",
      "Epoch 25/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0534 - accuracy: 0.9920 - val_loss: 1.0573 - val_accuracy: 0.9872\n",
      "Epoch 26/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0530 - accuracy: 0.9928 - val_loss: 1.0557 - val_accuracy: 0.9892\n",
      "Epoch 27/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0524 - accuracy: 0.9928 - val_loss: 1.0558 - val_accuracy: 0.9892\n",
      "Epoch 28/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0521 - accuracy: 0.9932 - val_loss: 1.0556 - val_accuracy: 0.9886\n",
      "Epoch 29/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0516 - accuracy: 0.9937 - val_loss: 1.0557 - val_accuracy: 0.9886\n",
      "Epoch 30/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0512 - accuracy: 0.9938 - val_loss: 1.0563 - val_accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20682fe0b20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data_low_train,\n",
    "    label_low_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "aborted",
     "timestamp": 1636125295698,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mq9bBd-3pfgL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0537 - accuracy: 0.9909\n",
      "\n",
      "Test accuracy: 0.9908804297447205\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI3aR1l4pqhS"
   },
   "source": [
    "# **Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295699,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "piwc0fbspvlc"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(data_low_test)   # Make prediction of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y9R_XtjSrO2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  2\n",
      "True label =  2.0\n"
     ]
    }
   ],
   "source": [
    "num = int(random.uniform(0,data_low_test.shape[0]))\n",
    "print(\"Prediction = \" , np.argmax(predictions[num]))\n",
    "print(\"True label = \" , label_low_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "2Uj_jf6-jCGj"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    class_names = ['0','1','2','3','4','5']\n",
    "\n",
    "    true_label, img = int(true_label[i]), img[i,:,:]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = (np.squeeze(img))## you have to delete the channel information (if grayscale) to plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)   \n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(6))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "_L_MP6pejCGk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = int(random.uniform(0, predictions.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plot_image(num, predictions[num], label_low_test, data_low_test)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plot_value_array(num, predictions[num], label_low_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye7xyl_-vkkk"
   },
   "source": [
    "## **Save models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_model(model, MODEL_PATH, flag):\n",
    "    new_file = open(MODEL_PATH + 'model_summary.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    if(flag==0):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the ORIGINAL MODEL\")\n",
    "    elif(flag==1):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the FROZEN MODEL\")\n",
    "    new_file.write(\"\\n\")\n",
    "    new_file.write(\"\\n Batch size:       \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs:           \" + str(epochs))\n",
    "    new_file.write(\"\\n Metrics:          \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer:        \" + optimizer)\n",
    "    new_file.write(\"\\n Loss:             \" + \"SparseCategoricalCrossentropy \\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "rjFdtesdvqzf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0537110567092896\n",
      "Test accuracy: 0.9908804297447205\n",
      "Save ORIGINAL MODEL as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath('')\n",
    "SAVE_MODEL_PATH = ROOT_PATH + \"\\\\Saved_models\\\\\"\n",
    "\n",
    "ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Original_model\\\\\"\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Save ORIGINAL MODEL as mnist_cnn.h5')\n",
    "model.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model, ORIGINAL_MODEL_PATH, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1352)              0         \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save FROZEN MODEL model as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE THE FROZEN MODEL\n",
    "frozen_model = keras.models.Sequential(model.layers[:-1])\n",
    "frozen_model.summary()\n",
    "frozen_model.compile()\n",
    "\n",
    "FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_model\\\\\"\n",
    "\n",
    "print('Save FROZEN MODEL model as mnist_cnn.h5')\n",
    "frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(frozen_model, FROZEN_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the last layer weights is: (1352, 6)\n",
      "The shape of the last layer biases is: (6,)\n"
     ]
    }
   ],
   "source": [
    "ll_weights = np.array(model.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jSSceEYKsHX"
   },
   "source": [
    "## **Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1Txju54d6yY"
   },
   "source": [
    "**Full integer quantization**\n",
    "\n",
    "For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. As a result, the converter requires a representative dataset to calibrate them. This dataset can be a small subset (around ~100-500 samples) of the training or validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "C1VewrfEKpwW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpe8nwzfy1\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_io = converter.convert()\n",
    "with open(\"mnist_quant_io.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkJY45mABi6w"
   },
   "source": [
    "**Integer with float fallback (using default float input/output)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "-KhP_3Y8NK6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpgsonowyk\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpgsonowyk\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "with open(\"mnist_quant.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Qpda9DBIvsaK"
   },
   "outputs": [],
   "source": [
    "#representative_data_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TEST SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "temp_num = int(random.uniform(0,100))\n",
    "temp_data = data_test[5:100,:,:]\n",
    "print(temp_data.shape)\n",
    "temp_label = label_test[temp_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-18.37033119   8.01741843  -6.42371742  -8.42573955  -5.47698429\n",
      "  -9.13887387]\n",
      "[-18.370333    8.017419   -6.4237175  -8.425738   -5.476986   -9.138874 ]\n"
     ]
    }
   ],
   "source": [
    "# prediction with frozen model+ OL layer\n",
    "my_result  = np.zeros(6)\n",
    "my_result2 = np.zeros(6)\n",
    "my_forzen_out = frozen_model.predict(data_low_test)\n",
    "my_forzen_out = my_forzen_out[temp_num]\n",
    "\n",
    "\n",
    "my_result = np.array(np.matmul(my_forzen_out, ll_weights) + ll_biases)\n",
    "\n",
    "\n",
    "for i in range(0,6):\n",
    "    for j in range(0,ll_weights.shape[0]):\n",
    "        my_result2[i] += ll_weights[j,i]*my_forzen_out[j]\n",
    "    my_result2[i] += ll_biases[i]\n",
    "    \n",
    "print(my_result2)\n",
    "print(my_result)\n",
    "\n",
    "    \n",
    "    \n",
    "my_soft = np.zeros(6)\n",
    "m       = my_result[0]\n",
    "sum_val = 0\n",
    "\n",
    "for i in range(0, 6):\n",
    "    if(m<my_result[i]):\n",
    "        m = my_result[i]\n",
    "\n",
    "for i in range(0, 6):\n",
    "    sum_val += np.exp(my_result[i] - m)\n",
    "\n",
    "constant = m + np.log(sum_val)\n",
    "for i in range(0, 6):\n",
    "    my_soft[i] = np.exp(my_result[i] - constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(my_soft))\n",
    "print(np.argmax(predictions[temp_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.46692320e-12 9.99997979e-01 5.34925484e-07 7.22481427e-08\n",
      " 1.37864860e-06 3.54091726e-08]\n",
      "[3.4669331e-12 9.9999797e-01 5.3492602e-07 7.2248000e-08 1.3786524e-06\n",
      " 3.5409208e-08]\n"
     ]
    }
   ],
   "source": [
    "print(my_soft)\n",
    "print(predictions[temp_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0278425\n",
      "-0.0278425\n"
     ]
    }
   ],
   "source": [
    "print(ll_weights[2025,2])\n",
    "print(np.array(model.layers[-1].get_weights()[0])[2025,2])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mnist_half.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
