{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8g3_OkUNOuD"
   },
   "source": [
    "## **Import the TensorFlow library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKk-D3IZkkbE"
   },
   "source": [
    "This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to eb applied on the OpenMV camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1674,
     "status": "ok",
     "timestamp": 1636125291944,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XCqcQuaBLNgF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8C9aeAMdSE"
   },
   "source": [
    "Load MNIST dataset and split in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1636125292418,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mNfeJ2bbNDET",
    "outputId": "606983b1-3cb4-47dc-cd7f-2594067c9536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset shapes are\n",
      "    Train dataset shape: (60000, 28, 28)\n",
      "    Test dataset shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "print('The original dataset shapes are')\n",
    "print(f'    Train dataset shape: {data_train.shape}')\n",
    "print(f'    Test dataset shape:  {data_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaAIs1HlrltM"
   },
   "source": [
    "Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1636125293501,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wjQCPI7FTr2H",
    "outputId": "ef9f907e-5961-4f6a-e438-b894251c263c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:\n",
      "     Train dataset lower than 6 has shape:  (36017, 28, 28)\n",
      "     Train dataset higher than 6 has shape: (23983, 28, 28)\n",
      "\n",
      "     Test dataset lower than 6 has shape:  (6031, 28, 28)\n",
      "     Test dataset higher than 6 has shape: (3969, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_samples = label_train.shape[0]\n",
    "test_samples  = label_test.shape[0]\n",
    "\n",
    "trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n",
    "testLow_samples = np.sum(np.where(label_test <  6, 1, 0))\n",
    "\n",
    "# separate in containers data that is lower nad higer than 6\n",
    "data_low_train   = np.zeros([trainLow_samples,28,28])\n",
    "label_low_train  = np.zeros(trainLow_samples)\n",
    "data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n",
    "label_high_train = np.zeros(train_samples-trainLow_samples)\n",
    "\n",
    "data_low_test   = np.zeros([testLow_samples,28,28])\n",
    "label_low_test  = np.zeros(testLow_samples)\n",
    "data_high_test  = np.zeros([test_samples-testLow_samples,28,28])\n",
    "label_high_test = np.zeros(test_samples-testLow_samples)\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,train_samples):  \n",
    "    if(label_train[i]<6):\n",
    "        data_low_train[j,:,:] = data_train[i,:,:]\n",
    "        label_low_train[j]    = label_train[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_train[k,:,:] = data_train[i,:,:]\n",
    "        label_high_train[k]    = label_train[i]\n",
    "        k+=1\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,test_samples):  \n",
    "    if(label_test[i]<6):\n",
    "        data_low_test[j,:,:] = data_test[i,:,:]\n",
    "        label_low_test[j]    = label_test[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_test[k,:,:] = data_test[i,:,:]\n",
    "        label_high_test[k]    = label_test[i]\n",
    "        k+=1\n",
    "\n",
    "print('After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:')\n",
    "print(f'     Train dataset lower than 6 has shape:  {data_low_train.shape}')\n",
    "print(f'     Train dataset higher than 6 has shape: {data_high_train.shape}')\n",
    "print()\n",
    "print(f'     Test dataset lower than 6 has shape:  {data_low_test.shape}')\n",
    "print(f'     Test dataset higher than 6 has shape: {data_high_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1636125293502,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "bgVHZlEqqBr7",
    "outputId": "28486df0-9dfe-4765-d6f3-99f928d59445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly check if dataset that I created are filled correctly\n",
    "num = int(random.uniform(0,trainLow_samples))\n",
    "plt.imshow(data_low_train[num], cmap=\"gray\") # Import the image\n",
    "print(label_low_train[num])\n",
    "plt.show() # Plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTx7YrtENh3F"
   },
   "source": [
    "## **Pre process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "lU_tKzkCse1H"
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "c2TsbEYpU-p2"
   },
   "outputs": [],
   "source": [
    "# Something I don't know\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293504,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "eE5Ju7QbRDBF"
   },
   "outputs": [],
   "source": [
    "data_low_train  = data_low_train.astype(np.float32) / 255.0\n",
    "data_high_train = data_high_train.astype(np.float32) / 255.0\n",
    "data_low_test   = data_low_test.astype(np.float32) / 255.0\n",
    "data_high_test  = data_high_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNaCD_O0RPDs"
   },
   "source": [
    "## **Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "epochs     = 30\n",
    "optimizer  = \"adam\"\n",
    "loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics    = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1636125294415,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "8pfF6SCiRUjB"
   },
   "outputs": [],
   "source": [
    "# METHOD 1\n",
    "# Define the model architecture\n",
    "#model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "#    tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(6, activation = \"softmax\")\n",
    "#])\n",
    "\n",
    "#model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=12, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12174     \n",
      "=================================================================\n",
      "Total params: 12,294\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "executionInfo": {
     "elapsed": 1293,
     "status": "error",
     "timestamp": 1636125295704,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZRk1oPJmTCM2",
    "outputId": "ddc8832c-c895-4dc8-ffcf-7a119c04dfce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.1694 - accuracy: 0.9054 - val_loss: 1.0881 - val_accuracy: 0.9611\n",
      "Epoch 2/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0829 - accuracy: 0.9654 - val_loss: 1.0684 - val_accuracy: 0.9789\n",
      "Epoch 3/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0709 - accuracy: 0.9763 - val_loss: 1.0628 - val_accuracy: 0.9839\n",
      "Epoch 4/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0648 - accuracy: 0.9821 - val_loss: 1.0609 - val_accuracy: 0.9850\n",
      "Epoch 5/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0615 - accuracy: 0.9850 - val_loss: 1.0584 - val_accuracy: 0.9870\n",
      "Epoch 6/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0593 - accuracy: 0.9873 - val_loss: 1.0573 - val_accuracy: 0.9872\n",
      "Epoch 7/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0575 - accuracy: 0.9886 - val_loss: 1.0576 - val_accuracy: 0.9872\n",
      "Epoch 8/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0563 - accuracy: 0.9895 - val_loss: 1.0558 - val_accuracy: 0.9892\n",
      "Epoch 9/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0554 - accuracy: 0.9899 - val_loss: 1.0558 - val_accuracy: 0.9892\n",
      "Epoch 10/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0541 - accuracy: 0.9915 - val_loss: 1.0565 - val_accuracy: 0.9886\n",
      "Epoch 11/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0535 - accuracy: 0.9920 - val_loss: 1.0552 - val_accuracy: 0.9892\n",
      "Epoch 12/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0529 - accuracy: 0.9927 - val_loss: 1.0554 - val_accuracy: 0.9892\n",
      "Epoch 13/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0522 - accuracy: 0.9930 - val_loss: 1.0545 - val_accuracy: 0.9897\n",
      "Epoch 14/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0516 - accuracy: 0.9937 - val_loss: 1.0544 - val_accuracy: 0.9908\n",
      "Epoch 15/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0512 - accuracy: 0.9940 - val_loss: 1.0543 - val_accuracy: 0.9895\n",
      "Epoch 16/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0506 - accuracy: 0.9943 - val_loss: 1.0540 - val_accuracy: 0.9906\n",
      "Epoch 17/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0503 - accuracy: 0.9948 - val_loss: 1.0542 - val_accuracy: 0.9895\n",
      "Epoch 18/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0498 - accuracy: 0.9951 - val_loss: 1.0534 - val_accuracy: 0.9911\n",
      "Epoch 19/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0496 - accuracy: 0.9953 - val_loss: 1.0534 - val_accuracy: 0.9908\n",
      "Epoch 20/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0493 - accuracy: 0.9955 - val_loss: 1.0543 - val_accuracy: 0.9900\n",
      "Epoch 21/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0491 - accuracy: 0.9957 - val_loss: 1.0534 - val_accuracy: 0.9906\n",
      "Epoch 22/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0486 - accuracy: 0.9959 - val_loss: 1.0543 - val_accuracy: 0.9897\n",
      "Epoch 23/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0484 - accuracy: 0.9962 - val_loss: 1.0535 - val_accuracy: 0.9908\n",
      "Epoch 24/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0484 - accuracy: 0.9961 - val_loss: 1.0539 - val_accuracy: 0.9900\n",
      "Epoch 25/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0481 - accuracy: 0.9965 - val_loss: 1.0528 - val_accuracy: 0.9911\n",
      "Epoch 26/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0479 - accuracy: 0.9965 - val_loss: 1.0533 - val_accuracy: 0.9903\n",
      "Epoch 27/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0478 - accuracy: 0.9967 - val_loss: 1.0533 - val_accuracy: 0.9908\n",
      "Epoch 28/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0474 - accuracy: 0.9970 - val_loss: 1.0544 - val_accuracy: 0.9897\n",
      "Epoch 29/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0474 - accuracy: 0.9969 - val_loss: 1.0531 - val_accuracy: 0.9906\n",
      "Epoch 30/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0473 - accuracy: 0.9970 - val_loss: 1.0530 - val_accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2148121e7f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data_low_train,\n",
    "    label_low_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "aborted",
     "timestamp": 1636125295698,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mq9bBd-3pfgL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 1ms/step - loss: 1.0509 - accuracy: 0.9937\n",
      "\n",
      "Test accuracy: 0.9936991930007935\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI3aR1l4pqhS"
   },
   "source": [
    "# **Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295699,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "piwc0fbspvlc"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(data_low_test)   # Make prediction of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y9R_XtjSrO2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  0\n",
      "True label =  0.0\n"
     ]
    }
   ],
   "source": [
    "num = int(random.uniform(0,data_low_test.shape[0]))\n",
    "print(\"Prediction = \" , np.argmax(predictions[num]))\n",
    "print(\"True label = \" , label_low_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "2Uj_jf6-jCGj"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    class_names = ['0','1','2','3','4','5']\n",
    "\n",
    "    true_label, img = int(true_label[i]), img[i,:,:]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = (np.squeeze(img))## you have to delete the channel information (if grayscale) to plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)   \n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(6))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "_L_MP6pejCGk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = int(random.uniform(0, predictions.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plot_image(num, predictions[num], label_low_test, data_low_test)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plot_value_array(num, predictions[num], label_low_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye7xyl_-vkkk"
   },
   "source": [
    "## **Save models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_model(model, MODEL_PATH, flag):\n",
    "    new_file = open(MODEL_PATH + 'model_summary.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    if(flag==0):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the ORIGINAL MODEL\")\n",
    "    elif(flag==1):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the FROZEN MODEL\")\n",
    "    new_file.write(\"\\n\")\n",
    "    new_file.write(\"\\n Batch size:       \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs:           \" + str(epochs))\n",
    "    new_file.write(\"\\n Metrics:          \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer:        \" + optimizer)\n",
    "    new_file.write(\"\\n Loss:             \" + \"SparseCategoricalCrossentropy \\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "rjFdtesdvqzf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0508843660354614\n",
      "Test accuracy: 0.9936991930007935\n",
      "Save ORIGINAL MODEL as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath('')\n",
    "SAVE_MODEL_PATH = ROOT_PATH + \"\\\\Saved_models\\\\\"\n",
    "\n",
    "ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Original_model\\\\\"\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Save ORIGINAL MODEL as mnist_cnn.h5')\n",
    "model.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model, ORIGINAL_MODEL_PATH, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save FROZEN MODEL model as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE THE FROZEN MODEL\n",
    "frozen_model = keras.models.Sequential(model.layers[:-1])\n",
    "frozen_model.summary()\n",
    "frozen_model.compile()\n",
    "\n",
    "FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_model\\\\\"\n",
    "\n",
    "print('Save FROZEN MODEL model as mnist_cnn.h5')\n",
    "frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(frozen_model, FROZEN_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the last layer weights is: (2028, 6)\n",
      "The shape of the last layer biases is: (6,)\n"
     ]
    }
   ],
   "source": [
    "ll_weights = np.array(model.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jSSceEYKsHX"
   },
   "source": [
    "## **Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1Txju54d6yY"
   },
   "source": [
    "**Full integer quantization**\n",
    "\n",
    "For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. As a result, the converter requires a representative dataset to calibrate them. This dataset can be a small subset (around ~100-500 samples) of the training or validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "C1VewrfEKpwW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpsjw2ujqa\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_io = converter.convert()\n",
    "with open(\"mnist_quant_io.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkJY45mABi6w"
   },
   "source": [
    "**Integer with float fallback (using default float input/output)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "-KhP_3Y8NK6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpve4fb298\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpve4fb298\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "with open(\"mnist_quant.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Qpda9DBIvsaK"
   },
   "outputs": [],
   "source": [
    "#representative_data_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TEST SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "temp_num = int(random.uniform(0,100))\n",
    "temp_data = data_test[5:100,:,:]\n",
    "print(temp_data.shape)\n",
    "temp_label = label_test[temp_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-18.37033119   8.01741843  -6.42371742  -8.42573955  -5.47698429\n",
      "  -9.13887387]\n",
      "[-18.370333    8.017419   -6.4237175  -8.425738   -5.476986   -9.138874 ]\n"
     ]
    }
   ],
   "source": [
    "# prediction with frozen model+ OL layer\n",
    "my_result  = np.zeros(6)\n",
    "my_result2 = np.zeros(6)\n",
    "my_forzen_out = frozen_model.predict(data_low_test)\n",
    "my_forzen_out = my_forzen_out[temp_num]\n",
    "\n",
    "\n",
    "my_result = np.array(np.matmul(my_forzen_out, ll_weights) + ll_biases)\n",
    "\n",
    "\n",
    "for i in range(0,6):\n",
    "    for j in range(0,ll_weights.shape[0]):\n",
    "        my_result2[i] += ll_weights[j,i]*my_forzen_out[j]\n",
    "    my_result2[i] += ll_biases[i]\n",
    "    \n",
    "print(my_result2)\n",
    "print(my_result)\n",
    "\n",
    "    \n",
    "    \n",
    "my_soft = np.zeros(6)\n",
    "m       = my_result[0]\n",
    "sum_val = 0\n",
    "\n",
    "for i in range(0, 6):\n",
    "    if(m<my_result[i]):\n",
    "        m = my_result[i]\n",
    "\n",
    "for i in range(0, 6):\n",
    "    sum_val += np.exp(my_result[i] - m)\n",
    "\n",
    "constant = m + np.log(sum_val)\n",
    "for i in range(0, 6):\n",
    "    my_soft[i] = np.exp(my_result[i] - constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(my_soft))\n",
    "print(np.argmax(predictions[temp_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.46692320e-12 9.99997979e-01 5.34925484e-07 7.22481427e-08\n",
      " 1.37864860e-06 3.54091726e-08]\n",
      "[3.4669331e-12 9.9999797e-01 5.3492602e-07 7.2248000e-08 1.3786524e-06\n",
      " 3.5409208e-08]\n"
     ]
    }
   ],
   "source": [
    "print(my_soft)\n",
    "print(predictions[temp_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0278425\n",
      "-0.0278425\n"
     ]
    }
   ],
   "source": [
    "print(ll_weights[2025,2])\n",
    "print(np.array(model.layers[-1].get_weights()[0])[2025,2])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mnist_half.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
