{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8g3_OkUNOuD"
   },
   "source": [
    "## **Import the TensorFlow library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKk-D3IZkkbE"
   },
   "source": [
    "This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to eb applied on the OpenMV camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3311,
     "status": "ok",
     "timestamp": 1642669899172,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XCqcQuaBLNgF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv \n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8C9aeAMdSE"
   },
   "source": [
    "Load MNIST dataset and split in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1642669899176,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mNfeJ2bbNDET",
    "outputId": "48aa2ce4-cace-4979-af5d-d0db989bf648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset shapes are\n",
      "    Train dataset shape: (60000, 28, 28)\n",
      "    Test dataset shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "print('The original dataset shapes are')\n",
    "print(f'    Train dataset shape: {data_train.shape}')\n",
    "print(f'    Test dataset shape:  {data_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1642669899179,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "IyjJkzGxpxDf",
    "outputId": "99156193-19bb-4c47-c384-8991f7e82241"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaAIs1HlrltM"
   },
   "source": [
    "Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1642669900033,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wjQCPI7FTr2H",
    "outputId": "2472a0c4-13f7-4810-b622-437141c61dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:\n",
      "     Train dataset lower than 6 has shape:  (36017, 28, 28)\n",
      "     Train dataset higher than 6 has shape: (23983, 28, 28)\n",
      "\n",
      "     Test dataset lower than 6 has shape:  (6031, 28, 28)\n",
      "     Test dataset higher than 6 has shape: (3969, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_samples = label_train.shape[0]\n",
    "test_samples  = label_test.shape[0]\n",
    "\n",
    "trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n",
    "testLow_samples = np.sum(np.where(label_test <  6, 1, 0))\n",
    "\n",
    "# separate in containers data that is lower nad higer than 6\n",
    "data_low_train   = np.zeros([trainLow_samples,28,28])\n",
    "label_low_train  = np.zeros(trainLow_samples)\n",
    "data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n",
    "label_high_train = np.zeros(train_samples-trainLow_samples)\n",
    "\n",
    "data_low_test   = np.zeros([testLow_samples,28,28])\n",
    "label_low_test  = np.zeros(testLow_samples)\n",
    "data_high_test  = np.zeros([test_samples-testLow_samples,28,28])\n",
    "label_high_test = np.zeros(test_samples-testLow_samples)\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,train_samples):  \n",
    "    if(label_train[i]<6):\n",
    "        data_low_train[j,:,:] = data_train[i,:,:]\n",
    "        label_low_train[j]    = label_train[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_train[k,:,:] = data_train[i,:,:]\n",
    "        label_high_train[k]    = label_train[i]\n",
    "        k+=1\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,test_samples):  \n",
    "    if(label_test[i]<6):\n",
    "        data_low_test[j,:,:] = data_test[i,:,:]\n",
    "        label_low_test[j]    = label_test[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_test[k,:,:] = data_test[i,:,:]\n",
    "        label_high_test[k]    = label_test[i]\n",
    "        k+=1\n",
    "\n",
    "print('After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:')\n",
    "print(f'     Train dataset lower than 6 has shape:  {data_low_train.shape}')\n",
    "print(f'     Train dataset higher than 6 has shape: {data_high_train.shape}')\n",
    "print()\n",
    "print(f'     Test dataset lower than 6 has shape:  {data_low_test.shape}')\n",
    "print(f'     Test dataset higher than 6 has shape: {data_high_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1642669900037,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "bgVHZlEqqBr7",
    "outputId": "bcad13ec-918c-4cad-c1b7-fb8a8a298161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly check if dataset that I created are filled correctly\n",
    "num = int(random.uniform(0,trainLow_samples))\n",
    "plt.imshow(data_low_train[num], cmap=\"gray\") # Import the image\n",
    "print(label_low_train[num])\n",
    "plt.show() # Plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTx7YrtENh3F"
   },
   "source": [
    "## **Pre process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1642669900041,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "lU_tKzkCse1H"
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1642669900044,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "c2TsbEYpU-p2"
   },
   "outputs": [],
   "source": [
    "# Something I don't know\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_low_train  = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_low_test   = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_test  = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape     = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_low_train  = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_low_test   = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_test  = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape     = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NZNND6XFXFw"
   },
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1642669900796,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "eE5Ju7QbRDBF"
   },
   "outputs": [],
   "source": [
    "data_low_train  = data_low_train.astype(np.float32) / 255.0\n",
    "data_high_train = data_high_train.astype(np.float32) / 255.0\n",
    "data_low_test   = data_low_test.astype(np.float32) / 255.0\n",
    "data_high_test  = data_high_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNaCD_O0RPDs"
   },
   "source": [
    "## **BUILD THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1642669900799,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "dewlaeUUlFpw"
   },
   "outputs": [],
   "source": [
    "TRAIN_MODEL_1 = True\n",
    "TRAIN_MODEL_2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1642669900801,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "VkSwp6sOFXF6"
   },
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "epochs     = 30\n",
    "validation_split = 0.1\n",
    "optimizer  = \"adam\"\n",
    "loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics    = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1642669901174,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "vZVNdEatp8L2",
    "outputId": "699d1a6b-5a3d-48ff-9af3-6ce3fc0dfbc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 8)         4616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 31,758\n",
      "Trainable params: 31,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(8,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1642669901176,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Cige2fQHFXGB"
   },
   "outputs": [],
   "source": [
    "# METHOD 2\n",
    "# This model is a bit larger and should be much more precise in the feature extraction\n",
    "if(TRAIN_MODEL_2):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, (3, 3), input_shape = input_shape))\n",
    "    model2.add(Conv2D(32, (3, 3), activation = \"relu\"))\n",
    "    model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(128, activation = \"relu\"))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "    model2.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_3CoNfUFXGE"
   },
   "source": [
    "## TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144034,
     "status": "ok",
     "timestamp": 1642670045191,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZRk1oPJmTCM2",
    "outputId": "b430d7c3-48c9-411c-d362-2e1d61802dfc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.1533 - accuracy: 0.8990 - val_loss: 1.0610 - val_accuracy: 0.9831\n",
      "Epoch 2/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0698 - accuracy: 0.9752 - val_loss: 1.0558 - val_accuracy: 0.9881\n",
      "Epoch 3/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0637 - accuracy: 0.9805 - val_loss: 1.0532 - val_accuracy: 0.9908\n",
      "Epoch 4/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0597 - accuracy: 0.9842 - val_loss: 1.0526 - val_accuracy: 0.9914\n",
      "Epoch 5/30\n",
      "541/541 [==============================] - 17s 32ms/step - loss: 1.0593 - accuracy: 0.9850 - val_loss: 1.0529 - val_accuracy: 0.9914\n",
      "Epoch 6/30\n",
      "541/541 [==============================] - 17s 32ms/step - loss: 1.0576 - accuracy: 0.9865 - val_loss: 1.0526 - val_accuracy: 0.9911\n",
      "Epoch 7/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0558 - accuracy: 0.9880 - val_loss: 1.0538 - val_accuracy: 0.9900\n",
      "Epoch 8/30\n",
      "541/541 [==============================] - 17s 32ms/step - loss: 1.0558 - accuracy: 0.9884 - val_loss: 1.0522 - val_accuracy: 0.9917\n",
      "Epoch 9/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0544 - accuracy: 0.9894 - val_loss: 1.0516 - val_accuracy: 0.9922\n",
      "Epoch 10/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0542 - accuracy: 0.9894 - val_loss: 1.0512 - val_accuracy: 0.9922\n",
      "Epoch 11/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0532 - accuracy: 0.9907 - val_loss: 1.0505 - val_accuracy: 0.9928\n",
      "Epoch 12/30\n",
      "541/541 [==============================] - 17s 32ms/step - loss: 1.0527 - accuracy: 0.9913 - val_loss: 1.0497 - val_accuracy: 0.9939\n",
      "Epoch 13/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0534 - accuracy: 0.9903 - val_loss: 1.0522 - val_accuracy: 0.9911\n",
      "Epoch 14/30\n",
      "541/541 [==============================] - 17s 32ms/step - loss: 1.0527 - accuracy: 0.9909 - val_loss: 1.0513 - val_accuracy: 0.9919\n",
      "Epoch 15/30\n",
      "541/541 [==============================] - 18s 33ms/step - loss: 1.0518 - accuracy: 0.9917 - val_loss: 1.0510 - val_accuracy: 0.9922\n",
      "Epoch 16/30\n",
      "541/541 [==============================] - 18s 34ms/step - loss: 1.0522 - accuracy: 0.9913 - val_loss: 1.0510 - val_accuracy: 0.9928\n",
      "Epoch 17/30\n",
      "541/541 [==============================] - 18s 33ms/step - loss: 1.0525 - accuracy: 0.9911 - val_loss: 1.0515 - val_accuracy: 0.9919\n",
      "Epoch 18/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0509 - accuracy: 0.9928 - val_loss: 1.0497 - val_accuracy: 0.9939\n",
      "Epoch 19/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0507 - accuracy: 0.9929 - val_loss: 1.0489 - val_accuracy: 0.9950\n",
      "Epoch 20/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0502 - accuracy: 0.9934 - val_loss: 1.0492 - val_accuracy: 0.9944\n",
      "Epoch 21/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0507 - accuracy: 0.9928 - val_loss: 1.0483 - val_accuracy: 0.9953\n",
      "Epoch 22/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0499 - accuracy: 0.9937 - val_loss: 1.0485 - val_accuracy: 0.9953\n",
      "Epoch 23/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0501 - accuracy: 0.9934 - val_loss: 1.0483 - val_accuracy: 0.9953\n",
      "Epoch 24/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0500 - accuracy: 0.9937 - val_loss: 1.0507 - val_accuracy: 0.9928\n",
      "Epoch 25/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0504 - accuracy: 0.9932 - val_loss: 1.0484 - val_accuracy: 0.9950\n",
      "Epoch 26/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0492 - accuracy: 0.9944 - val_loss: 1.0483 - val_accuracy: 0.9956\n",
      "Epoch 27/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0496 - accuracy: 0.9941 - val_loss: 1.0493 - val_accuracy: 0.9939\n",
      "Epoch 28/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0499 - accuracy: 0.9936 - val_loss: 1.0486 - val_accuracy: 0.9950\n",
      "Epoch 29/30\n",
      "541/541 [==============================] - 17s 32ms/step - loss: 1.0497 - accuracy: 0.9938 - val_loss: 1.0498 - val_accuracy: 0.9936\n",
      "Epoch 30/30\n",
      "541/541 [==============================] - 17s 31ms/step - loss: 1.0498 - accuracy: 0.9938 - val_loss: 1.0489 - val_accuracy: 0.9950\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 1.0477 - accuracy: 0.9960\n",
      "\n",
      "Test accuracy: 0.9960205554962158\n"
     ]
    }
   ],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model.fit(data_low_train, label_low_train, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n",
    "\n",
    "  # Evaluate the model performance\n",
    "    test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n",
    "\n",
    "  print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1642670045193,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "h_oS2hh3FXGO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_2):\n",
    "\n",
    "    labels_prova = keras.utils.to_categorical(label_low_train, 6)\n",
    "\n",
    "    model2.fit(data_low_train, labels_prova, epochs = epochs, batch_size = batch_size, validation_split = validation_split )\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    test_loss, test_acc = model2.evaluate(data_low_test, keras.utils.to_categorical(label_low_test, 6))\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI3aR1l4pqhS"
   },
   "source": [
    "## TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1642670045194,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "AVNdx-gjlhze"
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model_test = model\n",
    "elif(TRAIN_MODEL_2):\n",
    "    model_test = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1642670045883,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "piwc0fbspvlc"
   },
   "outputs": [],
   "source": [
    "predictions = model_test.predict(data_low_test)   # Make prediction of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1642670045885,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y9R_XtjSrO2g",
    "outputId": "38a3a49f-7a7b-40b9-dc06-1d191479e0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  1\n",
      "True label =  1.0\n"
     ]
    }
   ],
   "source": [
    "num = int(random.uniform(0,data_low_test.shape[0]))\n",
    "print(\"Prediction = \" , np.argmax(predictions[num]))\n",
    "print(\"True label = \" , label_low_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1642670045887,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "2Uj_jf6-jCGj"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    class_names = ['0','1','2','3','4','5']\n",
    "\n",
    "    true_label, img = int(true_label[i]), img[i,:,:]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = (np.squeeze(img))## you have to delete the channel information (if grayscale) to plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)   \n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(6))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1642670045888,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "_L_MP6pejCGk",
    "outputId": "d173a92a-dab6-46ac-9f8d-05edbb8b5b7e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = int(random.uniform(0, predictions.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plot_image(num, predictions[num], label_low_test, data_low_test)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plot_value_array(num, predictions[num], label_low_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye7xyl_-vkkk"
   },
   "source": [
    "## **SAVE ORIGINAL MODEL AND FROZEN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1642670045890,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ADvJBmeEFXGf"
   },
   "outputs": [],
   "source": [
    "def save_summary_model(model, MODEL_PATH, flag):\n",
    "    new_file = open(MODEL_PATH + 'model_summary.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    if(flag==0):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the ORIGINAL MODEL\")\n",
    "    elif(flag==1):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the FROZEN MODEL\")\n",
    "    new_file.write(\"\\n\")\n",
    "    new_file.write(\"\\n Batch size:       \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs:           \" + str(epochs))\n",
    "    new_file.write(\"\\n Metrics:          \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer:        \" + optimizer)\n",
    "    new_file.write(\"\\n Loss:             \" + \"SparseCategoricalCrossentropy \\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1642670046245,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "rjFdtesdvqzf",
    "outputId": "273832e4-7e4a-4008-ef73-0a1e9c15a38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0477176904678345\n",
      "Test accuracy: 0.9960205554962158\n",
      "Save ORIGINAL MODEL as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath('')\n",
    "SAVE_MODEL_PATH = ROOT_PATH + \"\\\\Backup_models\\\\Last_trained_model\"\n",
    "\n",
    "ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Original_model\\\\\" \n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Save ORIGINAL MODEL as mnist_cnn.h5')\n",
    "model.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model_test, ORIGINAL_MODEL_PATH, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nPOwtTnFXGk"
   },
   "source": [
    "Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk84TZDvyjW4"
   },
   "source": [
    "### SAVE THE FROZEN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1642670046247,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "qQzEf-OKFXGl",
    "outputId": "e17c094d-1148-44e2-b9d0-552eb712dd85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 8)         4616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               25728     \n",
      "=================================================================\n",
      "Total params: 30,984\n",
      "Trainable params: 30,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save FROZEN MODEL model as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE THE FROZEN MODEL\n",
    "frozen_model = keras.models.Sequential(model_test.layers[:-1])\n",
    "frozen_model.summary()\n",
    "frozen_model.compile()\n",
    "\n",
    "FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_model\\\\\"\n",
    "\n",
    "print('Save FROZEN MODEL model as mnist_cnn.h5')\n",
    "frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(frozen_model, FROZEN_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1wsEHInFXGn"
   },
   "source": [
    "Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1642670046248,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "NOvcRsOVFXGn",
    "outputId": "3f3446d3-a168-4256-eff5-72969162d8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the last layer weights is: (128, 6)\n",
      "The shape of the last layer biases is: (6,)\n"
     ]
    }
   ],
   "source": [
    "ll_weights = np.array(model_test.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model_test.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jSSceEYKsHX"
   },
   "source": [
    "## PRUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86fkMkzrFXGs"
   },
   "source": [
    "https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 3384,
     "status": "ok",
     "timestamp": 1642670049623,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wM4PKTiCFXGw"
   },
   "outputs": [],
   "source": [
    "# Install needed optimization toolkit\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1642670050700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "oxawOG-5FXGy",
    "outputId": "50a0d265-ca20-4fdf-9a4f-710c33b603a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:212: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 64)        1218      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 11, 11, 8)         9226      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 5, 5, 8)           1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout  (None, 5, 5, 8)           1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 200)               1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 128)               51330     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 6)                 1544      \n",
      "=================================================================\n",
      "Total params: 63,322\n",
      "Trainable params: 31,758\n",
      "Non-trainable params: 31,564\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after n epochs.\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "validation_split = 0.1  # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = data_low_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model_test, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "\n",
    "# Select appropriate optimizer\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251734,
     "status": "ok",
     "timestamp": 1642670302425,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "f8YgeDcrFXG2",
    "outputId": "6a50bfea-5684-4f5e-a633-bcd833a1491d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835A6E15E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835A6E15E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Pruning._maybe_update_block_mask of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_impl.Pruning object at 0x000002835A8CCC40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Pruning._maybe_update_block_mask of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_impl.Pruning object at 0x000002835A8CCC40>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835DE66280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835DE66280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835AB03820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835AB03820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E3DB280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E3DB280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835DE66280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835DE66280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835A36B280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835A36B280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835AB030D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835AB030D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835A36B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835A36B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E19D040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E19D040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364D85A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364D85A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E179EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E179EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364E849D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364E849D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E179F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E179F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364E84820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364E84820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E1798B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002835E1798B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364E849D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x0000028364E849D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1013 [..............................] - ETA: 0s - loss: 1.0436 - accuracy: 1.0000WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1013 [..............................] - ETA: 38s - loss: 1.0436 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0630s). Check your callbacks.\n",
      "1013/1013 [==============================] - 19s 19ms/step - loss: 1.0496 - accuracy: 0.9942 - val_loss: 1.0483 - val_accuracy: 0.9956\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013/1013 [==============================] - 18s 18ms/step - loss: 1.0491 - accuracy: 0.9948 - val_loss: 1.0492 - val_accuracy: 0.9942\n",
      "Epoch 3/20\n",
      "1013/1013 [==============================] - 18s 18ms/step - loss: 1.0492 - accuracy: 0.9946 - val_loss: 1.0494 - val_accuracy: 0.9947\n",
      "Epoch 4/20\n",
      "1013/1013 [==============================] - 19s 18ms/step - loss: 1.0492 - accuracy: 0.9945 - val_loss: 1.0490 - val_accuracy: 0.9944\n",
      "Epoch 5/20\n",
      "1013/1013 [==============================] - 21s 21ms/step - loss: 1.0483 - accuracy: 0.9956 - val_loss: 1.0488 - val_accuracy: 0.9947\n",
      "Epoch 6/20\n",
      "1013/1013 [==============================] - 30s 29ms/step - loss: 1.0489 - accuracy: 0.9949 - val_loss: 1.0488 - val_accuracy: 0.9947\n",
      "Epoch 7/20\n",
      "1013/1013 [==============================] - 23s 23ms/step - loss: 1.0491 - accuracy: 0.9949 - val_loss: 1.0492 - val_accuracy: 0.9944\n",
      "Epoch 8/20\n",
      "1013/1013 [==============================] - 22s 22ms/step - loss: 1.0486 - accuracy: 0.9954 - val_loss: 1.0488 - val_accuracy: 0.9953\n",
      "Epoch 9/20\n",
      "1013/1013 [==============================] - 24s 23ms/step - loss: 1.0489 - accuracy: 0.9949 - val_loss: 1.0487 - val_accuracy: 0.9947\n",
      "Epoch 10/20\n",
      "1013/1013 [==============================] - 20s 20ms/step - loss: 1.0481 - accuracy: 0.9961 - val_loss: 1.0486 - val_accuracy: 0.9956\n",
      "Epoch 11/20\n",
      "1013/1013 [==============================] - 22s 21ms/step - loss: 1.0487 - accuracy: 0.9954 - val_loss: 1.0486 - val_accuracy: 0.9953\n",
      "Epoch 12/20\n",
      "1013/1013 [==============================] - 22s 22ms/step - loss: 1.0490 - accuracy: 0.9951 - val_loss: 1.0481 - val_accuracy: 0.9961\n",
      "Epoch 13/20\n",
      "1013/1013 [==============================] - 22s 21ms/step - loss: 1.0485 - accuracy: 0.9956 - val_loss: 1.0486 - val_accuracy: 0.9953\n",
      "Epoch 14/20\n",
      "1013/1013 [==============================] - 22s 22ms/step - loss: 1.0486 - accuracy: 0.9954 - val_loss: 1.0491 - val_accuracy: 0.9942\n",
      "Epoch 15/20\n",
      "1013/1013 [==============================] - 22s 22ms/step - loss: 1.0484 - accuracy: 0.9956 - val_loss: 1.0477 - val_accuracy: 0.9964\n",
      "Epoch 16/20\n",
      "1013/1013 [==============================] - 22s 21ms/step - loss: 1.0479 - accuracy: 0.9960 - val_loss: 1.0474 - val_accuracy: 0.9961\n",
      "Epoch 17/20\n",
      "1013/1013 [==============================] - 24s 24ms/step - loss: 1.0478 - accuracy: 0.9961 - val_loss: 1.0480 - val_accuracy: 0.9956\n",
      "Epoch 18/20\n",
      "1013/1013 [==============================] - 22s 22ms/step - loss: 1.0480 - accuracy: 0.9960 - val_loss: 1.0485 - val_accuracy: 0.9953\n",
      "Epoch 19/20\n",
      "1013/1013 [==============================] - 24s 23ms/step - loss: 1.0474 - accuracy: 0.9963 - val_loss: 1.0489 - val_accuracy: 0.9947\n",
      "Epoch 20/20\n",
      "1013/1013 [==============================] - 23s 23ms/step - loss: 1.0474 - accuracy: 0.9964 - val_loss: 1.0474 - val_accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2835de2e880>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(data_low_train, label_low_train,\n",
    "                    batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1642670303234,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "IHJW7bkYLiOV",
    "outputId": "3c14850f-33a8-4d9c-93cb-bd08c3789463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test accuracy:  0.9960205554962158\n",
      "Pruned test accuracy:    0.9975128769874573\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(data_low_test, label_low_test, verbose=0)\n",
    "\n",
    "print('Original test accuracy: ', test_acc)\n",
    "print('Pruned test accuracy:   ', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIAK-1EJK6Z_"
   },
   "source": [
    "## CREATE A x3 SMALLER MODEL FROM PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1642670303235,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "E_MqIPRtFXG3",
    "outputId": "3fd08389-cd6e-42a4-da3d-d8127047ce17"
   },
   "outputs": [],
   "source": [
    "# First, create a compressible model for TensorFlow\n",
    "\n",
    "PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Pruned_model\\\\\"\n",
    "\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.save(PRUNED_MODEL_PATH + 'pruned.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2178,
     "status": "ok",
     "timestamp": 1642670305406,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XLBF9aRvFXG5",
    "outputId": "91b4b562-8d2f-4d13-dbd6-3563ffda612e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpyycv98t7\\assets\n"
     ]
    }
   ],
   "source": [
    "# Then, create a compressible model for TFLite\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "with open(PRUNED_MODEL_PATH + 'Pruned.tflite', 'wb') as f:\n",
    "    f.write(pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1642670305409,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "FAh4chQQMdVJ"
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1642670423546,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "oiLalXuSMSwF",
    "outputId": "e9f8d3d6-2791-4993-b4e6-f306e3a6d2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 118008.00 bytes\n",
      "Size of gzipped pruned Keras model  : 41078.00 bytes\n",
      "Size of gzipped pruned TFlite model : 39284.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n",
    "print(\"Size of gzipped pruned Keras model  : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + 'pruned.h5')))\n",
    "print(\"Size of gzipped pruned TFlite model : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + 'Pruned.tflite')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi4RUhtOPUKr"
   },
   "source": [
    "## CREATE A 10x SMALLER MODEL, COMBINE PRUNING WITH QUANTIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2209,
     "status": "ok",
     "timestamp": 1642670670389,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "X_xSV0ZePY7S",
    "outputId": "f246574c-06df-4a52-d680-cef893dfd630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmp5i6hs9b0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmp5i6hs9b0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and pruned TFLite model to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmp6118ss73.tflite\n",
      "Size of gzipped baseline Keras model             : 118008.00 bytes\n",
      "Size of gzipped pruned and quantized TFlite model: 14485.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model             : %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFG2-AhwyZsZ"
   },
   "source": [
    "## SAVE THE FROZEN MODEL VERSION OF THE PRUNED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1642670675487,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "CF1fpU3RyoPj",
    "outputId": "1dd42723-a73d-4fa1-d73b-9de69a931cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 8)         4616      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               25728     \n",
      "=================================================================\n",
      "Total params: 30,984\n",
      "Trainable params: 30,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save FROZEN PRUNED MODEL model as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "frozen_pruned_model = keras.models.Sequential(model_for_export.layers[:-1])\n",
    "frozen_pruned_model.summary()\n",
    "frozen_pruned_model.compile()\n",
    "\n",
    "FROZEN_PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_Pruned_model\\\\\"\n",
    "\n",
    "print('Save FROZEN PRUNED MODEL model as mnist_cnn.h5')\n",
    "frozen_model.save(FROZEN_PRUNED_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model_for_export, FROZEN_PRUNED_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1642670683191,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZDFF5jp6yslG",
    "outputId": "1cc4e095-5cd5-479f-c8c0-15756665f544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the last layer weights is: (128, 6)\n",
      "The shape of the last layer biases is: (6,)\n"
     ]
    }
   ],
   "source": [
    "ll_weights = np.array(model_for_export.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model_for_export.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_PRUNED_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_PRUNED_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu1ooRLcwAwb"
   },
   "source": [
    "## DOWNLOAD ENTIIRE MODEL DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1642670707129,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y6PSAT4AQCwq",
    "outputId": "eadd7971-b925-45d8-83a8-2771ec6cb6fd"
   },
   "outputs": [],
   "source": [
    "#%cd '/content'\n",
    "#from google.colab import files\n",
    "#import shutil\n",
    "#shutil.make_archive('Colab_models', 'zip', 'Models')\n",
    "#files.download('Colab_models.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd2AzXoKzc6l"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_MNIST_half.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
