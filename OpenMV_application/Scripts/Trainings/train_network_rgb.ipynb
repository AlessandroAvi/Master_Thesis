{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMXmkOruVNDQ"
   },
   "source": [
    "# **Project openmv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8gBsGnyVX79"
   },
   "source": [
    "### Enable GPUs for the notebook:\n",
    "\n",
    "    - Navigate to Edit→Notebook Settings\n",
    "    - select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "Then run following section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7155,
     "status": "ok",
     "timestamp": 1623926949892,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "Hz2QoxjGv_c-",
    "outputId": "f3c6a913-d2e0-42de-ca89-c8b1e076ebe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTLRUUP2M4y9"
   },
   "source": [
    "To see the speedup by using a GPU form Google Colab see:\n",
    "https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=oM_8ELnJq_wd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRQRlbMBFv2J"
   },
   "source": [
    "### Load image folder and insert model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18344,
     "status": "ok",
     "timestamp": 1623926971122,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "ca7lYfFIIENk",
    "outputId": "4e94630f-528f-4cd9-9c7b-f0561f7912fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHGwT9WZIF2v"
   },
   "outputs": [],
   "source": [
    "#!unzip -uq \"/content/drive/My Drive/Embedded/Project/project-openmv/DataSet_1.zip\"\n",
    "#!unzip -uq \"/content/drive/My Drive/project-openmv/DataSet_1.zip\"\n",
    "!unzip -uq \"/content/drive/My Drive/Embedded/Project/project-openmv/DataSet_2.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1r-IgxZPgmH"
   },
   "outputs": [],
   "source": [
    "# Insert directory containing the python scripts\n",
    "import sys\n",
    "sys.path.insert(0,\"/content/drive/My Drive/Embedded/Project/project-openmv/PythonCode/CNNs\")\n",
    "#sys.path.insert(0,\"/content/drive/My Drive/project-openmv/PythonCode/CNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27y0b7cvE9lD"
   },
   "source": [
    "### Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvtvl2D-Fq5L"
   },
   "outputs": [],
   "source": [
    "# Set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "#from lenet import LeNet\n",
    "#from mobilenetv2 import MobileNetV2\n",
    "#from squeezenet import SqueezeNet\n",
    "\n",
    "from lenet_prep import LeNet\n",
    "from mobilenetv2_prep import MobileNetV2\n",
    "from squeezenet_prep import SqueezeNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmPOjV08Q7PZ"
   },
   "source": [
    "### Initialize variables and create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUU1lpmLF9JT"
   },
   "outputs": [],
   "source": [
    "# Train datset path\n",
    "#tp = \"./DataSet_1/TrainSet\"\n",
    "tp = \"./DataSet_2/TrainSet\"\n",
    "\n",
    "# Initialize the number of epochs, learning rate and batch size\n",
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "# Initialize data and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2713,
     "status": "ok",
     "timestamp": 1623927190122,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "hStPa5JDGKOf",
    "outputId": "a3fbe259-9fd2-4dca-825b-dfb846e0279a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[1, 4, 0, 1, 4, 6, 4, 6, 4, 0]\n",
      "(15791, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "# Grab the image paths and randomly shuffle them\n",
    "train_paths = sorted(list(paths.list_images(tp)))\n",
    "random.seed(42)\n",
    "random.shuffle(train_paths)\n",
    "\n",
    "# Cycle over the input train images\n",
    "for train_path in train_paths:\n",
    "\n",
    "  # Load the train image, preprocess it and store in the data array\n",
    "  train_image = cv.imread(train_path) # read in rgb\n",
    "    \n",
    "  # train_image = cv.resize(train_image, (64, 64))\n",
    "  train_image = img_to_array(train_image)\n",
    "  data.append(train_image)\n",
    "\n",
    "  # Extract the class label form the train image paths\n",
    "  label = train_path.split(os.path.sep)[-2]\n",
    "\n",
    "  if label == \"Arrow0\":\n",
    "    label = 0\n",
    "  elif label == \"Arrow45\":\n",
    "    label = 1\n",
    "  elif label == \"Arrow90\":\n",
    "    label = 2\n",
    "  elif label == \"Arrow135\":\n",
    "    label = 3\n",
    "  elif label == \"Arrow180\":\n",
    "    label = 4\n",
    "  elif label == \"Arrow225\":\n",
    "    label = 5\n",
    "  elif label == \"Arrow270\":\n",
    "    label = 6\n",
    "  else:\n",
    "    label = 7\n",
    "  labels.append(label)\n",
    "print(labels[0:10])\n",
    "print(np.array(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2105,
     "status": "ok",
     "timestamp": 1623927192220,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "YhJeL5rTLAfv",
    "outputId": "72cea787-7462-475a-e05d-c1b6f9291caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15791\n",
      "15791\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "# Partition the data into training and testing splits using 75% of the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)\n",
    "print(type(np.float32(trainX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4pDxwIePEkj"
   },
   "outputs": [],
   "source": [
    "# Convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=8)\n",
    "testY = to_categorical(testY, num_classes=8)\n",
    "\n",
    "# Construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=5, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2,\n",
    "                         zoom_range=0.2,horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubSg_HPDRmOJ"
   },
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1623927192223,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "9WilqWz6PdOK",
    "outputId": "3ae5ecc8-8a8d-45d5-e937-a16c8a9ec5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling the model...\n",
      "Model: \"squeezenet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 31, 31, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 31, 31, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 15, 15, 64)   0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 15, 15, 16)   1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 15, 15, 16)   0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 15, 15, 64)   1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 15, 15, 64)   9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 15, 15, 64)   0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 15, 15, 64)   0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 15, 15, 128)  0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 7, 7, 128)    0           fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 7, 7, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 7, 7, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 7, 7, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 7, 7, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 7, 7, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 7, 7, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 7, 7, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 3, 3, 256)    0           fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 3, 3, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 3, 3, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 3, 3, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 3, 3, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 3, 3, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 3, 3, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 3, 3, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 3, 3, 64)     24640       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 3, 3, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 3, 3, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 3, 3, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 3, 3, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 3, 3, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 3, 3, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 3, 3, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 3, 3, 100)    51300       drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 3, 3, 100)    0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 100)          0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Dense)                    (None, 8)            808         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 404,524\n",
      "Trainable params: 404,524\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "import tensorflow as tf\n",
    "print(\"[INFO] compiling the model...\")\n",
    "\n",
    "### Select a model\n",
    "\n",
    "#model = LeNet.build(width=64, height=64, depth=1, classes=8)\n",
    "#model = MobileNetV2.build((64,64,1),8)\n",
    "model = SqueezeNet.build(input_shape=(64,64,3), classes=8)\n",
    "\n",
    "# Selects the appropriate optimizer\n",
    "if model.name == \"squeezenet\":\n",
    "  sgd = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "  model.compile(optimizer=sgd, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "else:\n",
    "  opt = Adam(lr=INIT_LR, decay=(INIT_LR / EPOCHS))\n",
    "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9GL-8aqUVmv"
   },
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367472,
     "status": "ok",
     "timestamp": 1623927559687,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "oC-rs3hXQDG0",
    "outputId": "a459a680-e4c6-42dd-fbaa-77e469728600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "370/370 [==============================] - 17s 42ms/step - loss: 1.9958 - accuracy: 0.1872 - val_loss: 1.9207 - val_accuracy: 0.2090\n",
      "Epoch 2/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 1.8038 - accuracy: 0.2834 - val_loss: 1.6883 - val_accuracy: 0.3663\n",
      "Epoch 3/20\n",
      "370/370 [==============================] - 16s 42ms/step - loss: 1.4571 - accuracy: 0.4485 - val_loss: 0.8269 - val_accuracy: 0.7138\n",
      "Epoch 4/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.8330 - accuracy: 0.7001 - val_loss: 0.4797 - val_accuracy: 0.8440\n",
      "Epoch 5/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.5969 - accuracy: 0.7838 - val_loss: 0.4205 - val_accuracy: 0.8422\n",
      "Epoch 6/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.4422 - accuracy: 0.8410 - val_loss: 0.2062 - val_accuracy: 0.9428\n",
      "Epoch 7/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.3464 - accuracy: 0.8821 - val_loss: 0.2373 - val_accuracy: 0.9141\n",
      "Epoch 8/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.3325 - accuracy: 0.8860 - val_loss: 0.1292 - val_accuracy: 0.9640\n",
      "Epoch 9/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.2775 - accuracy: 0.9045 - val_loss: 0.1678 - val_accuracy: 0.9400\n",
      "Epoch 10/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.2215 - accuracy: 0.9251 - val_loss: 0.0842 - val_accuracy: 0.9752\n",
      "Epoch 11/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.1956 - accuracy: 0.9339 - val_loss: 0.0823 - val_accuracy: 0.9737\n",
      "Epoch 12/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.2015 - accuracy: 0.9315 - val_loss: 0.0653 - val_accuracy: 0.9813\n",
      "Epoch 13/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.1627 - accuracy: 0.9443 - val_loss: 0.0459 - val_accuracy: 0.9896\n",
      "Epoch 14/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.1558 - accuracy: 0.9479 - val_loss: 0.0532 - val_accuracy: 0.9856\n",
      "Epoch 15/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.1614 - accuracy: 0.9465 - val_loss: 0.3972 - val_accuracy: 0.8594\n",
      "Epoch 16/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.1260 - accuracy: 0.9605 - val_loss: 0.0353 - val_accuracy: 0.9921\n",
      "Epoch 17/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.1169 - accuracy: 0.9641 - val_loss: 0.0258 - val_accuracy: 0.9942\n",
      "Epoch 18/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.1152 - accuracy: 0.9598 - val_loss: 0.0235 - val_accuracy: 0.9939\n",
      "Epoch 19/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.1154 - accuracy: 0.9615 - val_loss: 0.0283 - val_accuracy: 0.9906\n",
      "Epoch 20/20\n",
      "370/370 [==============================] - 15s 41ms/step - loss: 0.1134 - accuracy: 0.9635 - val_loss: 0.0850 - val_accuracy: 0.9640\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "print(\"[INFO] training the network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), validation_data=(testX, testY),steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1623927559691,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "abDxGSMDQMCB",
    "outputId": "757e66a3-3f88-4fba-d5be-e33388d6bd75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving the network...\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "print(\"[INFO] saving the network...\")\n",
    "model.save(model.name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1623927560028,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "agj2cnanfP7O",
    "outputId": "e15b9d8d-bf1a-40f8-886c-8fe33e3e9364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model history:  {'loss': [1.9957998991012573, 1.8037528991699219, 1.4571478366851807, 0.8330432176589966, 0.5968717932701111, 0.44218239188194275, 0.34642109274864197, 0.33253511786460876, 0.27754300832748413, 0.22154733538627625, 0.19557493925094604, 0.20153166353702545, 0.1627376526594162, 0.15576137602329254, 0.16138778626918793, 0.12600941956043243, 0.11685818433761597, 0.11516251415014267, 0.11544007807970047, 0.11342471092939377], 'accuracy': [0.18719837069511414, 0.2833799123764038, 0.4484802186489105, 0.7001100778579712, 0.7837609052658081, 0.8409956693649292, 0.8820590972900391, 0.8860384225845337, 0.9044958353042603, 0.9250698685646057, 0.9338752031326294, 0.9315045475959778, 0.9442892074584961, 0.9479299187660217, 0.9464905858039856, 0.9605452418327332, 0.964101254940033, 0.9597832560539246, 0.9614765644073486, 0.9635086059570312], 'val_loss': [1.9207239151000977, 1.6882902383804321, 0.826867938041687, 0.4796561300754547, 0.42054155468940735, 0.20624211430549622, 0.23726043105125427, 0.1292213648557663, 0.16777580976486206, 0.0841999426484108, 0.0823308601975441, 0.0652548149228096, 0.04587174579501152, 0.053244344890117645, 0.3972364366054535, 0.03529191389679909, 0.025770336389541626, 0.023547673597931862, 0.028287407010793686, 0.08496403694152832], 'val_accuracy': [0.20896656811237335, 0.36626139283180237, 0.7137791514396667, 0.8439716100692749, 0.8421986103057861, 0.9427558183670044, 0.9141337275505066, 0.9640324115753174, 0.9399695992469788, 0.9751772880554199, 0.9736575484275818, 0.9812563061714172, 0.9896150231361389, 0.9855623245239258, 0.859422504901886, 0.9921479225158691, 0.9941742420196533, 0.9939209818840027, 0.990628182888031, 0.9640324115753174]}\n"
     ]
    }
   ],
   "source": [
    "# Save model history as png and as json file to be used in matlab\n",
    "\n",
    "print(\"\\n model history: \", H.history)\n",
    "\n",
    "# Plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"center right\")\n",
    "sf = model.name + \"_history.png\"\n",
    "plt.savefig(sf)\n",
    "plt.show()\n",
    "\n",
    "import json\n",
    "a_file = open(model.name + \"_history.json\", \"w\")\n",
    "json.dump(H.history, a_file)\n",
    "a_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko8Oocrgh72K"
   },
   "source": [
    "## **Pruning**\n",
    "https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1623927560029,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "aNbaU-O2_p76",
    "outputId": "49b25c2b-7f17-4141-b6dc-34147e24f924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CNN...\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this section if you want to load an already trained .h5 model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print(\"[INFO] loading CNN...\")\n",
    "#model = load_model(\"/content/drive/MyDrive/Embedded/Project/project-openmv/Results/squeezenet/ndat/3channels/squeezenet.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3556,
     "status": "ok",
     "timestamp": 1623927563576,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "C-Aye8xltD1K",
    "outputId": "e8012dc3-9402-44b2-f493-801990d699f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |██                              | 10kB 21.3MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 20kB 28.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 30kB 25.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 40kB 26.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 51kB 26.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 61kB 21.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 71kB 23.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 81kB 24.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 92kB 21.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 102kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 112kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 122kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 133kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 143kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 153kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 163kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 174kB 23.2MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install needed optimization toolkit\n",
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGdUx3p9bKFB"
   },
   "source": [
    "Create model for pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1623927564391,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "fTGZ3TM2h5ix",
    "outputId": "e6ffce35-cef1-4e0c-fa15-84c9de48f9bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2191: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"squeezenet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv1 (Prun (None, 31, 31, 64)   3522        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_relu_conv1  (None, 31, 31, 64)   1           prune_low_magnitude_conv1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_pool1 (Prun (None, 15, 15, 64)   1           prune_low_magnitude_relu_conv1[0]\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire2/squee (None, 15, 15, 16)   2066        prune_low_magnitude_pool1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire2/relu_ (None, 15, 15, 16)   1           prune_low_magnitude_fire2/squeeze\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire2/expan (None, 15, 15, 64)   2114        prune_low_magnitude_fire2/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire2/expan (None, 15, 15, 64)   18498       prune_low_magnitude_fire2/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire2/relu_ (None, 15, 15, 64)   1           prune_low_magnitude_fire2/expand1\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire2/relu_ (None, 15, 15, 64)   1           prune_low_magnitude_fire2/expand3\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire2/conca (None, 15, 15, 128)  1           prune_low_magnitude_fire2/relu_ex\n",
      "                                                                 prune_low_magnitude_fire2/relu_ex\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_pool3 (Prun (None, 7, 7, 128)    1           prune_low_magnitude_fire2/concat[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire4/squee (None, 7, 7, 32)     8226        prune_low_magnitude_pool3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire4/relu_ (None, 7, 7, 32)     1           prune_low_magnitude_fire4/squeeze\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire4/expan (None, 7, 7, 128)    8322        prune_low_magnitude_fire4/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire4/expan (None, 7, 7, 128)    73858       prune_low_magnitude_fire4/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire4/relu_ (None, 7, 7, 128)    1           prune_low_magnitude_fire4/expand1\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire4/relu_ (None, 7, 7, 128)    1           prune_low_magnitude_fire4/expand3\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire4/conca (None, 7, 7, 256)    1           prune_low_magnitude_fire4/relu_ex\n",
      "                                                                 prune_low_magnitude_fire4/relu_ex\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_pool5 (Prun (None, 3, 3, 256)    1           prune_low_magnitude_fire4/concat[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire6/squee (None, 3, 3, 48)     24626       prune_low_magnitude_pool5[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire6/relu_ (None, 3, 3, 48)     1           prune_low_magnitude_fire6/squeeze\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire6/expan (None, 3, 3, 192)    18626       prune_low_magnitude_fire6/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire6/expan (None, 3, 3, 192)    166082      prune_low_magnitude_fire6/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire6/relu_ (None, 3, 3, 192)    1           prune_low_magnitude_fire6/expand1\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire6/relu_ (None, 3, 3, 192)    1           prune_low_magnitude_fire6/expand3\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire6/conca (None, 3, 3, 384)    1           prune_low_magnitude_fire6/relu_ex\n",
      "                                                                 prune_low_magnitude_fire6/relu_ex\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire9/squee (None, 3, 3, 64)     49218       prune_low_magnitude_fire6/concat[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire9/relu_ (None, 3, 3, 64)     1           prune_low_magnitude_fire9/squeeze\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire9/expan (None, 3, 3, 256)    33026       prune_low_magnitude_fire9/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire9/expan (None, 3, 3, 256)    295170      prune_low_magnitude_fire9/relu_sq\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire9/relu_ (None, 3, 3, 256)    1           prune_low_magnitude_fire9/expand1\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire9/relu_ (None, 3, 3, 256)    1           prune_low_magnitude_fire9/expand3\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_fire9/conca (None, 3, 3, 512)    1           prune_low_magnitude_fire9/relu_ex\n",
      "                                                                 prune_low_magnitude_fire9/relu_ex\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_drop9 (Prun (None, 3, 3, 512)    1           prune_low_magnitude_fire9/concat[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv10 (Pru (None, 3, 3, 100)    102502      prune_low_magnitude_drop9[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_relu_conv10 (None, 3, 3, 100)    1           prune_low_magnitude_conv10[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_global_aver (None, 100)          1           prune_low_magnitude_relu_conv10[0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_loss (Prune (None, 8)            1610        prune_low_magnitude_global_averag\n",
      "==================================================================================================\n",
      "Total params: 807,489\n",
      "Trainable params: 404,524\n",
      "Non-trainable params: 402,965\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after n epochs.\n",
    "batch_size = BS\n",
    "epochs = 20\n",
    "validation_split = 0.1  # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = trainX.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "\n",
    "# Select appropriate optimizer\n",
    "if model_for_pruning.name == \"squeezenet\":\n",
    "  sgd = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "  model_for_pruning.compile(optimizer=sgd, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "else:\n",
    "  model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hypYtBP8bU-B"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271595,
     "status": "ok",
     "timestamp": 1623927835982,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "Nsu4DVkqjURe",
    "outputId": "2cdfda37-8602-42bf-94f3-105363f660d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "  5/334 [..............................] - ETA: 1:25 - loss: 3.7857 - accuracy: 0.2313WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0226s vs `on_train_batch_begin` time: 0.0665s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0226s vs `on_train_batch_end` time: 0.0959s). Check your callbacks.\n",
      "334/334 [==============================] - 22s 41ms/step - loss: 0.6969 - accuracy: 0.8203 - val_loss: 0.3510 - val_accuracy: 0.9004\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.3838 - accuracy: 0.9062 - val_loss: 0.1873 - val_accuracy: 0.9654\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.5199 - accuracy: 0.8686 - val_loss: 2.3802 - val_accuracy: 0.3316\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.4493 - accuracy: 0.8767 - val_loss: 0.2599 - val_accuracy: 0.9578\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 12s 36ms/step - loss: 0.4282 - accuracy: 0.8921 - val_loss: 0.2089 - val_accuracy: 0.9679\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 12s 36ms/step - loss: 0.3962 - accuracy: 0.8915 - val_loss: 0.9254 - val_accuracy: 0.6633\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 12s 36ms/step - loss: 0.2971 - accuracy: 0.9151 - val_loss: 0.1687 - val_accuracy: 0.9747\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.4400 - accuracy: 0.8970 - val_loss: 0.2167 - val_accuracy: 0.9671\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.3640 - accuracy: 0.9157 - val_loss: 0.4829 - val_accuracy: 0.8388\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.1798 - accuracy: 0.9568 - val_loss: 0.1363 - val_accuracy: 0.9722\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.1631 - accuracy: 0.9636 - val_loss: 0.1002 - val_accuracy: 0.9806\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 12s 36ms/step - loss: 0.1395 - accuracy: 0.9657 - val_loss: 0.0902 - val_accuracy: 0.9797\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.0852 - accuracy: 0.9818 - val_loss: 0.0704 - val_accuracy: 0.9865\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 12s 36ms/step - loss: 0.0672 - accuracy: 0.9863 - val_loss: 0.0540 - val_accuracy: 0.9916\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.0525 - accuracy: 0.9894 - val_loss: 0.1034 - val_accuracy: 0.9603\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.0427 - accuracy: 0.9915 - val_loss: 0.0339 - val_accuracy: 0.9899\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 12s 36ms/step - loss: 0.0382 - accuracy: 0.9922 - val_loss: 0.0286 - val_accuracy: 0.9941\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.0294 - accuracy: 0.9940 - val_loss: 0.0314 - val_accuracy: 0.9932\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 12s 35ms/step - loss: 0.0292 - accuracy: 0.9934 - val_loss: 0.0351 - val_accuracy: 0.9907\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 12s 36ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 0.0438 - val_accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "if model_for_pruning.name == \"squeezenet\":\n",
    "  model_for_pruning.fit(trainX, trainY,\n",
    "                      batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                      callbacks=callbacks)\n",
    "else:\n",
    "  model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), \n",
    "                      validation_data=(testX, testY),steps_per_epoch=len(trainX) // BS, epochs=epochs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1623927835990,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "a8l81P5Twu5c",
    "outputId": "fedc24e0-fb4d-42a8-c67f-f2c3cd4f1ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# First, create a compressible model for TensorFlow\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.save(model_for_pruning.name + 'Exp.h5', include_optimizer=False)\n",
    "\n",
    "# Both tfmot.sparsity.keras.strip_pruning and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression benefits of pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3144,
     "status": "ok",
     "timestamp": 1623927839121,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "GH_ObUk6zBWL",
    "outputId": "19b78b30-aa08-4a84-fbcd-9c6e5d98545c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpct7idu9b/assets\n"
     ]
    }
   ],
   "source": [
    "# Then, create a compressible model for TFLite\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "with open(model_for_export.name + 'Pruned.tflite', 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnmg1Z_lkz8a"
   },
   "source": [
    "## **Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KAxQvMLhPnv"
   },
   "source": [
    "### Full integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5423,
     "status": "ok",
     "timestamp": 1623927844534,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "mjCdT17vfXNa",
    "outputId": "d4511989-1024-43e6-969b-419adcfe246b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmquegumr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmquegumr/assets\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "# Note: not working for MobileNetV2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(np.float32(trainX)).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant_io = converter.convert()\n",
    "with open(model_for_export.name + \"FullIntQuant.tflite\", 'wb') as f:\n",
    "  f.write(tflite_model_quant_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6h_v8iN3hW5e"
   },
   "source": [
    "### Integer with float fallback (using default float input/output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4103,
     "status": "ok",
     "timestamp": 1623927848626,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "ezdrWGLFf65s",
    "outputId": "d31e9b8b-dab5-48e0-8d53-a1a0db37174c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9_ny3c97/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9_ny3c97/assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(np.float32(trainX)).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "with open(model_for_export.name + \"FloatFallbackQuant.tflite\", 'wb') as f:\n",
    "  f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bWArhNJl-5d"
   },
   "source": [
    "##**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8OyG0cnAn8W"
   },
   "outputs": [],
   "source": [
    "# Define test images path\n",
    "#testImg_folder = \"./DataSet_1/ValidationSet\"\n",
    "testImg_folder = \"./DataSet_2/ValidationSet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dyqEluJKZ7m"
   },
   "source": [
    "Initialize data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2612,
     "status": "ok",
     "timestamp": 1623927851235,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "yl2VNQkI5vH_",
    "outputId": "4e95cbb7-6aef-4f95-86f1-dbdd510fa5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading test images...\n",
      "(1, 64, 64, 3)\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Initialize data and labels\n",
    "print(\"[INFO] loading test images...\")\n",
    "test_images = []      # for .h5 models\n",
    "test_labels = []\n",
    "\n",
    "test_images_tf = []   # for .tflite models\n",
    "test_labels_tf = []\n",
    "\n",
    "# Grab the test image paths and randomly shuffle them\n",
    "test_paths = sorted(list(paths.list_images(testImg_folder)))\n",
    "random.seed(42)\n",
    "random.shuffle(test_paths)\n",
    "\n",
    "# Cycle over the input test images\n",
    "for test_path in test_paths:\n",
    "\n",
    "  # Load the test image, preprocess it and store in the test array\n",
    "  test_image = cv.imread(test_path)   # read as rgb\n",
    "\n",
    "  test_image = cv.resize(test_image, (64, 64))\n",
    "  test_image = test_image.astype(\"float\") / 255.0     # scale to [0,1]\n",
    "  test_image = img_to_array(test_image)\n",
    "  test_images_tf.append(test_image)\n",
    "  test_image = np.expand_dims(test_image, axis=0)\n",
    "  test_images.append(test_image)\n",
    "\n",
    "\n",
    "  # Extract the class label form the train image paths\n",
    "  label = test_path.split(os.path.sep)[-2]\n",
    "  if label == \"Arrow0\":\n",
    "    label = 0                       # for .h5 files\n",
    "    label_tf = [1,0,0,0,0,0,0,0]    # for .tflite files\n",
    "  elif label == \"Arrow45\":\n",
    "    label = 1\n",
    "    label_tf = [0,1,0,0,0,0,0,0]\n",
    "  elif label == \"Arrow90\":\n",
    "    label = 2\n",
    "    label_tf = [0,0,1,0,0,0,0,0]\n",
    "  elif label == \"Arrow135\":\n",
    "    label = 3\n",
    "    label_tf = [0,0,0,1,0,0,0,0]\n",
    "  elif label == \"Arrow180\":\n",
    "    label = 4\n",
    "    label_tf = [0,0,0,0,1,0,0,0]\n",
    "  elif label == \"Arrow225\":\n",
    "    label = 5\n",
    "    label_tf = [0,0,0,0,0,1,0,0]\n",
    "  elif label == \"Arrow270\":\n",
    "    label = 6\n",
    "    label_tf = [0,0,0,0,0,0,1,0]\n",
    "  else:\n",
    "    label = 7\n",
    "    label_tf = [0,0,0,0,0,0,0,1]\n",
    "  test_labels.append(label)\n",
    "  test_labels_tf.append(label_tf)\n",
    "\n",
    "print(test_images[0].shape)\n",
    "print(test_images_tf[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyCeE3NMADpp"
   },
   "source": [
    "### For .h5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0BcqYbm5vwa"
   },
   "source": [
    "Specify model and path to validation set folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQphTr2ymC6n"
   },
   "outputs": [],
   "source": [
    "# Define model path if you want to test an already existing trained .h5 model\n",
    "\n",
    "#model_path = \"/content/drive/MyDrive/Embedded/Project/project-openmv/Results/lenet/lenet.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1623927851237,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "1ARodFp-65MT",
    "outputId": "77fa8fb1-b530-4081-ebed-73f6502b25f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CNN...\n"
     ]
    }
   ],
   "source": [
    "# Load the trained CNN model\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print(\"[INFO] loading CNN...\")\n",
    "model_test = model\n",
    "#model_test = model_for_pruning\n",
    "#model_test = model_for_export\n",
    "#model_test = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p817n_jwKqCT"
   },
   "source": [
    "Make predictions and compute the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148667,
     "status": "ok",
     "timestamp": 1623927999893,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "JSHfQFGO7Qgk",
    "outputId": "0b0893b5-8ea0-4919-88c6-2927e0d9685a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compute predictions...\n",
      "tf.Tensor(\n",
      "[[478   1   0   1   0   0   0   0]\n",
      " [  0 456   0   0   0   0   1   0]\n",
      " [  0   0 476   2   0   0   0   0]\n",
      " [  0   0   0 477   0   0   0   3]\n",
      " [  0   0   0   8 471   0   0   0]\n",
      " [  1   6   0   0   1 456   4   1]\n",
      " [  0   0   0   2   0   0 453   0]\n",
      " [  0   0   0   5   0   0   0 453]], shape=(8, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "# cycle over the test images\n",
    "print(\"[INFO] compute predictions...\")\n",
    "for j in range(0, len(test_images)):\n",
    "\n",
    "  # Predict image\n",
    "  prediction = model_test.predict(test_images[j])[0]\n",
    "  predictions.append(np.argmax(prediction))\n",
    "\n",
    "#print(len(predictions))\n",
    "#print(len(labels))\n",
    "\n",
    "from tensorflow import math as tfMath\n",
    "\n",
    "confusionMatrix = tfMath.confusion_matrix(test_labels, predictions)\n",
    "print(confusionMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OE_104x9rm8"
   },
   "outputs": [],
   "source": [
    "# Save the confusion matrix\n",
    "np.savetxt(model_test.name + \"ConfMatr.txt\", confusionMatrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_hK9YeSLHtT"
   },
   "source": [
    "Compute the accuracy of the above selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1623927999895,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "JY0_GzH-xbfN",
    "outputId": "dfa15d86-3612-4206-cd09-89f67c16b491"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# models must be compiled to can perform the evaluate attribute\n",
    "import tensorflow as tf\n",
    "#   Select appropriate optimizer\n",
    "if model_test.name == \"squeezenet\":\n",
    "  sgd = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "  model_test.compile(optimizer=sgd, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "else:\n",
    "  model_test.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1125,
     "status": "ok",
     "timestamp": 1623928001013,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "9I5JV-OS_Nrx",
    "outputId": "3af6788d-9817-4999-8191-77eaebcc46b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9904153347015381\n"
     ]
    }
   ],
   "source": [
    "_, model_accuracy = model_test.evaluate(\n",
    "    np.array(test_images_tf), np.array(test_labels_tf), verbose=0)\n",
    "    \n",
    "print(model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-RNi67VIfd7"
   },
   "outputs": [],
   "source": [
    "# Save accuracy to file\n",
    "with open(model_test.name + \"Accuracy.txt\", 'w') as f:\n",
    "  f.write(\"%f\" % model_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XMci7yI5Tm3"
   },
   "source": [
    "### Evaluate Pruned Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1623928001429,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "c3FP3AGv5Yko",
    "outputId": "985c1d2c-64c8-4034-9d82-808e7e7632f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CNN...\n"
     ]
    }
   ],
   "source": [
    "# Load the trained CNN model\n",
    "\n",
    "print(\"[INFO] loading CNN...\")\n",
    "model_test = pruned_tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjbsOuz-5cuJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images_tf):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "    #if i == 1000:\n",
    "    #    break\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "\n",
    "  correctPositives = 0\n",
    "  ary = np.array([np.array(prediction_digits), np.array(test_labels)])\n",
    "\n",
    "  for n in range(0,len(ary[0])):\n",
    "    if ary[0][n] == ary[1][n]:\n",
    "      correctPositives += 1\n",
    "\n",
    "  return correctPositives/len(ary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4487,
     "status": "ok",
     "timestamp": 1623928005909,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "n2QOMuh35mbD",
    "outputId": "e00d2516-41cd-4676-b26a-2185f5522397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "\n",
      "\n",
      "accuracy: 0.9904153354632588\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=model_test)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYPBgyBV5naX"
   },
   "outputs": [],
   "source": [
    "# Save accuracy to file\n",
    "with open(\"Pruned\" + \"Accuracy.txt\", 'w') as f:\n",
    "  f.write(\"%f\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKefedtZ-Okw"
   },
   "source": [
    "#Evaluate Full Integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1623928005911,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "a-fh8iCY_JHS",
    "outputId": "461ec212-c413-4301-a0ad-31243740d89f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CNN...\n"
     ]
    }
   ],
   "source": [
    "# Load the trained CNN model\n",
    "\n",
    "print(\"[INFO] loading CNN...\")\n",
    "model_test = tflite_model_quant_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzP7ntt2-OxJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  \n",
    "  # Inputs for the TFLite model must be uint8, so we quantize our input data\n",
    "  scale, zero_point = input_details['quantization']\n",
    "  \n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images_tf):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.uint8(test_image / scale + zero_point)\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.uint8)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "    #if i == 1000:\n",
    "    #    break\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy\n",
    "\n",
    "  correctPositives = 0\n",
    "  ary = np.array([np.array(prediction_digits), np.array(test_labels)])\n",
    "\n",
    "  for n in range(0,len(ary[0])):\n",
    "    if ary[0][n] == ary[1][n]:\n",
    "      correctPositives += 1\n",
    "\n",
    "  print(np.array(prediction_digits))\n",
    "  print(np.array(test_labels))\n",
    "\n",
    "  return correctPositives/len(ary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107780,
     "status": "ok",
     "timestamp": 1623928113682,
     "user": {
      "displayName": "Markus Profunser",
      "photoUrl": "",
      "userId": "11703814908669562978"
     },
     "user_tz": -120
    },
    "id": "HpzPO9lF-Plk",
    "outputId": "1d57171c-f7c5-4dbf-8967-57274174fb9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "\n",
      "\n",
      "[5 6 2 ... 0 0 7]\n",
      "[5 6 2 ... 0 0 7]\n",
      "accuracy: 0.9901490947816827\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=model_test)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NorIUkzW-7Qv"
   },
   "outputs": [],
   "source": [
    "# Save accuracy to file\n",
    "with open(\"FullIntegerQuantization\" + \"Accuracy.txt\", 'w') as f:\n",
    "  f.write(\"%f\" % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_network_rgb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
