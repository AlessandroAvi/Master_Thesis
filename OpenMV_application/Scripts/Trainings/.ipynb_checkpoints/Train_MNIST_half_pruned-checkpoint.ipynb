{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8g3_OkUNOuD"
   },
   "source": [
    "## **Import the TensorFlow library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKk-D3IZkkbE"
   },
   "source": [
    "This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to eb applied on the OpenMV camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3311,
     "status": "ok",
     "timestamp": 1642669899172,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XCqcQuaBLNgF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv \n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8C9aeAMdSE"
   },
   "source": [
    "Load MNIST dataset and split in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1642669899176,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mNfeJ2bbNDET",
    "outputId": "48aa2ce4-cace-4979-af5d-d0db989bf648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset shapes are\n",
      "    Train dataset shape: (60000, 28, 28)\n",
      "    Test dataset shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "print('The original dataset shapes are')\n",
    "print(f'    Train dataset shape: {data_train.shape}')\n",
    "print(f'    Test dataset shape:  {data_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1642669899179,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "IyjJkzGxpxDf",
    "outputId": "99156193-19bb-4c47-c384-8991f7e82241"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaAIs1HlrltM"
   },
   "source": [
    "Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1642669900033,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wjQCPI7FTr2H",
    "outputId": "2472a0c4-13f7-4810-b622-437141c61dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:\n",
      "     Train dataset lower than 6 has shape:  (36017, 28, 28)\n",
      "     Train dataset higher than 6 has shape: (23983, 28, 28)\n",
      "\n",
      "     Test dataset lower than 6 has shape:  (6031, 28, 28)\n",
      "     Test dataset higher than 6 has shape: (3969, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_samples = label_train.shape[0]\n",
    "test_samples  = label_test.shape[0]\n",
    "\n",
    "trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n",
    "testLow_samples = np.sum(np.where(label_test <  6, 1, 0))\n",
    "\n",
    "# separate in containers data that is lower nad higer than 6\n",
    "data_low_train   = np.zeros([trainLow_samples,28,28])\n",
    "label_low_train  = np.zeros(trainLow_samples)\n",
    "data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n",
    "label_high_train = np.zeros(train_samples-trainLow_samples)\n",
    "\n",
    "data_low_test   = np.zeros([testLow_samples,28,28])\n",
    "label_low_test  = np.zeros(testLow_samples)\n",
    "data_high_test  = np.zeros([test_samples-testLow_samples,28,28])\n",
    "label_high_test = np.zeros(test_samples-testLow_samples)\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,train_samples):  \n",
    "    if(label_train[i]<6):\n",
    "        data_low_train[j,:,:] = data_train[i,:,:]\n",
    "        label_low_train[j]    = label_train[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_train[k,:,:] = data_train[i,:,:]\n",
    "        label_high_train[k]    = label_train[i]\n",
    "        k+=1\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,test_samples):  \n",
    "    if(label_test[i]<6):\n",
    "        data_low_test[j,:,:] = data_test[i,:,:]\n",
    "        label_low_test[j]    = label_test[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_test[k,:,:] = data_test[i,:,:]\n",
    "        label_high_test[k]    = label_test[i]\n",
    "        k+=1\n",
    "\n",
    "print('After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:')\n",
    "print(f'     Train dataset lower than 6 has shape:  {data_low_train.shape}')\n",
    "print(f'     Train dataset higher than 6 has shape: {data_high_train.shape}')\n",
    "print()\n",
    "print(f'     Test dataset lower than 6 has shape:  {data_low_test.shape}')\n",
    "print(f'     Test dataset higher than 6 has shape: {data_high_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1642669900037,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "bgVHZlEqqBr7",
    "outputId": "bcad13ec-918c-4cad-c1b7-fb8a8a298161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly check if dataset that I created are filled correctly\n",
    "num = int(random.uniform(0,trainLow_samples))\n",
    "plt.imshow(data_low_train[num], cmap=\"gray\") # Import the image\n",
    "print(label_low_train[num])\n",
    "plt.show() # Plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTx7YrtENh3F"
   },
   "source": [
    "## **Pre process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1642669900041,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "lU_tKzkCse1H"
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1642669900044,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "c2TsbEYpU-p2"
   },
   "outputs": [],
   "source": [
    "# Something I don't know\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_low_train  = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_low_test   = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_test  = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape     = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_low_train  = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_low_test   = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_test  = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape     = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NZNND6XFXFw"
   },
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1642669900796,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "eE5Ju7QbRDBF"
   },
   "outputs": [],
   "source": [
    "data_low_train  = data_low_train.astype(np.float32) / 255.0\n",
    "data_high_train = data_high_train.astype(np.float32) / 255.0\n",
    "data_low_test   = data_low_test.astype(np.float32) / 255.0\n",
    "data_high_test  = data_high_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNaCD_O0RPDs"
   },
   "source": [
    "## **BUILD THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1642669900799,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "dewlaeUUlFpw"
   },
   "outputs": [],
   "source": [
    "TRAIN_MODEL_1 = True\n",
    "TRAIN_MODEL_2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1642669900801,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "VkSwp6sOFXF6"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs     = 10\n",
    "validation_split = 0.1\n",
    "optimizer  = \"adam\"\n",
    "loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics    = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1642669901174,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "vZVNdEatp8L2",
    "outputId": "699d1a6b-5a3d-48ff-9af3-6ce3fc0dfbc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 32)        2336      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 15,326\n",
      "Trainable params: 15,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(8, kernel_size=(3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(Conv2D(8, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if(TRAIN_MODEL_1):\n",
    "    #tf.keras.utils.plot_model(model, show_shapes=True, to_file='naive_inception_module.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1642669901176,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Cige2fQHFXGB"
   },
   "outputs": [],
   "source": [
    "# METHOD 2\n",
    "# This model is a bit larger and should be much more precise in the feature extraction\n",
    "if(TRAIN_MODEL_2):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, (3, 3), input_shape = input_shape))\n",
    "    model2.add(Conv2D(32, (3, 3), activation = \"relu\"))\n",
    "    model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(128, activation = \"relu\"))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "    model2.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_3CoNfUFXGE"
   },
   "source": [
    "## TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144034,
     "status": "ok",
     "timestamp": 1642670045191,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZRk1oPJmTCM2",
    "outputId": "b430d7c3-48c9-411c-d362-2e1d61802dfc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1013/1013 [==============================] - 13s 13ms/step - loss: 1.1201 - accuracy: 0.9271 - val_loss: 1.0579 - val_accuracy: 0.9858\n",
      "Epoch 2/10\n",
      "1013/1013 [==============================] - 13s 13ms/step - loss: 1.0645 - accuracy: 0.9794 - val_loss: 1.0545 - val_accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "1013/1013 [==============================] - 13s 13ms/step - loss: 1.0609 - accuracy: 0.9828 - val_loss: 1.0532 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "1013/1013 [==============================] - 13s 13ms/step - loss: 1.0580 - accuracy: 0.9857 - val_loss: 1.0519 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 1.0574 - accuracy: 0.9863 - val_loss: 1.0499 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "1013/1013 [==============================] - 13s 13ms/step - loss: 1.0542 - accuracy: 0.9895 - val_loss: 1.0514 - val_accuracy: 0.9922\n",
      "Epoch 7/10\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 1.0540 - accuracy: 0.9895 - val_loss: 1.0517 - val_accuracy: 0.9914\n",
      "Epoch 8/10\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 1.0531 - accuracy: 0.9904 - val_loss: 1.0501 - val_accuracy: 0.9942\n",
      "Epoch 9/10\n",
      "1013/1013 [==============================] - 16s 16ms/step - loss: 1.0527 - accuracy: 0.9910 - val_loss: 1.0498 - val_accuracy: 0.9939\n",
      "Epoch 10/10\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 1.0533 - accuracy: 0.9901 - val_loss: 1.0529 - val_accuracy: 0.9911\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 1.0509 - accuracy: 0.9929\n",
      "\n",
      "Test accuracy: 0.9928701519966125\n"
     ]
    }
   ],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model.fit(data_low_train, label_low_train, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n",
    "\n",
    "  # Evaluate the model performance\n",
    "    test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1642670045193,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "h_oS2hh3FXGO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_2):\n",
    "\n",
    "    labels_prova = keras.utils.to_categorical(label_low_train, 6)\n",
    "\n",
    "    model2.fit(data_low_train, labels_prova, epochs = epochs, batch_size = batch_size, validation_split = validation_split )\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    test_loss, test_acc = model2.evaluate(data_low_test, keras.utils.to_categorical(label_low_test, 6))\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI3aR1l4pqhS"
   },
   "source": [
    "## TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1642670045194,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "AVNdx-gjlhze"
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model_test = model\n",
    "elif(TRAIN_MODEL_2):\n",
    "    model_test = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1642670045883,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "piwc0fbspvlc"
   },
   "outputs": [],
   "source": [
    "predictions = model_test.predict(data_low_test)   # Make prediction of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1642670045885,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y9R_XtjSrO2g",
    "outputId": "38a3a49f-7a7b-40b9-dc06-1d191479e0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  3\n",
      "True label =  3.0\n"
     ]
    }
   ],
   "source": [
    "num = int(random.uniform(0,data_low_test.shape[0]))\n",
    "print(\"Prediction = \" , np.argmax(predictions[num]))\n",
    "print(\"True label = \" , label_low_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1642670045887,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "2Uj_jf6-jCGj"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    class_names = ['0','1','2','3','4','5']\n",
    "\n",
    "    true_label, img = int(true_label[i]), img[i,:,:]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = (np.squeeze(img))## you have to delete the channel information (if grayscale) to plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)   \n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(6))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1642670045888,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "_L_MP6pejCGk",
    "outputId": "d173a92a-dab6-46ac-9f8d-05edbb8b5b7e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADCCAYAAAB3whgdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJ2ElEQVR4nO3de2xeZR3A8e/PDQXmDJctA4TY6aYRjCAwsmSRKFFEJF6iBnQSjCT+gwQDRGOivLzjoiZeIHjFSxiZsuDUSATERTDE4IUVNuOcRmLGnEwJMgJGQQs//zjv5tK+3Xo57a+l30/S0J6ePudpCV+envO0jcxEkjT9XlA9AUmaqwywJBUxwJJUxABLUhEDLElFDLAkFZlfPQGp2qJFi3JgYKDk2lv+voWhZ4daGWv+vPmcuOTEVsZSewYHBx/LzMX93meANecNDAywadOmkmtHN1oba4ghNnVqPg+NLiIeHu193oKQpCIGWJKKGGBJKjKue8AR4S+O0JTKzPZuikoznCtgSSpigCWpiAGWpCIGWJKKGGBJKmKAJamIAZakIgZYkooYYEkqYoAlqYgBlqQiBliSihhgSSpigCWpiAGWpCIGWJKKGGBJKmKAJamIAZakIgZYkoqM649yanRLliwZcWzt2rV9z73vvvtGHFuzZk3rc5I0s7kClqQiBliSihhgSSpigCWpiA/hWnLuueeOOLZq1aq+5y5fvnzEsWuvvbbvuUNDQ5ObmKQZyxWwJBUxwJJUxABLUhEDLElFDLAkFXEXxBRasGBB3+NLly4dcSwipno6kmYYV8CSVMQAS1IRAyxJRQywJBUxwJJUxABLUhEDLElFDLAkFTHAklTEAEtSEX8UeYZYsWJF3+P9/oKypOcHV8CSVMQAS1IRAyxJRQywJBXxIVyBfr/795RTTul7rg/hpOcvV8CSVMQAS1IRAyxJRQywJBUxwJJUxF0QBTJzxLF169YVzERSJVfAklTEAEtSEQMsSUUMsCQV8SHcDLFy5cq+x++8885pnomk6eIKWJKKGGBJKmKAJamIAZakIgZYkoq4C2KGWLZsWfUUJE0zV8CSVMQAS1IRAyxJRQywJBUxwJJUxABLUhEDLElFDLAkFTHAklTEAEtSEQMsSUUMsCQVMcCSVMQAS1IRAyxJRfx9wDPE7t27q6cgaZq5ApakIgZYkooYYEkqYoAlqYgP4WaIp59+unoKkqaZK2BJKmKAJamIAZakIgZYkooYYEkq4i6IlixcuHBSH79jx46WZiJptnAFLElFDLAkFTHAklTEAEtSER/CtWT16tVjPnf79u0jjj344IMtzkbSbOAKWJKKGGBJKmKAJamIAZakIgZYkoq4C6LA4sWLRxw74YQT+p67efPmKZ6NpCqugCWpiAGWpCIGWJKKGGBJKuJDuAILFiwYcWzr1q0FM5FUyRWwJBUxwJJUxABLUhEDLElFDLAkFTHAklTEAEtSEQMsSUUMsCQVMcCSVMQAS1IRAyxJRQywJBUxwJJUxABLUhEDLElF/IXsLbniiitGHLv44ov7nrtmzZoRx4aGhlqfk6SZzRWwJBUxwJJUxABLUhEDLElFfAjXkg0bNozpmCTt4QpYkooYYEkqYoAlqYgBlqQiBliSihhgSSpigCWpiAGWpCIGWJKKGGBJKmKAJamIAZakIgZYkooYYEkqYoAlqYgBlqQiBliSihhgSSpigCWpiAGWpCIGWJKKjPevIj8GPDwVE5GAl1VPQJpO4wpwZi6eqolI0lzjLQhJKmKAJamIAZakIuN9CDfrRTe+DZwDPJqdfM0o55wOXAe8FjgvO7lhn/ddAHyy9+bV2cm1veNLgfXAEcADwPnZyf9EN94NrAEeB96ZnfxHdOMVwDXZyfNGuX4AP+ud/+Roc45ufA64Izt59wS/HJIKzbkAAzcBXwJu3s85O4APApfvezC6cQTQAU4FEhiMbtyWndwNfBb4YnZyfXTja8CFwFeBy4CVwHnA+4EbgKuBT+3n+mcDW7KTTx5gzjcA3wAM8CQMDg4+FhGT3d2ziGaX0FQZ0/hxZUzZ2JMw18cfdXfPnAtwdvLe6MbAAc7ZDhDdeG7Yu94CbMxOPt57/0bgrOjGeuAMmsACrAWupAnwc8CLgEOBZ6Ibrwd2ZSf/tJ8prAZuPNCcs5MPRzeOjG4clZ382/4+J42ujd09EbEpM09tYz7TPf5snvtsH997wOPzUuAv+7y9s3fsSOCJ7OTQsOMAXeAu4E3ALTS3L646wHVWAYNjnNMDvfMlzTJzbgU8Sf2+v8v9HCc7uRHYCHvvH98BvCq6cTmwG7gkO/mvYR97RHbyqTHO6VHgmDGeK2kGcQU8PjuB4/Z5+1jgEZr7Q4dFN+YPO75XdONQ4ALgK8CngQ/RrHJX97nOUHRjrP9uDgb+PdZPQFPmxgOfMmPHn81zn9XjG+DxuQs4M7pxeHTjcOBM4K7sZAL3AO/pnXcB8KNhH/sx4Prs5H+BQ2hWyM/R3Bse7o/Ay8c4p1cCvxvXZ6HWZeaURmAqx5/Nc5/t48+5AEc3bgF+SXMbYGd048I+56yIbuwE3gt8PbqxFaD38O0q4P7ey5o9D+SAjwOXRjceorkn/K19xjsGODU7uSfKnwd+RRPq7/aZ5u3AGw405+jGQcAyYNNEvhaSakVmVs9Bw0Q3jgZuzk6++QDnvQs4OTu5vy1tmkIRcRZwPTAP+GZmfqbl8f+/Bzz771ufxNjH0WxtPIrmu7EbM/P6Fsc/GLiXZhfQfGBDZnbaGr93jXk0C5C/ZuY5bY7dG3878BTwLDDU9m6IObcCng2yk7uAb0Q3XnKAU+fTrKZVoPcf/5eBtwLHA++LiONbvsxNwFktj7nHEHBZZr6aZq/6RS3P/xngjMw8ETgJOCsiVrY4PsAlwLaWxxzujZl50lRsRXMXxAyVnbx1DOd8bzrmolGdBjyUmX8GiIj1wDuA37d1gcy8N2L/+9YnMfYuYFfv9aciYhvN9slW5p/Nt9f/7L15UO+ltW+5I+JY4G3ANcClbY07nVwBSxM32r7wWacX+dcBv2553HkRsZlmu+TGzGxz/OtoHm4P/4GpNiXw04gYjIgPtz24AZYmbtT937NJRLwY+D7w0cy9P/7eisx8NjNPotmaeVpEtHIfOyL23Bcf6w8sTdSqzDyZ5jbTRRFxepuDG2Bp4kbbFz5rRMRBNPH9Tmb+YKquk5lPAD+nvfvZq4C39x6SrQfOiIh1LY29V2Y+0vvno8APaW47tcYASxN3P7A8IpZGxAtpfuHSbcVzGrOICJrtktsy8wtTMP7iiDis9/ohND+O/4c2xs7MT2TmsZk5QPN1vzszP9DG2HtExIKIWLjndZp9/63uuTfA0gRl5hDwEZof0NkG3JqZW9u8RsQ+e8AjdkaM3Lc+CauA82lWj5t7L2e3OP7RwD0R8Vua/1ltzMwftzj+VFsC/CIitgC/AW7PzJ+0eQH3AUtSEVfAklTEAEtSEQMsSUUMsCQVMcCSVMQAS1IRAyxJRQywJBX5H4E1SnV9poGmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = int(random.uniform(0, predictions.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plot_image(num, predictions[num], label_low_test, data_low_test)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plot_value_array(num, predictions[num], label_low_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye7xyl_-vkkk"
   },
   "source": [
    "## **SAVE ORIGINAL MODEL AND FROZEN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1642670045890,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ADvJBmeEFXGf"
   },
   "outputs": [],
   "source": [
    "def save_summary_model(model, MODEL_PATH, flag):\n",
    "    new_file = open(MODEL_PATH + 'model_summary.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    if(flag==0):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the ORIGINAL MODEL\")\n",
    "    elif(flag==1):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the FROZEN MODEL\")\n",
    "    new_file.write(\"\\n\")\n",
    "    new_file.write(\"\\n Batch size:       \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs:           \" + str(epochs))\n",
    "    new_file.write(\"\\n Metrics:          \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer:        \" + optimizer)\n",
    "    new_file.write(\"\\n Loss:             \" + \"SparseCategoricalCrossentropy \\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1642670046245,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "rjFdtesdvqzf",
    "outputId": "273832e4-7e4a-4008-ef73-0a1e9c15a38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0508753061294556\n",
      "Test accuracy: 0.9928701519966125\n",
      "Save ORIGINAL MODEL as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath('')\n",
    "SAVE_MODEL_PATH = ROOT_PATH + \"\\\\Backup_models\\\\Last_trained_model\"\n",
    "\n",
    "ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Original_model\\\\\" \n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Save ORIGINAL MODEL as mnist_cnn.h5')\n",
    "model.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model_test, ORIGINAL_MODEL_PATH, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nPOwtTnFXGk"
   },
   "source": [
    "Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk84TZDvyjW4"
   },
   "source": [
    "### SAVE THE FROZEN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1642670046247,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "qQzEf-OKFXGl",
    "outputId": "e17c094d-1148-44e2-b9d0-552eb712dd85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 32)        2336      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 12,248\n",
      "Trainable params: 12,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save FROZEN MODEL model as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE THE FROZEN MODEL\n",
    "frozen_model = keras.models.Sequential(model_test.layers[:-1])\n",
    "frozen_model.summary()\n",
    "frozen_model.compile()\n",
    "\n",
    "FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_model\\\\\"\n",
    "\n",
    "print('Save FROZEN MODEL model as mnist_cnn.h5')\n",
    "frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(frozen_model, FROZEN_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1wsEHInFXGn"
   },
   "source": [
    "Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1642670046248,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "NOvcRsOVFXGn",
    "outputId": "3f3446d3-a168-4256-eff5-72969162d8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the last layer weights is: (512, 6)\n",
      "The shape of the last layer biases is: (6,)\n"
     ]
    }
   ],
   "source": [
    "ll_weights = np.array(model_test.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model_test.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jSSceEYKsHX"
   },
   "source": [
    "## PRUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86fkMkzrFXGs"
   },
   "source": [
    "https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3384,
     "status": "ok",
     "timestamp": 1642670049623,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wM4PKTiCFXGw"
   },
   "outputs": [],
   "source": [
    "# Install needed optimization toolkit\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1642670050700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "oxawOG-5FXGy",
    "outputId": "50a0d265-ca20-4fdf-9a4f-710c33b603a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:212: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 8)         154       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 24, 24, 8)         1162      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 12, 12, 8)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_2 (None, 10, 10, 32)        4642      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_3 (None, 8, 8, 32)          18466     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 4, 4, 32)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout  (None, 4, 4, 32)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 512)               1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 6)                 6152      \n",
      "=================================================================\n",
      "Total params: 30,580\n",
      "Trainable params: 15,326\n",
      "Non-trainable params: 15,254\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after n epochs.\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "validation_split = 0.1  # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = data_low_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model_test, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "\n",
    "# Select appropriate optimizer\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251734,
     "status": "ok",
     "timestamp": 1642670302425,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "f8YgeDcrFXG2",
    "outputId": "6a50bfea-5684-4f5e-a633-bcd833a1491d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Pruning._maybe_update_block_mask of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_impl.Pruning object at 0x000002BE2DE77A60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Pruning._maybe_update_block_mask of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_impl.Pruning object at 0x000002BE2DE77A60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE37212E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE37212E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE314609D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE314609D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE373078B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE373078B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE31460D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE37269040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE37269040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE37366DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE37366DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE38581C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE38581C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE38742550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE38742550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE3151F5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE387A6E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Pruning.conditional_mask_update.<locals>.maybe_update_masks at 0x000002BE387A6E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1/1013 [..............................] - ETA: 0s - loss: 1.0748 - accuracy: 0.9688WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1013 [..............................] - ETA: 36s - loss: 1.0592 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0107s vs `on_train_batch_end` time: 0.0629s). Check your callbacks.\n",
      "1013/1013 [==============================] - 14s 14ms/step - loss: 1.0522 - accuracy: 0.9914 - val_loss: 1.0506 - val_accuracy: 0.9925\n",
      "Epoch 2/5\n",
      "1013/1013 [==============================] - 13s 13ms/step - loss: 1.0512 - accuracy: 0.9927 - val_loss: 1.0494 - val_accuracy: 0.9942\n",
      "Epoch 3/5\n",
      "1013/1013 [==============================] - 13s 13ms/step - loss: 1.0510 - accuracy: 0.9931 - val_loss: 1.0494 - val_accuracy: 0.9950\n",
      "Epoch 4/5\n",
      "1013/1013 [==============================] - 17s 17ms/step - loss: 1.0501 - accuracy: 0.9941 - val_loss: 1.0499 - val_accuracy: 0.9942\n",
      "Epoch 5/5\n",
      "1013/1013 [==============================] - 15s 14ms/step - loss: 1.0494 - accuracy: 0.9946 - val_loss: 1.0487 - val_accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2be314a04c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(data_low_train, label_low_train,\n",
    "                    batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1642670303234,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "IHJW7bkYLiOV",
    "outputId": "3c14850f-33a8-4d9c-93cb-bd08c3789463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test accuracy:  0.9928701519966125\n",
      "Pruned test accuracy:    0.9968495965003967\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(data_low_test, label_low_test, verbose=0)\n",
    "\n",
    "print('Original test accuracy: ', test_acc)\n",
    "print('Pruned test accuracy:   ', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIAK-1EJK6Z_"
   },
   "source": [
    "## CREATE A x3 SMALLER MODEL FROM PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1642670303235,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "E_MqIPRtFXG3",
    "outputId": "3fd08389-cd6e-42a4-da3d-d8127047ce17"
   },
   "outputs": [],
   "source": [
    "# First, create a compressible model for TensorFlow\n",
    "\n",
    "PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Pruned_model\\\\\"\n",
    "\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.save(PRUNED_MODEL_PATH + 'Pruned_cnn.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2178,
     "status": "ok",
     "timestamp": 1642670305406,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XLBF9aRvFXG5",
    "outputId": "91b4b562-8d2f-4d13-dbd6-3563ffda612e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpqoi4o64_\\assets\n"
     ]
    }
   ],
   "source": [
    "# Then, create a compressible model for TFLite\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "with open(PRUNED_MODEL_PATH + 'Pruned_cnn.tflite', 'wb') as f:\n",
    "    f.write(pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1642670305409,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "FAh4chQQMdVJ"
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1642670423546,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "oiLalXuSMSwF",
    "outputId": "e9f8d3d6-2791-4993-b4e6-f306e3a6d2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 48498.00 bytes\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Impossibile trovare il file specificato: 'C:\\\\Users\\\\massi\\\\UNI\\\\Magistrale\\\\Anno 5\\\\Semestre 2\\\\Tesi\\\\Code\\\\OpenMV_application\\\\Scripts\\\\Trainings\\\\Backup_models\\\\Last_trained_model\\\\Pruned_model\\\\pruned.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24932/3382019468.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Size of gzipped baseline Keras model: %.2f bytes\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mget_gzipped_model_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFROZEN_MODEL_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"mnist_cnn.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Size of gzipped pruned Keras model  : %.2f bytes\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mget_gzipped_model_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRUNED_MODEL_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'pruned.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Size of gzipped pruned TFlite model : %.2f bytes\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mget_gzipped_model_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPRUNED_MODEL_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Pruned.tflite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24932/500910442.py\u001b[0m in \u001b[0;36mget_gzipped_model_size\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzipped_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.zip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipped_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZIP_DEFLATED\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipped_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1739\u001b[0m             )\n\u001b[0;32m   1740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1741\u001b[1;33m         zinfo = ZipInfo.from_file(filename, arcname,\n\u001b[0m\u001b[0;32m   1742\u001b[0m                                   strict_timestamps=self._strict_timestamps)\n\u001b[0;32m   1743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\zipfile.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, filename, arcname, strict_timestamps)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[0misdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_ISDIR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[0mmtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Impossibile trovare il file specificato: 'C:\\\\Users\\\\massi\\\\UNI\\\\Magistrale\\\\Anno 5\\\\Semestre 2\\\\Tesi\\\\Code\\\\OpenMV_application\\\\Scripts\\\\Trainings\\\\Backup_models\\\\Last_trained_model\\\\Pruned_model\\\\pruned.h5'"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n",
    "print(\"Size of gzipped pruned Keras model  : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + 'Pruned_cnn.h5')))\n",
    "print(\"Size of gzipped pruned TFlite model : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + 'Pruned_cnn.tflite')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi4RUhtOPUKr"
   },
   "source": [
    "## CREATE A 10x SMALLER MODEL, COMBINE PRUNING WITH QUANTIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/lite/performance/post_training_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2209,
     "status": "ok",
     "timestamp": 1642670670389,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "X_xSV0ZePY7S",
    "outputId": "f246574c-06df-4a52-d680-cef893dfd630"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export) # load the converter\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.h5')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model             : %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFG2-AhwyZsZ"
   },
   "source": [
    "## SAVE THE FROZEN MODEL VERSION OF THE PRUNED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1642670675487,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "CF1fpU3RyoPj",
    "outputId": "1dd42723-a73d-4fa1-d73b-9de69a931cd2"
   },
   "outputs": [],
   "source": [
    "frozen_pruned_model = keras.models.Sequential(model_for_pruning.layers[:-1])\n",
    "frozen_pruned_model.summary()\n",
    "frozen_pruned_model.compile()\n",
    "\n",
    "FROZEN_PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_Pruned_model\\\\\"\n",
    "\n",
    "print('Save FROZEN PRUNED MODEL model as Frozen_pruned_cnn.h5')\n",
    "frozen_model.save(FROZEN_PRUNED_MODEL_PATH + \"Frozen_pruned_cnn.h5\")\n",
    "save_summary_model(frozen_pruned_model, FROZEN_PRUNED_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1642670683191,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZDFF5jp6yslG",
    "outputId": "1cc4e095-5cd5-479f-c8c0-15756665f544"
   },
   "outputs": [],
   "source": [
    "ll_weights = np.array(model_for_pruning.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model_for_pruning.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_PRUNED_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_PRUNED_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu1ooRLcwAwb"
   },
   "source": [
    "## DOWNLOAD ENTIIRE MODEL DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1642670707129,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y6PSAT4AQCwq",
    "outputId": "eadd7971-b925-45d8-83a8-2771ec6cb6fd"
   },
   "outputs": [],
   "source": [
    "#%cd '/content'\n",
    "#from google.colab import files\n",
    "#import shutil\n",
    "#shutil.make_archive('Colab_models', 'zip', 'Models')\n",
    "#files.download('Colab_models.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd2AzXoKzc6l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_MNIST_half.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
