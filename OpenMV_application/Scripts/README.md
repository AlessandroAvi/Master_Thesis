# DIRECTORY STRUCTURE

## DIRECTORIES

- `OpenMV_scripts`: contains the scripts to be loaded on the OpenMV camera for performing the CL training (one main file and one library).

- `Results`: contains all the images generated by matplotlib containing the results fot he trainings with the different algorithms.

- `Saved_models`: contains the best performing models that were generated with the training script. In here cna be found the original model, frozen model, pruned model and quantized model.

- `Training_Images`: contains 2 images used for showing the state of the camera while training. 

- `lib`: contains 2 script where useful functions are defined for the manipulation of the MNIST DATASET.

## SCRIPTS

- `run_create_plots_paper.py`: python script used for generating the plots for the paper (bigger labels, bigger texts, compressed bar plots)

- `run_create_plots_thesis.py`: python script used for generating the plots for the thesis PDF (bigger labels, bigger texts)

- `run_create_plots.py`: python script that reads the results from a txt file and generates plots resuming the results of the training.

- `run_create_table.py`: python script that reads the results from a txt file and generates a table resuming the results of the training.

- `run_training`: python script used for loading the MNIST dataset, maintain sync with the camera, display the image on the screen and send a labelto the camera.

- `Train_MINST_half_pruned.ipynb`: jupyter notebook used for training a model on the recognition of half digits from 0 to 5 of the MNIST dataset. Additionally it performs pruning and quantization of the frozen model.

- `Train_MINST_half.ipynb`: jupyter notebook used for training a model on the recognition of half digits from 0 to 5 of the MNIST dataset. 

- `TrainOL_simulation.ipynb`: jupyter notebook used for simulating the continual learning algorithm on a CNN model.

# HOW TO RUN THE CODE

In order to reproduce correctly the OpenMV project some steps are necessary. 

- Train a model to recognize only half of the digits. This can be done in [this](https://github.com/AlessandroAvi/Master_Thesis/blob/main/OpenMV_application/Scripts/Trainings/Train_MNIST_half.ipynb) jupyter notebook. It will also automatically save the trained model and the last layer (as a txt file) in a specific directory.
- Load the trained model on the OpenMV camera. Simply follow the instructions in [this](https://github.com/AlessandroAvi/Master_Thesis/tree/main/OpenMV_application/Documentation) power point. 
- Load in the SD card of the OpenMV cam the library called `OpenMV_myLib.py` and the two files in which weights and biases of the last layer are saved. These two files are called `ll_weights.txt` and `ll_biases.txt`. 
- Flash on the camera the main code that I developed, which is called `OpenMV_OL_training_sync.py` 
- Is now very important to connect the camera to the PC but do not connect it to the IDE (do not press the button in the bottom left corner of the IDE). This because my script uses the UART connection for sending the true labels, which is not possible in debugging mode (camera connected to the IDE) because the UART connection is usually used by the IDE for sending the video stream from the OpenMV to the laptop. 
- Now for performing the training simply run the code `run_training.py`, point the camera to the SYNC APP window and toggle the bar in the training mode. Once the bar is toggled the script automatically syncs with the camera and shows the image on screen + sends the label to the camera.

# GOOD TO KNOW

Here are some useful links for understanding some problems I had on the camera. In general by searching in the forum it's quite easy to find the answer. If nothing can be found the developer are very quick to answer new issues.

- In order to read files written from the camera on the SD (like a txt file) it's necessary to unplug and plug again hte camera. [See link here](https://forums.openmv.io/t/saving-a-txt-file/700)
- In order to use the COM port for sending data from the PC to the camera it's necessary to load the scipr on the camera as a main.py file and not use the IDE. This because the connection camera-IDE turns the camera in debugging mode, which will use the COM port to send the video stream and other things, so the UART communication is occupied (or use the externa pins on the camera for the UART). See these [link 1](https://forums.openmv.io/t/usb-vcp-acces-denied-with-pyserial/2026) [link 2](https://forums.openmv.io/t/is-the-serial-terminal-in-ide-output-only/850/3) [link 3](https://forums.openmv.io/search?q=serial%20)
- The toolchain developed by students in the Embedded systems lab for flashing the firmware with a trained neural network the camera allows the use of tensorflow 2.4 or lower. (Because the tool fro STM CUBE accepts only this one). To avoid the error train the model with tenworflow 2.4 from the beginning.

