{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8g3_OkUNOuD"
   },
   "source": [
    "## **Import the TensorFlow library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKk-D3IZkkbE"
   },
   "source": [
    "This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to eb applied on the OpenMV camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3311,
     "status": "ok",
     "timestamp": 1642669899172,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XCqcQuaBLNgF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv \n",
    "import tempfile\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8C9aeAMdSE"
   },
   "source": [
    "Load MNIST dataset and split in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1642669899176,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mNfeJ2bbNDET",
    "outputId": "48aa2ce4-cace-4979-af5d-d0db989bf648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset shapes are\n",
      "    Train dataset shape: (60000, 28, 28)\n",
      "    Test dataset shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "print('The original dataset shapes are')\n",
    "print(f'    Train dataset shape: {data_train.shape}')\n",
    "print(f'    Test dataset shape:  {data_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaAIs1HlrltM"
   },
   "source": [
    "Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1642669900033,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wjQCPI7FTr2H",
    "outputId": "2472a0c4-13f7-4810-b622-437141c61dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:\n",
      "     Train dataset lower than 6 has shape:  (36017, 28, 28)\n",
      "     Train dataset higher than 6 has shape: (23983, 28, 28)\n",
      "\n",
      "     Test dataset lower than 6 has shape:  (6031, 28, 28)\n",
      "     Test dataset higher than 6 has shape: (3969, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_samples = label_train.shape[0]\n",
    "test_samples  = label_test.shape[0]\n",
    "\n",
    "trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n",
    "testLow_samples = np.sum(np.where(label_test <  6, 1, 0))\n",
    "\n",
    "# separate in containers data that is lower nad higer than 6\n",
    "data_low_train   = np.zeros([trainLow_samples,28,28])\n",
    "label_low_train  = np.zeros(trainLow_samples)\n",
    "data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n",
    "label_high_train = np.zeros(train_samples-trainLow_samples)\n",
    "\n",
    "data_low_test   = np.zeros([testLow_samples,28,28])\n",
    "label_low_test  = np.zeros(testLow_samples)\n",
    "data_high_test  = np.zeros([test_samples-testLow_samples,28,28])\n",
    "label_high_test = np.zeros(test_samples-testLow_samples)\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,train_samples):  \n",
    "    if(label_train[i]<6):\n",
    "        data_low_train[j,:,:] = data_train[i,:,:]\n",
    "        label_low_train[j]    = label_train[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_train[k,:,:] = data_train[i,:,:]\n",
    "        label_high_train[k]    = label_train[i]\n",
    "        k+=1\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,test_samples):  \n",
    "    if(label_test[i]<6):\n",
    "        data_low_test[j,:,:] = data_test[i,:,:]\n",
    "        label_low_test[j]    = label_test[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_test[k,:,:] = data_test[i,:,:]\n",
    "        label_high_test[k]    = label_test[i]\n",
    "        k+=1\n",
    "\n",
    "print('After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:')\n",
    "print(f'     Train dataset lower than 6 has shape:  {data_low_train.shape}')\n",
    "print(f'     Train dataset higher than 6 has shape: {data_high_train.shape}')\n",
    "print()\n",
    "print(f'     Test dataset lower than 6 has shape:  {data_low_test.shape}')\n",
    "print(f'     Test dataset higher than 6 has shape: {data_high_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1642669900037,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "bgVHZlEqqBr7",
    "outputId": "bcad13ec-918c-4cad-c1b7-fb8a8a298161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly check if dataset that I created are filled correctly\n",
    "num = int(random.uniform(0,trainLow_samples))\n",
    "plt.imshow(data_low_train[num], cmap=\"gray\") # Import the image\n",
    "print(label_low_train[num])\n",
    "plt.show() # Plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTx7YrtENh3F"
   },
   "source": [
    "## **Pre process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1642669900041,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "lU_tKzkCse1H"
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1642669900044,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "c2TsbEYpU-p2"
   },
   "outputs": [],
   "source": [
    "# Something I don't know\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_low_train  = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_low_test   = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_test  = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape     = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_low_train  = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_low_test   = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_test  = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape     = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NZNND6XFXFw"
   },
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1642669900796,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "eE5Ju7QbRDBF"
   },
   "outputs": [],
   "source": [
    "data_low_train  = data_low_train.astype(np.float32) / 255.0\n",
    "data_high_train = data_high_train.astype(np.float32) / 255.0\n",
    "data_low_test   = data_low_test.astype(np.float32) / 255.0\n",
    "data_high_test  = data_high_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNaCD_O0RPDs"
   },
   "source": [
    "## **BUILD THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1642669900799,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "dewlaeUUlFpw"
   },
   "outputs": [],
   "source": [
    "TRAIN_MODEL_1 = False\n",
    "TRAIN_MODEL_2 = False\n",
    "TRAIN_MODEL_3 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1642669900801,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "VkSwp6sOFXF6"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs     = 40\n",
    "validation_split = 0.1\n",
    "optimizer  = \"adam\"\n",
    "loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics    = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1642669901174,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "vZVNdEatp8L2",
    "outputId": "699d1a6b-5a3d-48ff-9af3-6ce3fc0dfbc7"
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(8, kernel_size=(3,3), activation='relu',input_shape=input_shape))\n",
    "    model.add(Conv2D(8, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if(TRAIN_MODEL_1):\n",
    "    #tf.keras.utils.plot_model(model, show_shapes=True, to_file='naive_inception_module.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1642669901176,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Cige2fQHFXGB"
   },
   "outputs": [],
   "source": [
    "# METHOD 2\n",
    "# This model is a bit larger and should be much more precise in the feature extraction\n",
    "if(TRAIN_MODEL_2):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, (3, 3), input_shape = input_shape))\n",
    "    model2.add(Conv2D(32, (3, 3), activation = \"relu\"))\n",
    "    model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(128, activation = \"relu\"))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "    model2.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 24)   792         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 24)   600         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 24)   5208        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 48)   0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 48)   0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 24)   1176        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 24)   600         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 14, 24)   5208        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 48)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 48)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 24)     1176        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 24)     600         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 24)     5208        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 48)     0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 48)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            294         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,182\n",
      "Trainable params: 21,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if(TRAIN_MODEL_3):\n",
    "\n",
    "    l = tf.keras.layers # syntax shortcut\n",
    "\n",
    "    def fire(x, squeeze, expand):\n",
    "        y = l.Conv2D(filters=squeeze, kernel_size=1, padding='same', activation='relu')(x)\n",
    "        y1 = l.Conv2D(filters=expand//2, kernel_size=1, padding='same', activation='relu')(y)\n",
    "        y3 = l.Conv2D(filters=expand//2, kernel_size=3, padding='same', activation='relu')(y)\n",
    "        return tf.keras.layers.concatenate([y1, y3])\n",
    "\n",
    "    # this is to make it behave similarly to other Keras layers\n",
    "    def fire_module(squeeze, expand):\n",
    "        return lambda x: fire(x, squeeze, expand)\n",
    "\n",
    "    # usage:\n",
    "    x = tf.keras.layers.Input(shape=[*input_shape]) # input is 192x192 pixels RGB\n",
    "\n",
    "    y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(x)\n",
    "    y = fire_module(24, 48)(y)\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(24, 48)(y)\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(24, 48)(y)\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D()(y)\n",
    "    y = tf.keras.layers.Dense(6, activation='softmax')(y)\n",
    "\n",
    "    model3 = tf.keras.Model(x, y)\n",
    "    model3.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_3CoNfUFXGE"
   },
   "source": [
    "## TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144034,
     "status": "ok",
     "timestamp": 1642670045191,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZRk1oPJmTCM2",
    "outputId": "b430d7c3-48c9-411c-d362-2e1d61802dfc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model.fit(data_low_train, label_low_train, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n",
    "\n",
    "  # Evaluate the model performance\n",
    "    test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1642670045193,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "h_oS2hh3FXGO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_2):\n",
    "\n",
    "    labels_prova = keras.utils.to_categorical(label_low_train, 6)\n",
    "\n",
    "    model2.fit(data_low_train, labels_prova, epochs = epochs, batch_size = batch_size, validation_split = validation_split )\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    test_loss, test_acc = model2.evaluate(data_low_test, keras.utils.to_categorical(label_low_test, 6))\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1013/1013 [==============================] - 60s 59ms/step - loss: 0.5011 - accuracy: 0.8144 - val_loss: 0.1427 - val_accuracy: 0.9570\n",
      "Epoch 2/40\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 0.1294 - accuracy: 0.9603 - val_loss: 0.1065 - val_accuracy: 0.9659\n",
      "Epoch 3/40\n",
      "1013/1013 [==============================] - 85s 83ms/step - loss: 0.0881 - accuracy: 0.9728 - val_loss: 0.0657 - val_accuracy: 0.9797\n",
      "Epoch 4/40\n",
      "1013/1013 [==============================] - 84s 82ms/step - loss: 0.0670 - accuracy: 0.9795 - val_loss: 0.0532 - val_accuracy: 0.9822\n",
      "Epoch 5/40\n",
      "1013/1013 [==============================] - 83s 82ms/step - loss: 0.0537 - accuracy: 0.9840 - val_loss: 0.0376 - val_accuracy: 0.9897\n",
      "Epoch 6/40\n",
      "1013/1013 [==============================] - 87s 86ms/step - loss: 0.0456 - accuracy: 0.9853 - val_loss: 0.0297 - val_accuracy: 0.9925\n",
      "Epoch 7/40\n",
      "1013/1013 [==============================] - 83s 82ms/step - loss: 0.0381 - accuracy: 0.9886 - val_loss: 0.0373 - val_accuracy: 0.9906\n",
      "Epoch 8/40\n",
      "1013/1013 [==============================] - 84s 83ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0274 - val_accuracy: 0.9919\n",
      "Epoch 9/40\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
      "Epoch 10/40\n",
      "1013/1013 [==============================] - 65s 64ms/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.0333 - val_accuracy: 0.9911\n",
      "Epoch 11/40\n",
      "1013/1013 [==============================] - 68s 67ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.0258 - val_accuracy: 0.9931\n",
      "Epoch 12/40\n",
      "1013/1013 [==============================] - 47s 46ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0341 - val_accuracy: 0.9914\n",
      "Epoch 13/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 14/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0364 - val_accuracy: 0.9903\n",
      "Epoch 15/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0282 - val_accuracy: 0.9922\n",
      "Epoch 16/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.0177 - val_accuracy: 0.9950\n",
      "Epoch 17/40\n",
      "1013/1013 [==============================] - 46s 45ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0182 - val_accuracy: 0.9950\n",
      "Epoch 18/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0239 - val_accuracy: 0.9939\n",
      "Epoch 19/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0303 - val_accuracy: 0.9931\n",
      "Epoch 20/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0166 - val_accuracy: 0.9972\n",
      "Epoch 21/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0184 - val_accuracy: 0.9956\n",
      "Epoch 22/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0214 - val_accuracy: 0.9956\n",
      "Epoch 23/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0285 - val_accuracy: 0.9928\n",
      "Epoch 24/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0234 - val_accuracy: 0.9944\n",
      "Epoch 25/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0193 - val_accuracy: 0.9958\n",
      "Epoch 26/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0174 - val_accuracy: 0.9964\n",
      "Epoch 27/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0185 - val_accuracy: 0.9956\n",
      "Epoch 28/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0357 - val_accuracy: 0.9942\n",
      "Epoch 29/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0178 - val_accuracy: 0.9969\n",
      "Epoch 30/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0345 - val_accuracy: 0.9936\n",
      "Epoch 31/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0237 - val_accuracy: 0.9956\n",
      "Epoch 32/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0175 - val_accuracy: 0.9964\n",
      "Epoch 33/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0191 - val_accuracy: 0.9958\n",
      "Epoch 34/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0363 - val_accuracy: 0.9928\n",
      "Epoch 35/40\n",
      "1013/1013 [==============================] - 45s 45ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0231 - val_accuracy: 0.9958\n",
      "Epoch 36/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0326 - val_accuracy: 0.9947\n",
      "Epoch 37/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0276 - val_accuracy: 0.9944\n",
      "Epoch 38/40\n",
      "1013/1013 [==============================] - 45s 44ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0280 - val_accuracy: 0.9958\n",
      "Epoch 39/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0248 - val_accuracy: 0.9950\n",
      "Epoch 40/40\n",
      "1013/1013 [==============================] - 44s 44ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0156 - val_accuracy: 0.9969\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_49068/3644629665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;31m# Evaluate the model performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_low_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_low_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTest accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Print out the model accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "if(TRAIN_MODEL_3):\n",
    "    \n",
    "    labels_modified = keras.utils.to_categorical(label_low_train, 6)\n",
    "    \n",
    "    model3.fit(data_low_train, labels_modified, epochs = epochs, batch_size = batch_size, validation_split = validation_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 2s 10ms/step - loss: 0.0120 - accuracy: 0.9970\n",
      "\n",
      "Test accuracy: 0.9970154166221619\n"
     ]
    }
   ],
   "source": [
    "if(TRAIN_MODEL_3):\n",
    "    \n",
    "    labels_modified_test = keras.utils.to_categorical(label_low_test, 6)\n",
    "\n",
    "# Evaluate the model performance\n",
    "    test_loss, test_acc = model3.evaluate(data_low_test, labels_modified_test)\n",
    "\n",
    "    print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI3aR1l4pqhS"
   },
   "source": [
    "## TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1642670045194,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "AVNdx-gjlhze"
   },
   "outputs": [],
   "source": [
    "if(TRAIN_MODEL_1):\n",
    "    model_test = model\n",
    "elif(TRAIN_MODEL_2):\n",
    "    model_test = model2\n",
    "elif(TRAIN_MODEL_3):\n",
    "    model_test = model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 33ms/step - loss: 0.0120 - accuracy: 0.9970\n",
      "test loss, test acc: [0.012002740055322647, 0.9970154166221619]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow evaluation on the test dataset\n",
    "results = model_test.evaluate(data_low_test, labels_modified_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1642670045883,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "piwc0fbspvlc"
   },
   "outputs": [],
   "source": [
    "predictions = model_test.predict(data_low_test)   # Make prediction of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1642670045885,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y9R_XtjSrO2g",
    "outputId": "38a3a49f-7a7b-40b9-dc06-1d191479e0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  3\n",
      "True label =  3.0\n"
     ]
    }
   ],
   "source": [
    "num = int(random.uniform(0,data_low_test.shape[0]))\n",
    "print(\"Prediction = \" , np.argmax(predictions[num]))\n",
    "print(\"True label = \" , label_low_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1642670045887,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "2Uj_jf6-jCGj"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    class_names = ['0','1','2','3','4','5']\n",
    "\n",
    "    true_label, img = int(true_label[i]), img[i,:,:]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = (np.squeeze(img))## you have to delete the channel information (if grayscale) to plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)   \n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(6))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1642670045888,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "_L_MP6pejCGk",
    "outputId": "d173a92a-dab6-46ac-9f8d-05edbb8b5b7e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = int(random.uniform(0, predictions.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plot_image(num, predictions[num], label_low_test, data_low_test)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plot_value_array(num, predictions[num], label_low_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye7xyl_-vkkk"
   },
   "source": [
    "## **SAVE ORIGINAL MODEL AND FROZEN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1642670045890,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ADvJBmeEFXGf"
   },
   "outputs": [],
   "source": [
    "def save_summary_model(model, MODEL_PATH, flag):\n",
    "    new_file = open(MODEL_PATH + 'model_summary.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    if(flag==0):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the ORIGINAL MODEL\")\n",
    "    elif(flag==1):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the FROZEN MODEL\")\n",
    "    new_file.write(\"\\n\")\n",
    "    new_file.write(\"\\n Batch size:       \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs:           \" + str(epochs))\n",
    "    new_file.write(\"\\n Metrics:          \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer:        \" + optimizer)\n",
    "    new_file.write(\"\\n Loss:             \" + \"SparseCategoricalCrossentropy \\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1642670046245,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "rjFdtesdvqzf",
    "outputId": "273832e4-7e4a-4008-ef73-0a1e9c15a38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.012002735398709774\n",
      "Test accuracy: 0.9970154166221619\n",
      "Save ORIGINAL MODEL as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath('')\n",
    "SAVE_MODEL_PATH = ROOT_PATH + \"\\\\Saved_models\\\\Backup_models\\\\Last_trained_model\"\n",
    "\n",
    "ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Original_model\\\\\" \n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Save ORIGINAL MODEL as mnist_cnn.h5')\n",
    "model_test.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model_test, ORIGINAL_MODEL_PATH, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nPOwtTnFXGk"
   },
   "source": [
    "Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk84TZDvyjW4"
   },
   "source": [
    "### SAVE THE FROZEN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1642670046247,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "qQzEf-OKFXGl",
    "outputId": "e17c094d-1148-44e2-b9d0-552eb712dd85"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A merge layer should be called on a list of inputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_49068/4145317313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CREATE AND SAVE THE FROZEN MODEL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfrozen_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfrozen_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfrozen_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    219\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    120\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A merge layer should be called on a list of inputs.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape_required\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m       \u001b[0mreshaped_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A merge layer should be called on a list of inputs."
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE THE FROZEN MODEL\n",
    "frozen_model = keras.models.Sequential(model_test.layers[:-1])\n",
    "frozen_model.summary()\n",
    "frozen_model.compile()\n",
    "\n",
    "FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_model\\\\\"\n",
    "\n",
    "print('Save FROZEN MODEL model as mnist_cnn.h5')\n",
    "frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(frozen_model, FROZEN_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1wsEHInFXGn"
   },
   "source": [
    "Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1642670046248,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "NOvcRsOVFXGn",
    "outputId": "3f3446d3-a168-4256-eff5-72969162d8b9"
   },
   "outputs": [],
   "source": [
    "ll_weights = np.array(model_test.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model_test.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jSSceEYKsHX"
   },
   "source": [
    "## PRUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86fkMkzrFXGs"
   },
   "source": [
    "https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3384,
     "status": "ok",
     "timestamp": 1642670049623,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wM4PKTiCFXGw"
   },
   "outputs": [],
   "source": [
    "# Install needed optimization toolkit\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1123,
     "status": "ok",
     "timestamp": 1642670050700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "oxawOG-5FXGy",
    "outputId": "50a0d265-ca20-4fdf-9a4f-710c33b603a1"
   },
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after n epochs.\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "validation_split = 0.1  # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = data_low_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model_test, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "\n",
    "# Select appropriate optimizer\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251734,
     "status": "ok",
     "timestamp": 1642670302425,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "f8YgeDcrFXG2",
    "outputId": "6a50bfea-5684-4f5e-a633-bcd833a1491d"
   },
   "outputs": [],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(data_low_train, label_low_train,\n",
    "                    batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1642670303234,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "IHJW7bkYLiOV",
    "outputId": "3c14850f-33a8-4d9c-93cb-bd08c3789463"
   },
   "outputs": [],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(data_low_test, label_low_test, verbose=0)\n",
    "\n",
    "print('Original test accuracy: ', test_acc)\n",
    "print('Pruned test accuracy:   ', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIAK-1EJK6Z_"
   },
   "source": [
    "## CREATE A x3 SMALLER MODEL FROM PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1642670303235,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "E_MqIPRtFXG3",
    "outputId": "3fd08389-cd6e-42a4-da3d-d8127047ce17"
   },
   "outputs": [],
   "source": [
    "# First, create a compressible model for TensorFlow\n",
    "\n",
    "PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Pruned_model\\\\\"\n",
    "\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.save(PRUNED_MODEL_PATH + 'Pruned_cnn.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2178,
     "status": "ok",
     "timestamp": 1642670305406,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XLBF9aRvFXG5",
    "outputId": "91b4b562-8d2f-4d13-dbd6-3563ffda612e"
   },
   "outputs": [],
   "source": [
    "# Then, create a compressible model for TFLite\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "with open(PRUNED_MODEL_PATH + 'Pruned_cnn.tflite', 'wb') as f:\n",
    "    f.write(pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1642670305409,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "FAh4chQQMdVJ"
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1642670423546,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "oiLalXuSMSwF",
    "outputId": "e9f8d3d6-2791-4993-b4e6-f306e3a6d2fc"
   },
   "outputs": [],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n",
    "print(\"Size of gzipped pruned Keras model  : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + 'Pruned_cnn.h5')))\n",
    "print(\"Size of gzipped pruned TFlite model : %.2f bytes\" % (get_gzipped_model_size(PRUNED_MODEL_PATH + 'Pruned_cnn.tflite')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi4RUhtOPUKr"
   },
   "source": [
    "## CREATE A 10x SMALLER MODEL, COMBINE PRUNING WITH QUANTIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/lite/performance/post_training_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2209,
     "status": "ok",
     "timestamp": 1642670670389,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "X_xSV0ZePY7S",
    "outputId": "f246574c-06df-4a52-d680-cef893dfd630"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export) # load the converter\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.h5')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model             : %.2f bytes\" % (get_gzipped_model_size(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFG2-AhwyZsZ"
   },
   "source": [
    "## SAVE THE FROZEN MODEL VERSION OF THE PRUNED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1642670675487,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "CF1fpU3RyoPj",
    "outputId": "1dd42723-a73d-4fa1-d73b-9de69a931cd2"
   },
   "outputs": [],
   "source": [
    "frozen_pruned_model = keras.models.Sequential(model_for_pruning.layers[:-1])\n",
    "frozen_pruned_model.summary()\n",
    "frozen_pruned_model.compile()\n",
    "\n",
    "FROZEN_PRUNED_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_Pruned_model\\\\\"\n",
    "\n",
    "print('Save FROZEN PRUNED MODEL model as Frozen_pruned_cnn.h5')\n",
    "frozen_model.save(FROZEN_PRUNED_MODEL_PATH + \"Frozen_pruned_cnn.h5\")\n",
    "save_summary_model(frozen_pruned_model, FROZEN_PRUNED_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1642670683191,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZDFF5jp6yslG",
    "outputId": "1cc4e095-5cd5-479f-c8c0-15756665f544"
   },
   "outputs": [],
   "source": [
    "ll_weights = np.array(model_for_pruning.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model_for_pruning.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_PRUNED_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_PRUNED_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lu1ooRLcwAwb"
   },
   "source": [
    "## DOWNLOAD ENTIIRE MODEL DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1642670707129,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y6PSAT4AQCwq",
    "outputId": "eadd7971-b925-45d8-83a8-2771ec6cb6fd"
   },
   "outputs": [],
   "source": [
    "#%cd '/content'\n",
    "#from google.colab import files\n",
    "#import shutil\n",
    "#shutil.make_archive('Colab_models', 'zip', 'Models')\n",
    "#files.download('Colab_models.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd2AzXoKzc6l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_MNIST_half.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
