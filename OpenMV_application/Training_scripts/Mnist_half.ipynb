{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8g3_OkUNOuD"
   },
   "source": [
    "## **Import the TensorFlow library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKk-D3IZkkbE"
   },
   "source": [
    "This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to eb applied on the OpenMV camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1674,
     "status": "ok",
     "timestamp": 1636125291944,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XCqcQuaBLNgF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8C9aeAMdSE"
   },
   "source": [
    "Load MNIST dataset and split in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1636125292418,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mNfeJ2bbNDET",
    "outputId": "606983b1-3cb4-47dc-cd7f-2594067c9536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset shapes are\n",
      "    Train dataset shape: (60000, 28, 28)\n",
      "    Test dataset shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "print('The original dataset shapes are')\n",
    "print(f'    Train dataset shape: {data_train.shape}')\n",
    "print(f'    Test dataset shape:  {data_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaAIs1HlrltM"
   },
   "source": [
    "Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1636125293501,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wjQCPI7FTr2H",
    "outputId": "ef9f907e-5961-4f6a-e438-b894251c263c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:\n",
      "     Train dataset lower than 6 has shape:  (36017, 28, 28)\n",
      "     Train dataset higher than 6 has shape: (23983, 28, 28)\n",
      "\n",
      "     Test dataset lower than 6 has shape:  (6031, 28, 28)\n",
      "     Test dataset higher than 6 has shape: (3969, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_samples = label_train.shape[0]\n",
    "test_samples  = label_test.shape[0]\n",
    "\n",
    "trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n",
    "testLow_samples = np.sum(np.where(label_test <  6, 1, 0))\n",
    "\n",
    "# separate in containers data that is lower nad higer than 6\n",
    "data_low_train   = np.zeros([trainLow_samples,28,28])\n",
    "label_low_train  = np.zeros(trainLow_samples)\n",
    "data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n",
    "label_high_train = np.zeros(train_samples-trainLow_samples)\n",
    "\n",
    "data_low_test   = np.zeros([testLow_samples,28,28])\n",
    "label_low_test  = np.zeros(testLow_samples)\n",
    "data_high_test  = np.zeros([test_samples-testLow_samples,28,28])\n",
    "label_high_test = np.zeros(test_samples-testLow_samples)\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,train_samples):  \n",
    "    if(label_train[i]<6):\n",
    "        data_low_train[j,:,:] = data_train[i,:,:]\n",
    "        label_low_train[j]    = label_train[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_train[k,:,:] = data_train[i,:,:]\n",
    "        label_high_train[k]    = label_train[i]\n",
    "        k+=1\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,test_samples):  \n",
    "    if(label_test[i]<6):\n",
    "        data_low_test[j,:,:] = data_test[i,:,:]\n",
    "        label_low_test[j]    = label_test[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_test[k,:,:] = data_test[i,:,:]\n",
    "        label_high_test[k]    = label_test[i]\n",
    "        k+=1\n",
    "\n",
    "print('After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:')\n",
    "print(f'     Train dataset lower than 6 has shape:  {data_low_train.shape}')\n",
    "print(f'     Train dataset higher than 6 has shape: {data_high_train.shape}')\n",
    "print()\n",
    "print(f'     Test dataset lower than 6 has shape:  {data_low_test.shape}')\n",
    "print(f'     Test dataset higher than 6 has shape: {data_high_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1636125293502,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "bgVHZlEqqBr7",
    "outputId": "28486df0-9dfe-4765-d6f3-99f928d59445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly check if dataset that I created are filled correctly\n",
    "num = int(random.uniform(0,trainLow_samples))\n",
    "plt.imshow(data_low_train[num], cmap=\"gray\") # Import the image\n",
    "print(label_low_train[num])\n",
    "plt.show() # Plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTx7YrtENh3F"
   },
   "source": [
    "## **Pre process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "lU_tKzkCse1H"
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "c2TsbEYpU-p2"
   },
   "outputs": [],
   "source": [
    "# Something I don't know\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293504,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "eE5Ju7QbRDBF"
   },
   "outputs": [],
   "source": [
    "data_low_train  = data_low_train.astype(np.float32) / 255.0\n",
    "data_high_train = data_high_train.astype(np.float32) / 255.0\n",
    "data_low_test   = data_low_test.astype(np.float32) / 255.0\n",
    "data_high_test  = data_high_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNaCD_O0RPDs"
   },
   "source": [
    "## **Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "epochs     = 30\n",
    "optimizer  = \"adam\"\n",
    "loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics    = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1636125294415,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "8pfF6SCiRUjB"
   },
   "outputs": [],
   "source": [
    "# METHOD 1\n",
    "# Define the model architecture\n",
    "#model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "#    tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(6, activation = \"softmax\")\n",
    "#])\n",
    "\n",
    "#model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=12, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12174     \n",
      "=================================================================\n",
      "Total params: 12,294\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "executionInfo": {
     "elapsed": 1293,
     "status": "error",
     "timestamp": 1636125295704,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZRk1oPJmTCM2",
    "outputId": "ddc8832c-c895-4dc8-ffcf-7a119c04dfce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "541/541 [==============================] - 12s 23ms/step - loss: 1.1651 - accuracy: 0.9073 - val_loss: 1.0910 - val_accuracy: 0.9572\n",
      "Epoch 2/30\n",
      "541/541 [==============================] - 11s 20ms/step - loss: 1.0902 - accuracy: 0.9582 - val_loss: 1.0781 - val_accuracy: 0.9678\n",
      "Epoch 3/30\n",
      "541/541 [==============================] - 9s 16ms/step - loss: 1.0778 - accuracy: 0.9694 - val_loss: 1.0692 - val_accuracy: 0.9775\n",
      "Epoch 4/30\n",
      "541/541 [==============================] - 11s 20ms/step - loss: 1.0696 - accuracy: 0.9774 - val_loss: 1.0629 - val_accuracy: 0.9850\n",
      "Epoch 5/30\n",
      "541/541 [==============================] - 10s 19ms/step - loss: 1.0645 - accuracy: 0.9826 - val_loss: 1.0627 - val_accuracy: 0.9817\n",
      "Epoch 6/30\n",
      "541/541 [==============================] - 9s 17ms/step - loss: 1.0615 - accuracy: 0.9854 - val_loss: 1.0586 - val_accuracy: 0.9870\n",
      "Epoch 7/30\n",
      "541/541 [==============================] - 10s 19ms/step - loss: 1.0593 - accuracy: 0.9870 - val_loss: 1.0574 - val_accuracy: 0.9883\n",
      "Epoch 8/30\n",
      "541/541 [==============================] - 11s 20ms/step - loss: 1.0580 - accuracy: 0.9880 - val_loss: 1.0576 - val_accuracy: 0.9878\n",
      "Epoch 9/30\n",
      "541/541 [==============================] - 11s 21ms/step - loss: 1.0566 - accuracy: 0.9895 - val_loss: 1.0567 - val_accuracy: 0.9883\n",
      "Epoch 10/30\n",
      "541/541 [==============================] - 12s 22ms/step - loss: 1.0553 - accuracy: 0.9906 - val_loss: 1.0560 - val_accuracy: 0.9886\n",
      "Epoch 11/30\n",
      "541/541 [==============================] - 9s 18ms/step - loss: 1.0545 - accuracy: 0.9912 - val_loss: 1.0547 - val_accuracy: 0.9914\n",
      "Epoch 12/30\n",
      "541/541 [==============================] - 11s 21ms/step - loss: 1.0535 - accuracy: 0.9920 - val_loss: 1.0547 - val_accuracy: 0.9908\n",
      "Epoch 13/30\n",
      "541/541 [==============================] - 11s 21ms/step - loss: 1.0529 - accuracy: 0.9923 - val_loss: 1.0544 - val_accuracy: 0.9903\n",
      "Epoch 14/30\n",
      "541/541 [==============================] - 10s 19ms/step - loss: 1.0525 - accuracy: 0.9927 - val_loss: 1.0543 - val_accuracy: 0.9908\n",
      "Epoch 15/30\n",
      "541/541 [==============================] - 9s 17ms/step - loss: 1.0519 - accuracy: 0.9933 - val_loss: 1.0543 - val_accuracy: 0.9914\n",
      "Epoch 16/30\n",
      "541/541 [==============================] - 11s 20ms/step - loss: 1.0515 - accuracy: 0.9935 - val_loss: 1.0555 - val_accuracy: 0.9889\n",
      "Epoch 17/30\n",
      "541/541 [==============================] - 11s 20ms/step - loss: 1.0507 - accuracy: 0.9945 - val_loss: 1.0542 - val_accuracy: 0.9906\n",
      "Epoch 18/30\n",
      "541/541 [==============================] - 12s 22ms/step - loss: 1.0503 - accuracy: 0.9947 - val_loss: 1.0542 - val_accuracy: 0.9892\n",
      "Epoch 19/30\n",
      "541/541 [==============================] - 10s 19ms/step - loss: 1.0498 - accuracy: 0.9952 - val_loss: 1.0550 - val_accuracy: 0.9897\n",
      "Epoch 20/30\n",
      "541/541 [==============================] - 8s 14ms/step - loss: 1.0497 - accuracy: 0.9950 - val_loss: 1.0538 - val_accuracy: 0.9917\n",
      "Epoch 21/30\n",
      "541/541 [==============================] - 8s 15ms/step - loss: 1.0493 - accuracy: 0.9956 - val_loss: 1.0536 - val_accuracy: 0.9906\n",
      "Epoch 22/30\n",
      "541/541 [==============================] - 8s 14ms/step - loss: 1.0488 - accuracy: 0.9959 - val_loss: 1.0542 - val_accuracy: 0.9908\n",
      "Epoch 23/30\n",
      "541/541 [==============================] - 8s 15ms/step - loss: 1.0486 - accuracy: 0.9962 - val_loss: 1.0531 - val_accuracy: 0.9914\n",
      "Epoch 24/30\n",
      "541/541 [==============================] - 9s 17ms/step - loss: 1.0483 - accuracy: 0.9962 - val_loss: 1.0541 - val_accuracy: 0.9906\n",
      "Epoch 25/30\n",
      "541/541 [==============================] - 8s 15ms/step - loss: 1.0480 - accuracy: 0.9965 - val_loss: 1.0532 - val_accuracy: 0.9906\n",
      "Epoch 26/30\n",
      "541/541 [==============================] - 8s 14ms/step - loss: 1.0478 - accuracy: 0.9968 - val_loss: 1.0533 - val_accuracy: 0.9903\n",
      "Epoch 27/30\n",
      "541/541 [==============================] - 8s 14ms/step - loss: 1.0477 - accuracy: 0.9967 - val_loss: 1.0529 - val_accuracy: 0.9922\n",
      "Epoch 28/30\n",
      "541/541 [==============================] - 8s 15ms/step - loss: 1.0474 - accuracy: 0.9971 - val_loss: 1.0526 - val_accuracy: 0.9914\n",
      "Epoch 29/30\n",
      "541/541 [==============================] - 8s 15ms/step - loss: 1.0474 - accuracy: 0.9969 - val_loss: 1.0527 - val_accuracy: 0.9917\n",
      "Epoch 30/30\n",
      "541/541 [==============================] - 8s 16ms/step - loss: 1.0473 - accuracy: 0.9970 - val_loss: 1.0521 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2501fc3e2e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data_low_train,\n",
    "    label_low_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "aborted",
     "timestamp": 1636125295698,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mq9bBd-3pfgL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 4ms/step - loss: 1.0515 - accuracy: 0.9930\n",
      "\n",
      "Test accuracy: 0.9930359721183777\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI3aR1l4pqhS"
   },
   "source": [
    "# **Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295699,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "piwc0fbspvlc"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(data_low_test)   # Make prediction of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y9R_XtjSrO2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  5\n",
      "True label =  5.0\n"
     ]
    }
   ],
   "source": [
    "num = int(random.uniform(0,data_low_test.shape[0]))\n",
    "print(\"Prediction = \" , np.argmax(predictions[num]))\n",
    "print(\"True label = \" , label_low_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "2Uj_jf6-jCGj"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    class_names = ['0','1','2','3','4','5']\n",
    "\n",
    "    true_label, img = int(true_label[i]), img[i,:,:]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = (np.squeeze(img))## you have to delete the channel information (if grayscale) to plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)   \n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(6))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "_L_MP6pejCGk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = int(random.uniform(0, predictions.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plot_image(num, predictions[num], label_low_test, data_low_test)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plot_value_array(num, predictions[num], label_low_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye7xyl_-vkkk"
   },
   "source": [
    "## **Save models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_model(model, MODEL_PATH, flag):\n",
    "    new_file = open(MODEL_PATH + 'model_summary.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    if(flag==0):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the ORIGINAL MODEL\")\n",
    "    elif(flag==1):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the FROZEN MODEL\")\n",
    "    new_file.write(\"\\n\")\n",
    "    new_file.write(\"\\n Batch size:       \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs:           \" + str(epochs))\n",
    "    new_file.write(\"\\n Metrics:          \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer:        \" + optimizer)\n",
    "    new_file.write(\"\\n Loss:             \" + \"SparseCategoricalCrossentropy \\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "rjFdtesdvqzf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0514512062072754\n",
      "Test accuracy: 0.9930359721183777\n",
      "Save ORIGINAL MODEL as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath('')\n",
    "SAVE_MODEL_PATH = ROOT_PATH + \"\\\\Saved_models\\\\\"\n",
    "\n",
    "ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Original_model\\\\\"\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Save ORIGINAL MODEL as mnist_cnn.h5')\n",
    "model.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model, ORIGINAL_MODEL_PATH, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save FROZEN MODEL model as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE THE CUT MODEL\n",
    "frozen_model = keras.models.Sequential(model.layers[:-1])\n",
    "frozen_model.summary()\n",
    "frozen_model.compile()\n",
    "\n",
    "FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_model\\\\\"\n",
    "\n",
    "print('Save FROZEN MODEL model as mnist_cnn.h5')\n",
    "model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(frozen_model, FROZEN_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the last layer weights is: (2028, 6)\n",
      "The shape of the last layer biases is: (6,)\n"
     ]
    }
   ],
   "source": [
    "ll_weights = np.array(model.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# separate thhis file in lines of \n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciccio = np.zeros((2028,10))\n",
    "\n",
    "\n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt') as weight_file:\n",
    "    j,i = 0,0\n",
    "    for line in weight_file:\n",
    "        data = line.split(',')\n",
    "        for numbers in data:\n",
    "            ciccio[i,j] = float(numbers)\n",
    "            i += 1\n",
    "\n",
    "            if (i == 2028):\n",
    "                i=0\n",
    "                j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5364562\n",
      "0.0037534148\n",
      "0.3447123\n",
      "-0.022823092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ll_weights[0,0])\n",
    "print(ll_weights[10,1])\n",
    "print(ll_weights[157,3])\n",
    "print(ll_weights[2000,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jSSceEYKsHX"
   },
   "source": [
    "## **Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1Txju54d6yY"
   },
   "source": [
    "**Full integer quantization**\n",
    "\n",
    "For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. As a result, the converter requires a representative dataset to calibrate them. This dataset can be a small subset (around ~100-500 samples) of the training or validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "C1VewrfEKpwW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpy80xszp9\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_io = converter.convert()\n",
    "with open(\"mnist_quant_io.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkJY45mABi6w"
   },
   "source": [
    "**Integer with float fallback (using default float input/output)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "-KhP_3Y8NK6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpbzeelk_o\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpbzeelk_o\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "with open(\"mnist_quant.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Qpda9DBIvsaK"
   },
   "outputs": [],
   "source": [
    "#representative_data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "tTx9cdDdVDgX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mnist_half.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
