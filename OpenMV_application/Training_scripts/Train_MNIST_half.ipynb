{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8g3_OkUNOuD"
   },
   "source": [
    "## **Import the TensorFlow library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKk-D3IZkkbE"
   },
   "source": [
    "This code contains the training for a CNN in which the model learns to recognize the digits. This is different from the other training script because the model learns the digits from 0 to 6. The Idea is to have the digits 7,8,9 for the OL learning to eb applied on the OpenMV camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1674,
     "status": "ok",
     "timestamp": 1636125291944,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "XCqcQuaBLNgF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8C9aeAMdSE"
   },
   "source": [
    "Load MNIST dataset and split in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1636125292418,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mNfeJ2bbNDET",
    "outputId": "606983b1-3cb4-47dc-cd7f-2594067c9536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset shapes are\n",
      "    Train dataset shape: (60000, 28, 28)\n",
      "    Test dataset shape:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(data_train, label_train),(data_test, label_test) = mnist.load_data() # Load data\n",
    "print('The original dataset shapes are')\n",
    "print(f'    Train dataset shape: {data_train.shape}')\n",
    "print(f'    Test dataset shape:  {data_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaAIs1HlrltM"
   },
   "source": [
    "Split the train and test dataset in smaller datasets. Separation criterion is if the number is smaller than 6 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1636125293501,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "wjQCPI7FTr2H",
    "outputId": "ef9f907e-5961-4f6a-e438-b894251c263c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:\n",
      "     Train dataset lower than 6 has shape:  (36017, 28, 28)\n",
      "     Train dataset higher than 6 has shape: (23983, 28, 28)\n",
      "\n",
      "     Test dataset lower than 6 has shape:  (6031, 28, 28)\n",
      "     Test dataset higher than 6 has shape: (3969, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_samples = label_train.shape[0]\n",
    "test_samples  = label_test.shape[0]\n",
    "\n",
    "trainLow_samples  = np.sum(np.where(label_train < 6, 1, 0))\n",
    "testLow_samples = np.sum(np.where(label_test <  6, 1, 0))\n",
    "\n",
    "# separate in containers data that is lower nad higer than 6\n",
    "data_low_train   = np.zeros([trainLow_samples,28,28])\n",
    "label_low_train  = np.zeros(trainLow_samples)\n",
    "data_high_train  = np.zeros([train_samples-trainLow_samples,28,28])\n",
    "label_high_train = np.zeros(train_samples-trainLow_samples)\n",
    "\n",
    "data_low_test   = np.zeros([testLow_samples,28,28])\n",
    "label_low_test  = np.zeros(testLow_samples)\n",
    "data_high_test  = np.zeros([test_samples-testLow_samples,28,28])\n",
    "label_high_test = np.zeros(test_samples-testLow_samples)\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,train_samples):  \n",
    "    if(label_train[i]<6):\n",
    "        data_low_train[j,:,:] = data_train[i,:,:]\n",
    "        label_low_train[j]    = label_train[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_train[k,:,:] = data_train[i,:,:]\n",
    "        label_high_train[k]    = label_train[i]\n",
    "        k+=1\n",
    "\n",
    "j,k = 0,0\n",
    "for i in range(0,test_samples):  \n",
    "    if(label_test[i]<6):\n",
    "        data_low_test[j,:,:] = data_test[i,:,:]\n",
    "        label_low_test[j]    = label_test[i]\n",
    "        j+=1\n",
    "    else:\n",
    "        data_high_test[k,:,:] = data_test[i,:,:]\n",
    "        label_high_test[k]    = label_test[i]\n",
    "        k+=1\n",
    "\n",
    "print('After the separation of the dataset in groups higer and lower/equal than 6 the datasets are:')\n",
    "print(f'     Train dataset lower than 6 has shape:  {data_low_train.shape}')\n",
    "print(f'     Train dataset higher than 6 has shape: {data_high_train.shape}')\n",
    "print()\n",
    "print(f'     Test dataset lower than 6 has shape:  {data_low_test.shape}')\n",
    "print(f'     Test dataset higher than 6 has shape: {data_high_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1636125293502,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "bgVHZlEqqBr7",
    "outputId": "28486df0-9dfe-4765-d6f3-99f928d59445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly check if dataset that I created are filled correctly\n",
    "num = int(random.uniform(0,trainLow_samples))\n",
    "plt.imshow(data_low_train[num], cmap=\"gray\") # Import the image\n",
    "print(label_low_train[num])\n",
    "plt.show() # Plot the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTx7YrtENh3F"
   },
   "source": [
    "## **Pre process the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "lU_tKzkCse1H"
   },
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1636125293503,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "c2TsbEYpU-p2"
   },
   "outputs": [],
   "source": [
    "# Something I don't know\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], 1, img_rows, img_cols)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], 1, img_rows, img_cols)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_low_train = data_low_train.reshape(data_low_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_train = data_high_train.reshape(data_high_train.shape[0], img_rows, img_cols, 1)\n",
    "    data_low_test = data_low_test.reshape(data_low_test.shape[0], img_rows, img_cols, 1)\n",
    "    data_high_test = data_high_test.reshape(data_high_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636125293504,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "eE5Ju7QbRDBF"
   },
   "outputs": [],
   "source": [
    "data_low_train  = data_low_train.astype(np.float32) / 255.0\n",
    "data_high_train = data_high_train.astype(np.float32) / 255.0\n",
    "data_low_test   = data_low_test.astype(np.float32) / 255.0\n",
    "data_high_test  = data_high_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNaCD_O0RPDs"
   },
   "source": [
    "## **Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "epochs     = 30\n",
    "optimizer  = \"adam\"\n",
    "loss       = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics    = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1636125294415,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "8pfF6SCiRUjB"
   },
   "outputs": [],
   "source": [
    "# METHOD 1\n",
    "# Define the model architecture\n",
    "#model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "#    tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "#    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(6, activation = \"softmax\")\n",
    "#])\n",
    "\n",
    "#model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=12, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 12174     \n",
      "=================================================================\n",
      "Total params: 12,294\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "executionInfo": {
     "elapsed": 1293,
     "status": "error",
     "timestamp": 1636125295704,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "ZRk1oPJmTCM2",
    "outputId": "ddc8832c-c895-4dc8-ffcf-7a119c04dfce",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.1561 - accuracy: 0.9165 - val_loss: 1.0869 - val_accuracy: 0.9606\n",
      "Epoch 2/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0860 - accuracy: 0.9626 - val_loss: 1.0746 - val_accuracy: 0.9720\n",
      "Epoch 3/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0745 - accuracy: 0.9725 - val_loss: 1.0666 - val_accuracy: 0.9808\n",
      "Epoch 4/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0674 - accuracy: 0.9793 - val_loss: 1.0620 - val_accuracy: 0.9856\n",
      "Epoch 5/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0626 - accuracy: 0.9845 - val_loss: 1.0616 - val_accuracy: 0.9850\n",
      "Epoch 6/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0600 - accuracy: 0.9867 - val_loss: 1.0566 - val_accuracy: 0.9892\n",
      "Epoch 7/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0579 - accuracy: 0.9884 - val_loss: 1.0558 - val_accuracy: 0.9892\n",
      "Epoch 8/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0562 - accuracy: 0.9899 - val_loss: 1.0556 - val_accuracy: 0.9900\n",
      "Epoch 9/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0550 - accuracy: 0.9910 - val_loss: 1.0555 - val_accuracy: 0.9897\n",
      "Epoch 10/30\n",
      "541/541 [==============================] - 3s 5ms/step - loss: 1.0540 - accuracy: 0.9917 - val_loss: 1.0547 - val_accuracy: 0.9897\n",
      "Epoch 11/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0531 - accuracy: 0.9927 - val_loss: 1.0549 - val_accuracy: 0.9900\n",
      "Epoch 12/30\n",
      "541/541 [==============================] - 4s 7ms/step - loss: 1.0526 - accuracy: 0.9931 - val_loss: 1.0549 - val_accuracy: 0.9895\n",
      "Epoch 13/30\n",
      "541/541 [==============================] - 4s 7ms/step - loss: 1.0520 - accuracy: 0.9934 - val_loss: 1.0538 - val_accuracy: 0.9908\n",
      "Epoch 14/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0513 - accuracy: 0.9939 - val_loss: 1.0552 - val_accuracy: 0.9897\n",
      "Epoch 15/30\n",
      "541/541 [==============================] - 4s 7ms/step - loss: 1.0510 - accuracy: 0.9942 - val_loss: 1.0544 - val_accuracy: 0.9897\n",
      "Epoch 16/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0505 - accuracy: 0.9946 - val_loss: 1.0542 - val_accuracy: 0.9900\n",
      "Epoch 17/30\n",
      "541/541 [==============================] - 4s 7ms/step - loss: 1.0503 - accuracy: 0.9948 - val_loss: 1.0541 - val_accuracy: 0.9903\n",
      "Epoch 18/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0497 - accuracy: 0.9953 - val_loss: 1.0538 - val_accuracy: 0.9900\n",
      "Epoch 19/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0493 - accuracy: 0.9957 - val_loss: 1.0535 - val_accuracy: 0.9906\n",
      "Epoch 20/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0491 - accuracy: 0.9958 - val_loss: 1.0541 - val_accuracy: 0.9897\n",
      "Epoch 21/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0487 - accuracy: 0.9962 - val_loss: 1.0545 - val_accuracy: 0.9897\n",
      "Epoch 22/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0483 - accuracy: 0.9964 - val_loss: 1.0534 - val_accuracy: 0.9897\n",
      "Epoch 23/30\n",
      "541/541 [==============================] - 4s 6ms/step - loss: 1.0482 - accuracy: 0.9966 - val_loss: 1.0529 - val_accuracy: 0.9908\n",
      "Epoch 24/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0479 - accuracy: 0.9970 - val_loss: 1.0537 - val_accuracy: 0.9906\n",
      "Epoch 25/30\n",
      "541/541 [==============================] - 3s 6ms/step - loss: 1.0476 - accuracy: 0.9972 - val_loss: 1.0532 - val_accuracy: 0.9908\n",
      "Epoch 26/30\n",
      "541/541 [==============================] - 4s 8ms/step - loss: 1.0475 - accuracy: 0.9971 - val_loss: 1.0522 - val_accuracy: 0.9919\n",
      "Epoch 27/30\n",
      "541/541 [==============================] - 5s 9ms/step - loss: 1.0472 - accuracy: 0.9973 - val_loss: 1.0531 - val_accuracy: 0.9919\n",
      "Epoch 28/30\n",
      "541/541 [==============================] - 5s 9ms/step - loss: 1.0473 - accuracy: 0.9971 - val_loss: 1.0526 - val_accuracy: 0.9914\n",
      "Epoch 29/30\n",
      "541/541 [==============================] - 4s 8ms/step - loss: 1.0472 - accuracy: 0.9972 - val_loss: 1.0534 - val_accuracy: 0.9908\n",
      "Epoch 30/30\n",
      "541/541 [==============================] - 4s 7ms/step - loss: 1.0470 - accuracy: 0.9973 - val_loss: 1.0516 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27308ad2520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data_low_train,\n",
    "    label_low_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "aborted",
     "timestamp": 1636125295698,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "mq9bBd-3pfgL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 2ms/step - loss: 1.0512 - accuracy: 0.9924\n",
      "\n",
      "Test accuracy: 0.9923727512359619\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "test_loss, test_acc = model.evaluate(data_low_test, label_low_test)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)   # Print out the model accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI3aR1l4pqhS"
   },
   "source": [
    "# **Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295699,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "piwc0fbspvlc"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(data_low_test)   # Make prediction of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Y9R_XtjSrO2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  3\n",
      "True label =  3.0\n"
     ]
    }
   ],
   "source": [
    "num = int(random.uniform(0,data_low_test.shape[0]))\n",
    "print(\"Prediction = \" , np.argmax(predictions[num]))\n",
    "print(\"True label = \" , label_low_test[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1636125295700,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "2Uj_jf6-jCGj"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    class_names = ['0','1','2','3','4','5']\n",
    "\n",
    "    true_label, img = int(true_label[i]), img[i,:,:]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = (np.squeeze(img))## you have to delete the channel information (if grayscale) to plot the image\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)   \n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(6))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "_L_MP6pejCGk"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = int(random.uniform(0, predictions.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "plot_image(num, predictions[num], label_low_test, data_low_test)\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plot_value_array(num, predictions[num], label_low_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye7xyl_-vkkk"
   },
   "source": [
    "## **Save models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_model(model, MODEL_PATH, flag):\n",
    "    new_file = open(MODEL_PATH + 'model_summary.txt', \"w\")\n",
    "\n",
    "    new_file.write(\"PARAMETERS SAVED FROM THE TRAINING\")\n",
    "    if(flag==0):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the ORIGINAL MODEL\")\n",
    "    elif(flag==1):\n",
    "        new_file.write(\"\\n\\n This model has been trained for learning the first 6 digits from the MNIST dataset, this is the FROZEN MODEL\")\n",
    "    new_file.write(\"\\n\")\n",
    "    new_file.write(\"\\n Batch size:       \" + str(batch_size))\n",
    "    new_file.write(\"\\n Epochs:           \" + str(epochs))\n",
    "    new_file.write(\"\\n Metrics:          \" + str(metrics))\n",
    "    new_file.write(\"\\n Optimizer:        \" + optimizer)\n",
    "    new_file.write(\"\\n Loss:             \" + \"SparseCategoricalCrossentropy \\n\\n\")\n",
    "\n",
    "    model.summary(print_fn=lambda x: new_file.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "rjFdtesdvqzf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0511736869812012\n",
      "Test accuracy: 0.9923727512359619\n",
      "Save ORIGINAL MODEL as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath('')\n",
    "SAVE_MODEL_PATH = ROOT_PATH + \"\\\\Saved_models\\\\\"\n",
    "\n",
    "ORIGINAL_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Original_model\\\\\"\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Save ORIGINAL MODEL as mnist_cnn.h5')\n",
    "model.save(ORIGINAL_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(model, ORIGINAL_MODEL_PATH, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the frozen model version for the one just saved. Which means just to cut away the last layer and save the model without the kast kayer. This should be instead saved in a txt/library file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save FROZEN MODEL model as mnist_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND SAVE THE CUT MODEL\n",
    "frozen_model = keras.models.Sequential(model.layers[:-1])\n",
    "frozen_model.summary()\n",
    "frozen_model.compile()\n",
    "\n",
    "FROZEN_MODEL_PATH = SAVE_MODEL_PATH + \"\\\\Frozen_model\\\\\"\n",
    "\n",
    "print('Save FROZEN MODEL model as mnist_cnn.h5')\n",
    "frozen_model.save(FROZEN_MODEL_PATH + \"mnist_cnn.h5\")\n",
    "save_summary_model(frozen_model, FROZEN_MODEL_PATH, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save also the last layer weights in a txt file, this will later be used in the OpenMV camera for loading the weights that have been already trained. (ll = last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the last layer weights is: (2028, 6)\n",
      "The shape of the last layer biases is: (6,)\n"
     ]
    }
   ],
   "source": [
    "ll_weights = np.array(model.layers[-1].get_weights()[0])   # get last layer weights from TF model\n",
    "ll_biases  = np.array(model.layers[-1].get_weights()[1])   # get last layer biases from TF model\n",
    "print(f'The shape of the last layer weights is: {ll_weights.shape}')\n",
    "print(f'The shape of the last layer biases is: {ll_biases.shape}')\n",
    "\n",
    "\n",
    "# -------- WEIGHTS\n",
    "# NB: the filof weights is separated in smaller rows (338 float values on each row)\n",
    "# thjis is done in order to make it easier for the OpenMV camera to load each line (memory problems)\n",
    "with open(FROZEN_MODEL_PATH + 'll_weights.txt', 'w') as new_file:\n",
    "\n",
    "    for j in range(0, ll_weights.shape[1]):\n",
    "        for i in range(0, ll_weights.shape[0]): \n",
    "            if(i%338==0 and i!= 0 and i != ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "                \n",
    "            new_file.write(str(ll_weights[i,j]))\n",
    "            \n",
    "            if(i == ll_weights.shape[0]-1):\n",
    "                new_file.write('\\n')\n",
    "            elif((i+1)%338 == 0):\n",
    "                dummy = 0\n",
    "            else:\n",
    "                new_file.write(',')\n",
    "\n",
    "new_file.close()\n",
    "\n",
    "\n",
    "# -------- BIASES\n",
    "with open(FROZEN_MODEL_PATH + 'll_biases.txt', 'w') as new_file:\n",
    "\n",
    "    for i in range(0, ll_biases.shape[0]):     \n",
    "        new_file.write(str(ll_biases[i])) \n",
    "        if(i!=ll_biases.shape[0]-1):\n",
    "            new_file.write(',')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jSSceEYKsHX"
   },
   "source": [
    "## **Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1Txju54d6yY"
   },
   "source": [
    "**Full integer quantization**\n",
    "\n",
    "For full integer quantization, you need to calibrate or estimate the range, i.e, (min, max) of all floating-point tensors in the model. Unlike constant tensors such as weights and biases, variable tensors such as model input, activations (outputs of intermediate layers) and model output cannot be calibrated unless we run a few inference cycles. As a result, the converter requires a representative dataset to calibrate them. This dataset can be a small subset (around ~100-500 samples) of the training or validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636125295702,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "C1VewrfEKpwW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\massi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmp6gaonpj8\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_io = converter.convert()\n",
    "with open(\"mnist_quant_io.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkJY45mABi6w"
   },
   "source": [
    "**Integer with float fallback (using default float input/output)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "-KhP_3Y8NK6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpyefiq83w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\massi\\AppData\\Local\\Temp\\tmpyefiq83w\\assets\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(data_low_train).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "with open(\"mnist_quant.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1636125295703,
     "user": {
      "displayName": "Alessandro_Avi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3g3OBoR2thMDg3ykM6pXzOuBTEcJePGTDW3_DNw=s64",
      "userId": "02552590181762893039"
     },
     "user_tz": -60
    },
    "id": "Qpda9DBIvsaK"
   },
   "outputs": [],
   "source": [
    "#representative_data_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TEST SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "temp_num = int(random.uniform(0,100))\n",
    "temp_data = data_test[5:100,:,:]\n",
    "print(temp_data.shape)\n",
    "temp_label = label_test[temp_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-12.37976103  -9.98557069  -9.72086869  -9.17863307  13.95551117\n",
      "  -4.88835744]\n",
      "[-12.379758   -9.985565   -9.720869   -9.178634   13.955512   -4.8883576]\n"
     ]
    }
   ],
   "source": [
    "# prediction with frozen model+ OL layer\n",
    "my_result  = np.zeros(6)\n",
    "my_result2 = np.zeros(6)\n",
    "my_forzen_out = frozen_model.predict(data_low_test)\n",
    "my_forzen_out = my_forzen_out[temp_num]\n",
    "\n",
    "\n",
    "my_result = np.array(np.matmul(my_forzen_out, ll_weights) + ll_biases)\n",
    "\n",
    "\n",
    "for i in range(0,6):\n",
    "    for j in range(0,ll_weights.shape[0]):\n",
    "        my_result2[i] += ll_weights[j,i]*my_forzen_out[j]\n",
    "    my_result2[i] += ll_biases[i]\n",
    "    \n",
    "print(my_result2)\n",
    "print(my_result)\n",
    "\n",
    "    \n",
    "    \n",
    "my_soft = np.zeros(6)\n",
    "m       = my_result[0]\n",
    "sum_val = 0\n",
    "\n",
    "for i in range(0, 6):\n",
    "    if(m<my_result[i]):\n",
    "        m = my_result[i]\n",
    "\n",
    "for i in range(0, 6):\n",
    "    sum_val += np.exp(my_result[i] - m)\n",
    "\n",
    "constant = m + np.log(sum_val)\n",
    "for i in range(0, 6):\n",
    "    my_soft[i] = np.exp(my_result[i] - constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(my_soft))\n",
    "print(np.argmax(predictions[temp_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.13918164e-15 9.99999687e-01 1.44810365e-09 2.15095815e-08\n",
      " 2.71937716e-07 1.76428431e-08]\n",
      "[2.1391859e-15 9.9999976e-01 1.4481044e-09 2.1509562e-08 2.7193812e-07\n",
      " 1.7642870e-08]\n"
     ]
    }
   ],
   "source": [
    "print(my_soft)\n",
    "print(predictions[temp_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0057468195\n",
      "-0.0057468195\n"
     ]
    }
   ],
   "source": [
    "print(ll_weights[2025,2])\n",
    "print(np.array(model.layers[-1].get_weights()[0])[2025,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mnist_half.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
