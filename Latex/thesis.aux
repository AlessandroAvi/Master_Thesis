\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{biblatex}
\bibdata{thesis-blx,thesis}
\citation{biblatex-control}
\abx@aux@refcontext{nty/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Introduction}{1}{chapter*.5}\protected@file@percent }
\newlabel{intro}{{}{1}{Introduction}{chapter*.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Related Works}{6}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:relworks}{{1}{6}{Related Works}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction to Machine Learning}{6}{section.1.1}\protected@file@percent }
\citation{ReLU_explanation}
\abx@aux@cite{0}{ReLU_explanation}
\abx@aux@segm{0}{0}{ReLU_explanation}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces On the left an example of layers inside a ML model. On the right a scheme of the behaviour of a neuron.\relax }}{7}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:modelstructure}{{1.1}{7}{On the left an example of layers inside a ML model. On the right a scheme of the behaviour of a neuron.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Characteristic summary of supervised, unsupervised, and reinforcement learning.\relax }}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:supervised}{{1.2}{9}{Characteristic summary of supervised, unsupervised, and reinforcement learning.\relax }{figure.caption.7}{}}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Continual on-line learning}{10}{section.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Block diagram showing examples of ML model structures: in the top left there is a fully connected NN, in the top right there is a CNN and in the bottom part there is an autoencoder.\relax }}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:structures}{{1.3}{11}{Block diagram showing examples of ML model structures: in the top left there is a fully connected NN, in the top right there is a CNN and in the bottom part there is an autoencoder.\relax }{figure.caption.8}{}}
\citation{french1999catastrophic}
\abx@aux@cite{0}{french1999catastrophic}
\abx@aux@segm{0}{0}{french1999catastrophic}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\citation{lesort2020continual}
\abx@aux@cite{0}{lesort2020continual}
\abx@aux@segm{0}{0}{lesort2020continual}
\citation{rusu2016progressive}
\abx@aux@cite{0}{rusu2016progressive}
\abx@aux@segm{0}{0}{rusu2016progressive}
\citation{cai2020tinytl}
\abx@aux@cite{0}{cai2020tinytl}
\abx@aux@segm{0}{0}{cai2020tinytl}
\citation{schwarz2018progress}
\abx@aux@cite{0}{schwarz2018progress}
\abx@aux@segm{0}{0}{schwarz2018progress}
\citation{ren2021tinyol}
\abx@aux@cite{0}{ren2021tinyol}
\abx@aux@segm{0}{0}{ren2021tinyol}
\citation{sudharsan2021train++}
\abx@aux@cite{0}{sudharsan2021train++}
\abx@aux@segm{0}{0}{sudharsan2021train++}
\citation{park2020convolutional}
\abx@aux@cite{0}{park2020convolutional}
\abx@aux@segm{0}{0}{park2020convolutional}
\citation{disabato2020incremental}
\abx@aux@cite{0}{disabato2020incremental}
\abx@aux@segm{0}{0}{disabato2020incremental}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\citation{li2017learning}
\abx@aux@cite{0}{li2017learning}
\abx@aux@segm{0}{0}{li2017learning}
\citation{zenke2017continual}
\abx@aux@cite{0}{zenke2017continual}
\abx@aux@segm{0}{0}{zenke2017continual}
\citation{kirkpatrick2017overcoming}
\abx@aux@cite{0}{kirkpatrick2017overcoming}
\abx@aux@segm{0}{0}{kirkpatrick2017overcoming}
\citation{lomonaco2017core50}
\abx@aux@cite{0}{lomonaco2017core50}
\abx@aux@segm{0}{0}{lomonaco2017core50}
\citation{grau2021device}
\abx@aux@cite{0}{grau2021device}
\abx@aux@segm{0}{0}{grau2021device}
\citation{sudharsan2021imbal}
\abx@aux@cite{0}{sudharsan2021imbal}
\abx@aux@segm{0}{0}{sudharsan2021imbal}
\citation{ren2021tinyol}
\abx@aux@cite{0}{ren2021tinyol}
\abx@aux@segm{0}{0}{ren2021tinyol}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Venn Diagram showing the classification of some well known CL strategies.\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:CLstrategies}{{1.4}{14}{Venn Diagram showing the classification of some well known CL strategies.\relax }{figure.caption.9}{}}
\citation{jokic2021battery}
\abx@aux@cite{0}{jokic2021battery}
\abx@aux@segm{0}{0}{jokic2021battery}
\citation{jokic2021sub}
\abx@aux@cite{0}{jokic2021sub}
\abx@aux@segm{0}{0}{jokic2021sub}
\citation{jokic2021sub}
\abx@aux@cite{0}{jokic2021sub}
\abx@aux@segm{0}{0}{jokic2021sub}
\citation{jokic2021battery}
\abx@aux@cite{0}{jokic2021battery}
\abx@aux@segm{0}{0}{jokic2021battery}
\citation{lin2020mcunet}
\abx@aux@cite{0}{lin2020mcunet}
\abx@aux@segm{0}{0}{lin2020mcunet}
\citation{TF_lite}
\abx@aux@cite{0}{TF_lite}
\abx@aux@segm{0}{0}{TF_lite}
\citation{stm_cube_ai}
\abx@aux@cite{0}{stm_cube_ai}
\abx@aux@segm{0}{0}{stm_cube_ai}
\citation{pytorch_mobile}
\abx@aux@cite{0}{pytorch_mobile}
\abx@aux@segm{0}{0}{pytorch_mobile}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Machine Learning on MCU}{16}{section.1.3}\protected@file@percent }
\newlabel{iot_pro}{{1.3}{16}{Machine Learning on MCU}{section.1.3}{}}
\citation{yu2017survey}
\abx@aux@cite{0}{yu2017survey}
\abx@aux@segm{0}{0}{yu2017survey}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Cloud vs edge inference}{17}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Pruning and quantization}{18}{subsection.1.3.2}\protected@file@percent }
\citation{pruning_article}
\abx@aux@cite{0}{pruning_article}
\abx@aux@segm{0}{0}{pruning_article}
\citation{tensorflow_quantization}
\abx@aux@cite{0}{tensorflow_quantization}
\abx@aux@segm{0}{0}{tensorflow_quantization}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Block diagram showing the steps of a pruning and quantization procedure.\relax }}{19}{figure.caption.10}\protected@file@percent }
\newlabel{fig:pruning}{{1.5}{19}{Block diagram showing the steps of a pruning and quantization procedure.\relax }{figure.caption.10}{}}
\citation{nucleo_datasheet}
\abx@aux@cite{0}{nucleo_datasheet}
\abx@aux@segm{0}{0}{nucleo_datasheet}
\citation{openmv_datasheet}
\abx@aux@cite{0}{openmv_datasheet}
\abx@aux@segm{0}{0}{openmv_datasheet}
\citation{stm_cube_ai}
\abx@aux@cite{0}{stm_cube_ai}
\abx@aux@segm{0}{0}{stm_cube_ai}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Hardware}{21}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{hardware}{{2}{21}{Hardware}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Gesture recognition hardware}{21}{section.2.1}\protected@file@percent }
\citation{shield_web_page}
\abx@aux@cite{0}{shield_web_page}
\abx@aux@segm{0}{0}{shield_web_page}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Hardware used for the CL applications. On the left Nucelo STM32 F401-RE, on the right OpenMV camera.\relax }}{22}{figure.caption.11}\protected@file@percent }
\newlabel{fig:hardware_all}{{2.1}{22}{Hardware used for the CL applications. On the left Nucelo STM32 F401-RE, on the right OpenMV camera.\relax }{figure.caption.11}{}}
\citation{abdelkader2017openmv}
\abx@aux@cite{0}{abdelkader2017openmv}
\abx@aux@segm{0}{0}{abdelkader2017openmv}
\citation{openmv_web_page}
\abx@aux@cite{0}{openmv_web_page}
\abx@aux@segm{0}{0}{openmv_web_page}
\citation{openmv_project}
\abx@aux@cite{0}{openmv_project}
\abx@aux@segm{0}{0}{openmv_project}
\citation{zhou2019design}
\abx@aux@cite{0}{zhou2019design}
\abx@aux@segm{0}{0}{zhou2019design}
\citation{wei2020design}
\abx@aux@cite{0}{wei2020design}
\abx@aux@segm{0}{0}{wei2020design}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Nucleo STM F401-RE specifications\relax }}{23}{table.caption.12}\protected@file@percent }
\newlabel{table:specifications_stm}{{2.1}{23}{Nucleo STM F401-RE specifications\relax }{table.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Hardware used in the gesture recognition application. On the left the sensor shield IKS01A2, on the right the sensor shield mounted on the Nucleo STM32 F401-RE.\relax }}{23}{figure.caption.13}\protected@file@percent }
\newlabel{fig:hardware_stm}{{2.2}{23}{Hardware used in the gesture recognition application. On the left the sensor shield IKS01A2, on the right the sensor shield mounted on the Nucleo STM32 F401-RE.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Image classification hardware}{23}{section.2.2}\protected@file@percent }
\citation{tripod_link}
\abx@aux@cite{0}{tripod_link}
\abx@aux@segm{0}{0}{tripod_link}
\citation{github_repo}
\abx@aux@cite{0}{github_repo}
\abx@aux@segm{0}{0}{github_repo}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces OpenMV H7+ specifications\relax }}{25}{table.caption.14}\protected@file@percent }
\newlabel{table:specifications_openmv}{{2.2}{25}{OpenMV H7+ specifications\relax }{table.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Hardware used in the image classification application. On the left the 3D printed tripod, on the right the OpenMV camera mounted on the 3D printed tripod.\relax }}{26}{figure.caption.15}\protected@file@percent }
\newlabel{fig:hardware_openmv}{{2.3}{26}{Hardware used in the image classification application. On the left the 3D printed tripod, on the right the OpenMV camera mounted on the 3D printed tripod.\relax }{figure.caption.15}{}}
\citation{ren2021tinyol}
\abx@aux@cite{0}{ren2021tinyol}
\abx@aux@segm{0}{0}{ren2021tinyol}
\citation{ren2021synergy}
\abx@aux@cite{0}{ren2021synergy}
\abx@aux@segm{0}{0}{ren2021synergy}
\citation{sudharsan2021train++}
\abx@aux@cite{0}{sudharsan2021train++}
\abx@aux@segm{0}{0}{sudharsan2021train++}
\citation{ren2021tinyol}
\abx@aux@cite{0}{ren2021tinyol}
\abx@aux@segm{0}{0}{ren2021tinyol}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}System implementation}{27}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Basic pipeline of the CL system developed}{28}{section.3.1}\protected@file@percent }
\newlabel{basic_system}{{3.1}{28}{Basic pipeline of the CL system developed}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Block diagram showing an example of model training\relax }}{29}{figure.caption.16}\protected@file@percent }
\newlabel{fig:block_diag_esempio}{{3.1}{29}{Block diagram showing an example of model training\relax }{figure.caption.16}{}}
\newlabel{zi}{{3.1}{30}{Basic pipeline of the CL system developed}{equation.3.1.1}{}}
\newlabel{yi}{{3.2}{30}{Basic pipeline of the CL system developed}{equation.3.1.2}{}}
\newlabel{cost_cross}{{3.3}{30}{Basic pipeline of the CL system developed}{equation.3.1.3}{}}
\citation{derivation_passages}
\abx@aux@cite{0}{derivation_passages}
\abx@aux@segm{0}{0}{derivation_passages}
\citation{kirkpatrick2017overcoming}
\abx@aux@cite{0}{kirkpatrick2017overcoming}
\abx@aux@segm{0}{0}{kirkpatrick2017overcoming}
\citation{zenke2017continual}
\abx@aux@cite{0}{zenke2017continual}
\abx@aux@segm{0}{0}{zenke2017continual}
\citation{li2017learning}
\abx@aux@cite{0}{li2017learning}
\abx@aux@segm{0}{0}{li2017learning}
\citation{lomonaco2017core50}
\abx@aux@cite{0}{lomonaco2017core50}
\abx@aux@segm{0}{0}{lomonaco2017core50}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\newlabel{w_update}{{3.10}{31}{Basic pipeline of the CL system developed}{equation.3.1.10}{}}
\newlabel{b_update}{{3.11}{31}{Basic pipeline of the CL system developed}{equation.3.1.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Implemented algorithms}{31}{section.3.2}\protected@file@percent }
\newlabel{algorithms}{{3.2}{31}{Implemented algorithms}{section.3.2}{}}
\citation{ren2021tinyol}
\abx@aux@cite{0}{ren2021tinyol}
\abx@aux@segm{0}{0}{ren2021tinyol}
\citation{batch_size_medium}
\abx@aux@cite{0}{batch_size_medium}
\abx@aux@segm{0}{0}{batch_size_medium}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}TinyOL}{32}{subsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Block diagram describing the algorithm TinyOL.\relax }}{34}{figure.caption.17}\protected@file@percent }
\newlabel{fig:block_diag_OL}{{3.2}{34}{Block diagram describing the algorithm TinyOL.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}TinyOL V2}{34}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Block diagram describing the algorithm TinyOL with batches.\relax }}{35}{figure.caption.18}\protected@file@percent }
\newlabel{fig:block_diag_OLwb}{{3.3}{35}{Block diagram describing the algorithm TinyOL with batches.\relax }{figure.caption.18}{}}
\citation{li2017learning}
\abx@aux@cite{0}{li2017learning}
\abx@aux@segm{0}{0}{li2017learning}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}LWF}{36}{subsection.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Block diagram describing the algorithm TinyOL V2.\relax }}{37}{figure.caption.19}\protected@file@percent }
\newlabel{fig:block_diag_OLV2}{{3.4}{37}{Block diagram describing the algorithm TinyOL V2.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Block diagram describing the algorithm TinyOL V2 with batches.\relax }}{37}{figure.caption.20}\protected@file@percent }
\newlabel{fig:block_diag_OLV2wb}{{3.5}{37}{Block diagram describing the algorithm TinyOL V2 with batches.\relax }{figure.caption.20}{}}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\citation{maltoni2019continuous}
\abx@aux@cite{0}{maltoni2019continuous}
\abx@aux@segm{0}{0}{maltoni2019continuous}
\newlabel{lwfcost}{{3.24}{38}{LWF}{equation.3.2.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Block diagram describing the algorithm LWF.\relax }}{40}{figure.caption.21}\protected@file@percent }
\newlabel{fig:block_diag_LWF}{{3.6}{40}{Block diagram describing the algorithm LWF.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}CWR}{40}{subsection.3.2.4}\protected@file@percent }
\newlabel{cwrweight}{{3.35}{41}{CWR}{equation.3.2.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Block diagram describing the algorithm CWR.\relax }}{42}{figure.caption.22}\protected@file@percent }
\newlabel{fig:block_diag_CWR}{{3.7}{42}{Block diagram describing the algorithm CWR.\relax }{figure.caption.22}{}}
\citation{deng2012mnist}
\abx@aux@cite{0}{deng2012mnist}
\abx@aux@segm{0}{0}{deng2012mnist}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experimental setup}{43}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Dataset collection}{43}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Accelerometer dataset}{44}{subsection.4.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Motion followed with the sensor for writing letters in the air.\relax }}{45}{figure.caption.23}\protected@file@percent }
\newlabel{fig:letters_motion}{{4.1}{45}{Motion followed with the sensor for writing letters in the air.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Digits recognition dataset}{45}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Stankey diagram showing how the letter dataset is divided\relax }}{46}{figure.caption.24}\protected@file@percent }
\newlabel{fig:flow_dataset_letters}{{4.2}{46}{Stankey diagram showing how the letter dataset is divided\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Example of images from the MNIST digits dataset\relax }}{46}{figure.caption.25}\protected@file@percent }
\newlabel{fig:mnist_dataset}{{4.3}{46}{Example of images from the MNIST digits dataset\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Stankey diagram showing how the MNIST dataset is divided\relax }}{47}{figure.caption.26}\protected@file@percent }
\newlabel{fig:flow_dataset_openmv}{{4.4}{47}{Stankey diagram showing how the MNIST dataset is divided\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Frozen model training and evaluation}{47}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Gesture recognition model}{47}{subsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Letter recognition model: basic structure and its separation in frozen model and CL classification layer\relax }}{48}{figure.caption.27}\protected@file@percent }
\newlabel{fig:letter_structure}{{4.5}{48}{Letter recognition model: basic structure and its separation in frozen model and CL classification layer\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Results after the Tensorflow training. Top left: variation of accuracy and loss during training and validation. Top right: accuracy of the model in each class. Bottom left: table resuming precision accuracy and F1 score. Bottom right: confusion matrix of the testing.\relax }}{49}{figure.caption.28}\protected@file@percent }
\newlabel{fig:training_letters}{{4.6}{49}{Results after the Tensorflow training. Top left: variation of accuracy and loss during training and validation. Top right: accuracy of the model in each class. Bottom left: table resuming precision accuracy and F1 score. Bottom right: confusion matrix of the testing.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Image classification model}{50}{subsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Image classification model: basic structure and its separation in frozen model and CL classification layer\relax }}{50}{figure.caption.29}\protected@file@percent }
\newlabel{fig:openmv_structure}{{4.7}{50}{Image classification model: basic structure and its separation in frozen model and CL classification layer\relax }{figure.caption.29}{}}
\citation{github_repo}
\abx@aux@cite{0}{github_repo}
\abx@aux@segm{0}{0}{github_repo}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Results after the Tensorflow training. Top left: variation of accuracy and loss during training and validation. Top right: accuracy of the model in each class. Bottom left: table resuming precision accuracy and F1 score. Bottom right confusion matrix.\relax }}{52}{figure.caption.30}\protected@file@percent }
\newlabel{fig:training_mnist}{{4.8}{52}{Results after the Tensorflow training. Top left: variation of accuracy and loss during training and validation. Top right: accuracy of the model in each class. Bottom left: table resuming precision accuracy and F1 score. Bottom right confusion matrix.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}STM F401-RE setup for gesture recognition}{53}{section.4.3}\protected@file@percent }
\newlabel{nucleo_application}{{4.3}{53}{STM F401-RE setup for gesture recognition}{section.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Block diagram showing the communication between laptop and STM Nucleo.\relax }}{55}{figure.caption.31}\protected@file@percent }
\newlabel{fig:python_stm_diagram}{{4.9}{55}{Block diagram showing the communication between laptop and STM Nucleo.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}OpenMV setup for image classification}{55}{section.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Block diagram showing the communication between laptop and OpenMV camera.\relax }}{58}{figure.caption.32}\protected@file@percent }
\newlabel{fig:python_openmv_diagram}{{4.10}{58}{Block diagram showing the communication between laptop and OpenMV camera.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces OpenMV camera pointing to a screen while in different states of the training. Top left is $idle$ mode, top right is $snap$ mode, bottom left is $elab$ mode, bottom right is $trai$ mode\relax }}{59}{figure.caption.33}\protected@file@percent }
\newlabel{fig:openmv_training}{{4.11}{59}{OpenMV camera pointing to a screen while in different states of the training. Top left is $idle$ mode, top right is $snap$ mode, bottom left is $elab$ mode, bottom right is $trai$ mode\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Point of view of the OpenMV camera. On the left the original image taken with no compression and no elaboration, in the center an image taken in $snap$ mode, on the right an image taken in $elab$ mode.\relax }}{59}{figure.caption.34}\protected@file@percent }
\newlabel{fig:openmv_pov}{{4.12}{59}{Point of view of the OpenMV camera. On the left the original image taken with no compression and no elaboration, in the center an image taken in $snap$ mode, on the right an image taken in $elab$ mode.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experimental results}{60}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Experiment A: Gesture recognition}{60}{section.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Block diagram showing at which block in a training step the parameters are copied and saved.\relax }}{61}{figure.caption.35}\protected@file@percent }
\newlabel{fig:evolution_params}{{5.1}{61}{Block diagram showing at which block in a training step the parameters are copied and saved.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Plot showing the element by element difference of two frozen model outputs (at training step 544) computed on the Nucleo MCU and on a laptop.\relax }}{62}{figure.caption.36}\protected@file@percent }
\newlabel{fig:comparison_frozen}{{5.2}{62}{Plot showing the element by element difference of two frozen model outputs (at training step 544) computed on the Nucleo MCU and on a laptop.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Plot showing the variation of bias number 1 recorded on the Nucleo MCU and on a laptop during a training session.\relax }}{62}{figure.caption.37}\protected@file@percent }
\newlabel{fig:comparison_bias}{{5.3}{62}{Plot showing the variation of bias number 1 recorded on the Nucleo MCU and on a laptop during a training session.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Plot showing the variation of weight number recorded on the Nucleo MCU and on a laptop during a training session.\relax }}{63}{figure.caption.38}\protected@file@percent }
\newlabel{fig:comparison_weights}{{5.4}{63}{Plot showing the variation of weight number recorded on the Nucleo MCU and on a laptop during a training session.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Plot showing the difference of the prediction for class $A$ computed on the Nucleo MCU and on a laptop during a training session.\relax }}{63}{figure.caption.39}\protected@file@percent }
\newlabel{fig:comparison_softmax}{{5.5}{63}{Plot showing the difference of the prediction for class $A$ computed on the Nucleo MCU and on a laptop during a training session.\relax }{figure.caption.39}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Table showing the overall accuracy, inference times and memory use for each method during testing of the gesture recognition application.\relax }}{65}{table.caption.40}\protected@file@percent }
\newlabel{table:nucleo_smalltable}{{5.1}{65}{Table showing the overall accuracy, inference times and memory use for each method during testing of the gesture recognition application.\relax }{table.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm in the gesture recognition application.\relax }}{66}{figure.caption.41}\protected@file@percent }
\newlabel{fig:letter_res_OL}{{5.6}{66}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm in the gesture recognition application.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm with batches in the gesture recognition application.\relax }}{66}{figure.caption.42}\protected@file@percent }
\newlabel{fig:letter_res_OL_batch}{{5.7}{66}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm with batches in the gesture recognition application.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm in the gesture recognition application.\relax }}{67}{figure.caption.43}\protected@file@percent }
\newlabel{fig:letter_res_OL_v2}{{5.8}{67}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm in the gesture recognition application.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm with batches in the gesture recognition application.\relax }}{67}{figure.caption.44}\protected@file@percent }
\newlabel{fig:letter_res_OL_v2_batch}{{5.9}{67}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm with batches in the gesture recognition application.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm in the gesture recognition application.\relax }}{68}{figure.caption.45}\protected@file@percent }
\newlabel{fig:letter_res_LWF}{{5.10}{68}{Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm in the gesture recognition application.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm with batches in the gesture recognition application.\relax }}{68}{figure.caption.46}\protected@file@percent }
\newlabel{fig:letter_res_LWF_batch}{{5.11}{68}{Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm with batches in the gesture recognition application.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with CWR algorithm in the gesture recognition application.\relax }}{69}{figure.caption.47}\protected@file@percent }
\newlabel{fig:letter_res_CWR}{{5.12}{69}{Bar plot and confusion matrix showing the results from the testing session performed with CWR algorithm in the gesture recognition application.\relax }{figure.caption.47}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Table showing the precision, accuracy and F1 score for each class and all methods during testing of the gesture recognition application.\relax }}{70}{table.caption.48}\protected@file@percent }
\newlabel{table:nucleo_bigtable}{{5.2}{70}{Table showing the precision, accuracy and F1 score for each class and all methods during testing of the gesture recognition application.\relax }{table.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Plot showing the relation between accuracy and batch size for all the methods implemented in the gesture recognition application.\relax }}{72}{figure.caption.49}\protected@file@percent }
\newlabel{fig:batch_size_letter}{{5.13}{72}{Plot showing the relation between accuracy and batch size for all the methods implemented in the gesture recognition application.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Experiment B: Image classification}{72}{section.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Table showing the overall accuracy and inference times for each method during testing of the digits recognition application.\relax }}{73}{table.caption.50}\protected@file@percent }
\newlabel{table:openmv_smalltable}{{5.3}{73}{Table showing the overall accuracy and inference times for each method during testing of the digits recognition application.\relax }{table.caption.50}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Table showing the precision, accuracy and F1 score for each class and all methods during testing of the digits recognition application.\relax }}{74}{table.caption.51}\protected@file@percent }
\newlabel{table:openmv_bigtable}{{5.4}{74}{Table showing the precision, accuracy and F1 score for each class and all methods during testing of the digits recognition application.\relax }{table.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm on the image classification experiment.\relax }}{75}{figure.caption.52}\protected@file@percent }
\newlabel{fig:openmv_res_OL}{{5.14}{75}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm on the image classification experiment.\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm with batches on the image classification experiment.\relax }}{75}{figure.caption.53}\protected@file@percent }
\newlabel{fig:openmv_res_OL_batch}{{5.15}{75}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL algorithm with batches on the image classification experiment.\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm on the image classification experiment.\relax }}{76}{figure.caption.54}\protected@file@percent }
\newlabel{fig:openmv_res_OL_v2}{{5.16}{76}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm on the image classification experiment.\relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm with batches on the image classification experiment.\relax }}{76}{figure.caption.55}\protected@file@percent }
\newlabel{fig:openmv_res_OL_v2_batch}{{5.17}{76}{Bar plot and confusion matrix showing the results from the testing session performed with TinyOL V2 algorithm with batches on the image classification experiment.\relax }{figure.caption.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm on the image classification experiment.\relax }}{77}{figure.caption.56}\protected@file@percent }
\newlabel{fig:openmv_res_LWF}{{5.18}{77}{Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm on the image classification experiment.\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm with batches on the image classification experiment.\relax }}{77}{figure.caption.57}\protected@file@percent }
\newlabel{fig:openmv_res_LWF_batch}{{5.19}{77}{Bar plot and confusion matrix showing the results from the testing session performed with LWF algorithm with batches on the image classification experiment.\relax }{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Bar plot and confusion matrix showing the results from the testing session performed with CWR algorithm on the image classification experiment.\relax }}{78}{figure.caption.58}\protected@file@percent }
\newlabel{fig:openmv_res_CWR}{{5.20}{78}{Bar plot and confusion matrix showing the results from the testing session performed with CWR algorithm on the image classification experiment.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces Plot showing the relation between accuracy and batch size for all the methods implemented in the digits recognition application.\relax }}{79}{figure.caption.59}\protected@file@percent }
\newlabel{fig:openmv_batch_size}{{5.21}{79}{Plot showing the relation between accuracy and batch size for all the methods implemented in the digits recognition application.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{80}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@read@bbl@mdfivesum{9C0FB6137042FEE76DDFBAA7A63AB954}
\abx@aux@defaultrefcontext{0}{abdelkader2017openmv}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{github_repo}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{derivation_passages}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{cai2020tinytl}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{deng2012mnist}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{disabato2020incremental}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{french1999catastrophic}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{grau2021device}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{jokic2021battery}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{jokic2021sub}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{kirkpatrick2017overcoming}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lesort2020continual}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{li2017learning}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lin2020mcunet}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{lomonaco2017core50}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{maltoni2019continuous}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{pytorch_mobile}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{openmv_datasheet}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{openmv_project}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{openmv_web_page}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{park2020convolutional}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ReLU_explanation}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ren2021synergy}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{ren2021tinyol}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{rusu2016progressive}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{schwarz2018progress}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{batch_size_medium}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{shield_web_page}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{nucleo_datasheet}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{stm_cube_ai}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{sudharsan2021imbal}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{sudharsan2021train++}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{pruning_article}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{tensorflow_quantization}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{TF_lite}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{tripod_link}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{wei2020design}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{yu2017survey}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zenke2017continual}{nty/global//global/global}
\abx@aux@defaultrefcontext{0}{zhou2019design}{nty/global//global/global}
\abx@aux@defaultlabelprefix{0}{abdelkader2017openmv}{}
\abx@aux@defaultlabelprefix{0}{github_repo}{}
\abx@aux@defaultlabelprefix{0}{derivation_passages}{}
\abx@aux@defaultlabelprefix{0}{cai2020tinytl}{}
\abx@aux@defaultlabelprefix{0}{deng2012mnist}{}
\abx@aux@defaultlabelprefix{0}{disabato2020incremental}{}
\abx@aux@defaultlabelprefix{0}{french1999catastrophic}{}
\abx@aux@defaultlabelprefix{0}{grau2021device}{}
\abx@aux@defaultlabelprefix{0}{jokic2021battery}{}
\abx@aux@defaultlabelprefix{0}{jokic2021sub}{}
\abx@aux@defaultlabelprefix{0}{kirkpatrick2017overcoming}{}
\abx@aux@defaultlabelprefix{0}{lesort2020continual}{}
\abx@aux@defaultlabelprefix{0}{li2017learning}{}
\abx@aux@defaultlabelprefix{0}{lin2020mcunet}{}
\abx@aux@defaultlabelprefix{0}{lomonaco2017core50}{}
\abx@aux@defaultlabelprefix{0}{maltoni2019continuous}{}
\abx@aux@defaultlabelprefix{0}{pytorch_mobile}{}
\abx@aux@defaultlabelprefix{0}{openmv_datasheet}{}
\abx@aux@defaultlabelprefix{0}{openmv_project}{}
\abx@aux@defaultlabelprefix{0}{openmv_web_page}{}
\abx@aux@defaultlabelprefix{0}{park2020convolutional}{}
\abx@aux@defaultlabelprefix{0}{ReLU_explanation}{}
\abx@aux@defaultlabelprefix{0}{ren2021synergy}{}
\abx@aux@defaultlabelprefix{0}{ren2021tinyol}{}
\abx@aux@defaultlabelprefix{0}{rusu2016progressive}{}
\abx@aux@defaultlabelprefix{0}{schwarz2018progress}{}
\abx@aux@defaultlabelprefix{0}{batch_size_medium}{}
\abx@aux@defaultlabelprefix{0}{shield_web_page}{}
\abx@aux@defaultlabelprefix{0}{nucleo_datasheet}{}
\abx@aux@defaultlabelprefix{0}{stm_cube_ai}{}
\abx@aux@defaultlabelprefix{0}{sudharsan2021imbal}{}
\abx@aux@defaultlabelprefix{0}{sudharsan2021train++}{}
\abx@aux@defaultlabelprefix{0}{pruning_article}{}
\abx@aux@defaultlabelprefix{0}{tensorflow_quantization}{}
\abx@aux@defaultlabelprefix{0}{TF_lite}{}
\abx@aux@defaultlabelprefix{0}{tripod_link}{}
\abx@aux@defaultlabelprefix{0}{wei2020design}{}
\abx@aux@defaultlabelprefix{0}{yu2017survey}{}
\abx@aux@defaultlabelprefix{0}{zenke2017continual}{}
\abx@aux@defaultlabelprefix{0}{zhou2019design}{}
\gdef \@abspage@last{96}
